{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import cudf\n",
    "import cuspatial\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cugraph\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "LANDUSE_NDVI_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/neighborhoods_with_ndvi_numerical.geojson\"\n",
    "OSM_BUILDINGS_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/Taipei_Buildings_fulldata.geojson\"\n",
    "OSM_ROADS_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_segments_cleaned_verified.geoparquet\"\n",
    "OSM_TREES_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_land.geoparquet\"\n",
    "OSM_TRANSIT_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_infrastructure.geoparquet\"\n",
    "URBAN_MASTERPLAN_PATH = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/Taipei_urban_masterplan.geojson\"\n",
    "SUBGRAPH_DIR = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/subgraphs\"\n",
    "CHECKPOINT_DIR = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/checkpoints\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def validate_geometries(gdf, name):\n",
    "    \"\"\"Validate and filter out invalid geometries.\"\"\"\n",
    "    print(f\"Validating geometries for {name}...\")\n",
    "    gdf = gdf[gdf.geometry.is_valid]\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    print(f\"{name} after validation: {len(gdf)} rows\")\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1: Data Loading and Preprocessing\n",
    "This stage loads geospatial data, validates geometries, and prepares it for graph construction. It uses GPU-accelerated libraries (cudf, cuspatial) alongside geopandas for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"Load and preprocess geospatial data.\"\"\"\n",
    "    print(\"Stage 1: Loading and preparing data...\")\n",
    "    with tqdm(total=6, desc=\"Loading files\") as pbar:\n",
    "        neighborhoods_gdf = gpd.read_file(LANDUSE_NDVI_PATH, encoding='utf-8-sig')\n",
    "        neighborhoods_gdf = validate_geometries(neighborhoods_gdf, \"neighborhoods\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        buildings_gdf = gpd.read_file(OSM_BUILDINGS_PATH, encoding='utf-8-sig')\n",
    "        buildings_gdf = validate_geometries(buildings_gdf, \"buildings\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        roads_gdf = gpd.read_parquet(OSM_ROADS_PATH)\n",
    "        roads_gdf = validate_geometries(roads_gdf, \"roads\")\n",
    "        # Ensure CRS is projected for meter-based lengths\n",
    "        if roads_gdf.crs.is_geographic:\n",
    "            print(\"Reprojecting roads_gdf to EPSG:3826 for length calculations in meters...\")\n",
    "            roads_gdf = roads_gdf.to_crs('EPSG:3826')\n",
    "        roads_gdf['length_m'] = roads_gdf.geometry.length\n",
    "        print(f\"roads_gdf columns after adding length_m: {roads_gdf.columns.tolist()}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        trees_gdf = gpd.read_parquet(OSM_TREES_PATH)\n",
    "        trees_gdf = trees_gdf[trees_gdf['subtype'] == 'tree']\n",
    "        trees_gdf = validate_geometries(trees_gdf, \"trees\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        transit_gdf = gpd.read_parquet(OSM_TRANSIT_PATH)\n",
    "        transit_gdf = transit_gdf[transit_gdf['class'].isin(['stop_position', 'bus_stop'])]\n",
    "        transit_gdf = transit_gdf[transit_gdf.geometry.geom_type == 'Point']\n",
    "        transit_gdf = validate_geometries(transit_gdf, \"transit\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        urban_masterplan_gdf = gpd.read_file(URBAN_MASTERPLAN_PATH)\n",
    "        urban_masterplan_gdf = validate_geometries(urban_masterplan_gdf, \"urban_masterplan\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Convert geometries to cuspatial for GPU-accelerated spatial operations\n",
    "    neighborhoods_geo = cuspatial.from_geopandas(neighborhoods_gdf['geometry'])\n",
    "    trees_geo = cuspatial.from_geopandas(trees_gdf['geometry'])\n",
    "    transit_geo = cuspatial.from_geopandas(transit_gdf['geometry'])\n",
    "\n",
    "    # Calculate tree_count and transit_count for each neighborhood\n",
    "    neighborhoods_gdf['tree_count'] = 0\n",
    "    neighborhoods_gdf['transit_count'] = 0\n",
    "    for idx in range(len(neighborhoods_gdf)):\n",
    "        neighborhood_geom = neighborhoods_geo.iloc[idx]\n",
    "        if neighborhood_geom.is_valid:\n",
    "            # Create a GeoSeries with a single polygon for this neighborhood\n",
    "            neighborhood_geo = cuspatial.GeoSeries([neighborhood_geom])\n",
    "            # Count trees within the neighborhood\n",
    "            trees_mask = cuspatial.point_in_polygon(trees_geo, neighborhood_geo)\n",
    "            neighborhoods_gdf.at[idx, 'tree_count'] = trees_mask.sum().values[0]\n",
    "            # Count transit points within the neighborhood\n",
    "            transit_mask = cuspatial.point_in_polygon(transit_geo, neighborhood_geo)\n",
    "            neighborhoods_gdf.at[idx, 'transit_count'] = transit_mask.sum().values[0]\n",
    "        else:\n",
    "            print(f\"Warning: Invalid geometry at index {idx} in neighborhoods_geo\")\n",
    "\n",
    "    return {\n",
    "        'neighborhoods': neighborhoods_gdf,\n",
    "        'buildings': buildings_gdf,\n",
    "        'roads': roads_gdf,\n",
    "        'trees': trees_gdf,\n",
    "        'transit': transit_gdf,\n",
    "        'urban_masterplan': urban_masterplan_gdf\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 2: Graph Construction\n",
    "This stage constructs a graph network for the city, creating subgraphs for each neighborhood and a road network using cugraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(data):\n",
    "    \"\"\"Build graph network with subgraphs for each neighborhood.\"\"\"\n",
    "    print(\"Stage 2: Building graph network...\")\n",
    "    subgraphs = {}\n",
    "    road_network_nodes = []\n",
    "\n",
    "    neighborhoods_gdf = data['neighborhoods']\n",
    "    buildings_gdf = data['buildings']\n",
    "    roads_gdf = data['roads']\n",
    "    trees_gdf = data['trees']\n",
    "    transit_gdf = data['transit']\n",
    "\n",
    "    for idx in tqdm(range(len(neighborhoods_gdf)), desc=\"Building subgraphs\"):\n",
    "        lie_name = neighborhoods_gdf['LIE_NAME'].iloc[idx]\n",
    "        subgraph_path = os.path.join(SUBGRAPH_DIR, f\"subgraph_{lie_name}.pkl\")\n",
    "        \n",
    "        if os.path.exists(subgraph_path):\n",
    "            with open(subgraph_path, 'rb') as f:\n",
    "                subgraphs[lie_name] = pickle.load(f)\n",
    "            continue\n",
    "\n",
    "        G_sub = cugraph.Graph(directed=False)\n",
    "        all_nodes = []\n",
    "        all_edges = []\n",
    "\n",
    "        # Neighborhood node\n",
    "        node_id = f\"neighborhood_{lie_name}\"\n",
    "        node_data = {\n",
    "            'vertex': node_id,\n",
    "            'type': 'neighborhood',\n",
    "            'lie_name': lie_name,\n",
    "            'population': neighborhoods_gdf['2024population'].iloc[idx],\n",
    "            'land_use_residential_percent': neighborhoods_gdf['land_use_residential_percent'].iloc[idx],\n",
    "            'land_use_commercial_percent': neighborhoods_gdf['land_use_commercial_percent'].iloc[idx],\n",
    "            'land_use_education_percent': neighborhoods_gdf['land_use_education_percent'].iloc[idx],\n",
    "            'ndvi_mean': neighborhoods_gdf['ndvi_mean'].iloc[idx],\n",
    "            'tree_count': neighborhoods_gdf['tree_count'].iloc[idx],\n",
    "            'transit_count': neighborhoods_gdf['transit_count'].iloc[idx]\n",
    "        }\n",
    "        all_nodes.append(node_data)\n",
    "\n",
    "        # Buffer and spatial filtering\n",
    "        buffer_distance = 200\n",
    "        neigh_geom = neighborhoods_gdf.geometry.iloc[idx]\n",
    "        neigh_buffer = neigh_geom.buffer(buffer_distance)\n",
    "\n",
    "        relevant_buildings = buildings_gdf[buildings_gdf.geometry.within(neigh_buffer)]\n",
    "        relevant_roads = roads_gdf[roads_gdf.geometry.intersects(neigh_buffer)]\n",
    "        relevant_trees = trees_gdf[trees_gdf.geometry.within(neigh_buffer)]\n",
    "        relevant_transit = transit_gdf[transit_gdf.geometry.within(neigh_buffer)]\n",
    "\n",
    "        # Building nodes\n",
    "        for b_idx, building in relevant_buildings.iterrows():\n",
    "            node_id = f\"building_{b_idx}\"\n",
    "            building_data = {\n",
    "                'vertex': node_id,\n",
    "                'type': 'building',\n",
    "                'building_type': building['building'],\n",
    "                'area_m2': building['area_m2']\n",
    "            }\n",
    "            all_nodes.append(building_data)\n",
    "\n",
    "        # Road nodes\n",
    "        road_points = []\n",
    "        for r_idx, road in relevant_roads.iterrows():\n",
    "            geom = road.geometry\n",
    "            if geom.geom_type == 'LineString':\n",
    "                start_point = Point(geom.coords[0])\n",
    "                end_point = Point(geom.coords[-1])\n",
    "                road_points.extend([(f\"road_start_{r_idx}\", start_point), (f\"road_end_{r_idx}\", end_point)])\n",
    "\n",
    "        for node_id, geom in road_points:\n",
    "            r_idx = int(node_id.split('_')[2])\n",
    "            road_data = {\n",
    "                'vertex': node_id,\n",
    "                'type': 'road',\n",
    "                'road_class': roads_gdf['class'].iloc[r_idx],\n",
    "                'length_m': roads_gdf['length_m'].iloc[r_idx]\n",
    "            }\n",
    "            all_nodes.append(road_data)\n",
    "            road_network_nodes.append(road_data)\n",
    "\n",
    "        # Tree nodes\n",
    "        for t_idx, tree in relevant_trees.iterrows():\n",
    "            node_id = f\"tree_{t_idx}\"\n",
    "            tree_data = {'vertex': node_id, 'type': 'tree'}\n",
    "            all_nodes.append(tree_data)\n",
    "\n",
    "        # Transit nodes\n",
    "        for t_idx, transit in relevant_transit.iterrows():\n",
    "            node_id = f\"transit_{t_idx}\"\n",
    "            transit_data = {\n",
    "                'vertex': node_id,\n",
    "                'type': 'transit',\n",
    "                'class': transit['class']\n",
    "            }\n",
    "            all_nodes.append(transit_data)\n",
    "\n",
    "        # Edges (simplified for brevity)\n",
    "        # Add edges based on spatial proximity (e.g., neighborhood to buildings, roads, etc.)\n",
    "        # This can be expanded as needed\n",
    "\n",
    "        nodes_df = cudf.DataFrame(all_nodes)\n",
    "        edges_df = cudf.DataFrame(all_edges) if all_edges else None\n",
    "        subgraph_data = {'nodes': nodes_df, 'edges': edges_df}\n",
    "        subgraphs[lie_name] = subgraph_data\n",
    "\n",
    "        with open(subgraph_path, 'wb') as f:\n",
    "            pickle.dump(subgraph_data, f)\n",
    "\n",
    "    return subgraphs, road_network_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 3: Walkability Calculation (Rule-Based)\n",
    "This stage calculates walkability scores using a rule-based approach, based on land use, NDVI, trees, transit, and open spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_walkability_scores(nodes_df):\n",
    "    \"\"\"Compute rule-based walkability scores for neighborhood nodes.\"\"\"\n",
    "    neighborhood_mask = nodes_df['type'] == 'neighborhood'\n",
    "    neighborhood_df = nodes_df[neighborhood_mask].copy()\n",
    "\n",
    "    if len(neighborhood_df) == 0:\n",
    "        if 'walkability_rule' not in nodes_df.columns:\n",
    "            nodes_df['walkability_rule'] = 0.0\n",
    "        return nodes_df\n",
    "\n",
    "    residential = neighborhood_df['land_use_residential_percent']\n",
    "    commercial = neighborhood_df['land_use_commercial_percent']\n",
    "    education = neighborhood_df['land_use_education_percent']\n",
    "    ndvi = neighborhood_df['ndvi_mean'].fillna(0.0)\n",
    "    tree_count = neighborhood_df['tree_count']\n",
    "    transit_count = neighborhood_df['transit_count']\n",
    "\n",
    "    land_use_score = (residential * 0.4 + commercial * 0.3 + education * 0.2) / 100\n",
    "    ndvi_score = ndvi * 0.5\n",
    "    tree_score = (tree_count / 100).clip(upper=1.0) * 0.2\n",
    "    transit_score = (transit_count / 20).clip(upper=1.0) * 0.2\n",
    "\n",
    "    walkability = (land_use_score + ndvi_score * 0.4 + tree_score + transit_score).clip(upper=1.0)\n",
    "\n",
    "    if 'walkability_rule' not in nodes_df.columns:\n",
    "        nodes_df['walkability_rule'] = 0.0\n",
    "    nodes_df.loc[neighborhood_mask, 'walkability_rule'] = walkability\n",
    "\n",
    "    return nodes_df\n",
    "\n",
    "def calculate_walkability(subgraphs, neighborhoods_gdf):\n",
    "    \"\"\"Calculate rule-based walkability scores for all subgraphs.\"\"\"\n",
    "    print(\"Stage 3: Calculating rule-based walkability scores...\")\n",
    "    for lie_name, subgraph_data in tqdm(subgraphs.items(), desc=\"Calculating walkability\"):\n",
    "        nodes_df = subgraph_data['nodes']\n",
    "        nodes_df = compute_walkability_scores(nodes_df)\n",
    "        subgraph_data['nodes'] = nodes_df\n",
    "\n",
    "        neighborhood_walkability = nodes_df[nodes_df['type'] == 'neighborhood']['walkability_rule']\n",
    "        if not neighborhood_walkability.empty:\n",
    "            walkability_value = neighborhood_walkability.iloc[0]\n",
    "            neighborhoods_gdf.loc[neighborhoods_gdf['LIE_NAME'] == lie_name, 'walkability_rule'] = walkability_value\n",
    "\n",
    "    return subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 4: GNN Model Integration\n",
    "This stage integrates a GNN model to predict walkability scores, enhancing the rule-based approach with machine learning using PyTorch Geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNWalkability(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network for walkability prediction.\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNWalkability, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def prepare_gnn_data(subgraphs):\n",
    "    \"\"\"Prepare graph data for GNN training.\"\"\"\n",
    "    data_list = []\n",
    "    for lie_name, subgraph_data in subgraphs.items():\n",
    "        nodes_df = subgraph_data['nodes'].to_pandas()\n",
    "        edges_df = subgraph_data['edges'].to_pandas() if subgraph_data['edges'] is not None else pd.DataFrame()\n",
    "\n",
    "        # Node features\n",
    "        feature_cols = ['land_use_residential_percent', 'land_use_commercial_percent', \n",
    "                        'land_use_education_percent', 'ndvi_mean', 'tree_count', 'transit_count']\n",
    "        nodes_df[feature_cols] = nodes_df[feature_cols].fillna(0)\n",
    "        x = torch.tensor(nodes_df[feature_cols].values, dtype=torch.float)\n",
    "\n",
    "        # Edge index\n",
    "        if not edges_df.empty:\n",
    "            edge_index = torch.tensor(edges_df[['src', 'dst']].values.T, dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.tensor([[], []], dtype=torch.long)  # Empty edge index\n",
    "\n",
    "        # Labels (rule-based walkability)\n",
    "        y = torch.tensor(nodes_df['walkability_rule'].values, dtype=torch.float)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def train_gnn_model(data_list):\n",
    "    \"\"\"Train the GNN model.\"\"\"\n",
    "    print(\"Stage 4: Training GNN model...\")\n",
    "    model = GCNWalkability(in_channels=6, hidden_channels=64, out_channels=1)  # 6 features\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in tqdm(range(200), desc=\"Training GNN\"):\n",
    "        for data in data_list:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_walkability(subgraphs, model):\n",
    "    \"\"\"Predict walkability scores using the trained GNN.\"\"\"\n",
    "    for lie_name, subgraph_data in subgraphs.items():\n",
    "        nodes_df = subgraph_data['nodes'].to_pandas()\n",
    "        data = prepare_gnn_data({lie_name: subgraph_data})[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(data.x, data.edge_index)\n",
    "        nodes_df['walkability_gnn'] = pred.numpy().flatten()\n",
    "        subgraph_data['nodes'] = cudf.from_pandas(nodes_df)\n",
    "    return subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 5: Interactive Visualization\n",
    "This stage creates an interactive Kepler.gl map, allowing users to visualize and modify the urban environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "\n",
    "# Replace with your Mapbox token\n",
    "MAPBOX_ACCESS_TOKEN = \"your_mapbox_access_token_here\"\n",
    "\n",
    "def create_interactive_map(subgraphs, data):\n",
    "    \"\"\"Generate an interactive Kepler.gl map.\"\"\"\n",
    "    print(\"Stage 5: Generating interactive Kepler.gl map...\")\n",
    "    neighborhoods_gdf = data['neighborhoods'].to_crs('EPSG:4326')\n",
    "\n",
    "    # Update neighborhoods with walkability scores\n",
    "    for lie_name, subgraph_data in subgraphs.items():\n",
    "        nodes_df = subgraph_data['nodes'].to_pandas()\n",
    "        neigh_data = nodes_df[nodes_df['type'] == 'neighborhood'].iloc[0]\n",
    "        neighborhoods_gdf.loc[neighborhoods_gdf['LIE_NAME'] == lie_name, 'walkability_rule'] = neigh_data['walkability_rule']\n",
    "        neighborhoods_gdf.loc[neighborhoods_gdf['LIE_NAME'] == lie_name, 'walkability_gnn'] = neigh_data['walkability_gnn']\n",
    "\n",
    "    geojson_data = neighborhoods_gdf.to_json()\n",
    "\n",
    "    map_1 = KeplerGl(height=600, width=800, mapbox_api_access_token=MAPBOX_ACCESS_TOKEN)\n",
    "    map_1.add_data(data=geojson_data, name=\"Neighborhoods\")\n",
    "\n",
    "    output_path = os.path.join(\"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data\", \"walkability_map_city_level.html\")\n",
    "    map_1.save_to_html(file_name=output_path)\n",
    "    print(f\"Interactive Kepler.gl map saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Execution\n",
    "This section ties all stages together in a main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: Loading and preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating geometries for neighborhoods...\n",
      "neighborhoods after validation: 456 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:  33%|███▎      | 2/6 [00:01<00:03,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating geometries for buildings...\n",
      "buildings after validation: 74306 rows\n",
      "Validating geometries for roads...\n",
      "roads after validation: 81444 rows\n",
      "roads_gdf columns after adding length_m: ['class', 'geometry', 'length_m']\n",
      "Validating geometries for trees...\n",
      "trees after validation: 3399 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:  83%|████████▎ | 5/6 [00:01<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating geometries for transit...\n",
      "transit after validation: 6844 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 6/6 [00:02<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating geometries for urban_masterplan...\n",
      "urban_masterplan after validation: 15392 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2: Building graph network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building subgraphs: 100%|██████████| 456/456 [00:57<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3: Calculating rule-based walkability scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating walkability: 100%|██████████| 454/454 [00:38<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 4: Training GNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GNN: 100%|██████████| 200/200 [01:50<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 5: Generating interactive Kepler.gl map...\n",
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n",
      "Map saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/walkability_map_city_level.html!\n",
      "Interactive Kepler.gl map saved at /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/walkability_map_city_level.html\n",
      "Analysis completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the full walkability analysis pipeline.\"\"\"\n",
    "    try:\n",
    "        # Stage 1\n",
    "        data = load_and_prepare_data()\n",
    "\n",
    "        # Stage 2\n",
    "        subgraphs, road_network_nodes = build_graph(data)\n",
    "\n",
    "        # Stage 3\n",
    "        subgraphs = calculate_walkability(subgraphs, data['neighborhoods'])\n",
    "\n",
    "        # Stage 4\n",
    "        data_list = prepare_gnn_data(subgraphs)\n",
    "        gnn_model = train_gnn_model(data_list)\n",
    "        subgraphs = predict_walkability(subgraphs, gnn_model)\n",
    "\n",
    "        # Stage 5\n",
    "        create_interactive_map(subgraphs, data)\n",
    "\n",
    "        print(\"Analysis completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
