{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a986f754",
   "metadata": {},
   "source": [
    "Cell 0: CUDA Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "dc2c30cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02.02 25.02.00\n"
     ]
    }
   ],
   "source": [
    "import cudf, cugraph\n",
    "print(cudf.__version__, cugraph.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac3ad7",
   "metadata": {},
   "source": [
    "Cell 1: Imports ,Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e388b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import logging\n",
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cugraph\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, BatchNorm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from shapely import make_valid\n",
    "from shapely.errors import GEOSException\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "# Plotting configuration\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'Noto Serif CJK TC', 'Noto Sans Mono CJK TC', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Directory and file paths\n",
    "BASE_DIR = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data\"\n",
    "LANDUSE_NDVI_PATH = os.path.join(BASE_DIR, \"neighborhoods_with_ndvi_numerical_corrected.geojson\")\n",
    "OSM_BUILDINGS_PATH = os.path.join(BASE_DIR, \"Taipei_Buildings_fulldata.geojson\")\n",
    "OSM_ROADS_PATH = os.path.join(BASE_DIR, \"taipei_segments_cleaned_verified.geoparquet\")\n",
    "OSM_TREES_PATH = os.path.join(BASE_DIR, \"taipei_land.geoparquet\")\n",
    "OSM_TRANSIT_PATH = os.path.join(BASE_DIR, \"taipei_infrastructure.geoparquet\")\n",
    "URBAN_MASTERPLAN_PATH = os.path.join(BASE_DIR, \"Taipei_urban_masterplan.geojson\")\n",
    "ACCIDENTS_PATH = os.path.join(BASE_DIR, \"2023_accidents.geojson\")\n",
    "POPULATION_PATH = os.path.join(BASE_DIR, \"population_corrected.json\")\n",
    "SUBGRAPH_DIR = os.path.join(BASE_DIR, \"subgraphs\")\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
    "INTERSECTION_CACHE_PATH = os.path.join(BASE_DIR, \"neighborhoods_with_intersections.geoparquet\")\n",
    "GRAPH_NODES_CACHE_PATH = os.path.join(BASE_DIR, \"graph_nodes.parquet\")\n",
    "GRAPH_EDGES_CACHE_PATH = os.path.join(BASE_DIR, \"graph_edges.parquet\")\n",
    "GRAPH_NODE_ID_CACHE_PATH = os.path.join(BASE_DIR, \"graph_node_id_to_index.json\")\n",
    "GRAPH_DATA_HASH_PATH = os.path.join(BASE_DIR, \"graph_data_hash.txt\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Constants for spatial analysis\n",
    "BUFFER_DISTANCE = 10  # Meters, buffer distance for border sharing of accidents (tunable based on spatial resolution)\n",
    "MIN_ROAD_LENGTH = 10  # Meters, minimum road length to avoid inflated accident density (tunable based on dataset)\n",
    "\n",
    "# Land use category priorities for area assignment\n",
    "CATEGORY_PRIORITY = {\n",
    "    'City_Open_Area': 10,\n",
    "    'Pedestrian': 9,\n",
    "    'Public_Transportation': 8,\n",
    "    'Amenity': 7,\n",
    "    'Education': 6,\n",
    "    'Medical': 5,\n",
    "    'Commercial': 4,\n",
    "    'Residential': 3,\n",
    "    'Natural': 2,\n",
    "    'Road': 1,\n",
    "    'River': 1,\n",
    "    'Infrastructure': 1,\n",
    "    'Government': 1,\n",
    "    'Special_Zone': 1,\n",
    "    'Military': 1,\n",
    "    'Industrial': 1,\n",
    "    'Agriculture': 1\n",
    "}\n",
    "\n",
    "# Weights for land use diversity in walkability scoring\n",
    "land_use_weights = {\n",
    "    'city_open_area': 0.8,\n",
    "    'commercial': 0.7,\n",
    "    'infrastructure': 0.4,\n",
    "    'government': 0.5,\n",
    "    'public_transportation': 0.8,\n",
    "    'education': 0.7,\n",
    "    'medical': 0.6,\n",
    "    'amenity': 0.8,\n",
    "    'road': 0.3,\n",
    "    'pedestrian': 1.0,\n",
    "    'natural': 0.7,\n",
    "    'special_zone': 0.4,\n",
    "    'river': 0.7,\n",
    "    'military': 0.2,\n",
    "    'residential': 0.6,\n",
    "    'industrial': 0.3,\n",
    "    'agriculture': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722f69a",
   "metadata": {},
   "source": [
    "Cell 2: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "713654c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def compute_road_type_accident_correlation(roads_gdf, neighborhoods_gdf, accidents_gdf):\n",
    "    \"\"\"\n",
    "    Compute correlation between OSM road types and accident density (accidents per km of road length).\n",
    "    Uses road class as a proxy for width, with ordinal ranking based on OSM hierarchy.\n",
    "    Generates bar, box, and scatter plots for visualization.\n",
    "    \"\"\"\n",
    "    logging.info(\"Computing correlation between road types and accident density...\")\n",
    "    \n",
    "    # Validate input data\n",
    "    validate_data(roads_gdf, ['class', 'geometry', 'length_m'], \"roads_gdf\")\n",
    "    validate_data(neighborhoods_gdf, ['LIE_NAME', 'geometry'], \"neighborhoods_gdf\")\n",
    "    validate_data(accidents_gdf, ['geometry'], \"accidents_gdf\")\n",
    "    \n",
    "    # Make local copies for roads and accidents to avoid modifying originals\n",
    "    roads_gdf_local = roads_gdf.copy()\n",
    "    accidents_gdf_local = accidents_gdf.copy()\n",
    "    \n",
    "    # Add unique identifier to accidents\n",
    "    accidents_gdf_local['accident_id'] = range(len(accidents_gdf_local))\n",
    "    \n",
    "    # Define width ranking\n",
    "    width_ranking = {\n",
    "        'motorway': 5, 'trunk': 5, 'primary': 4, 'secondary': 4, 'tertiary': 3,\n",
    "        'residential': 3, 'living_street': 3, 'service': 2, 'track': 2,\n",
    "        'path': 1, 'footway': 1, 'cycleway': 1, 'steps': 1, 'pedestrian': 1,\n",
    "        'unclassified': 0, 'bridleway': 0, 'unknown': 0\n",
    "    }\n",
    "    roads_gdf_local['width_rank'] = roads_gdf_local['class'].map(width_ranking).fillna(0).astype(int)\n",
    "    \n",
    "    # Buffer wider roads for accident assignment\n",
    "    roads_gdf_buffered = roads_gdf_local.copy()\n",
    "    roads_gdf_buffered['geometry'] = roads_gdf_buffered.apply(\n",
    "        lambda row: row['geometry'].buffer(5) if row['width_rank'] >= 4 else row['geometry'], axis=1\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Assigning accidents to nearest road...\")\n",
    "    accidents_gdf_local['geometry'] = accidents_gdf_local['geometry'].apply(fix_geometry)\n",
    "    accidents_gdf_local = accidents_gdf_local[accidents_gdf_local['geometry'].is_valid & ~accidents_gdf_local['geometry'].is_empty]\n",
    "    \n",
    "    if accidents_gdf_local.empty:\n",
    "        logging.warning(\"No valid accidents after geometry fixing.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Assign accidents to nearest road\n",
    "    nearest = gpd.sjoin_nearest(\n",
    "        accidents_gdf_local,\n",
    "        roads_gdf_buffered[['geometry', 'class', 'width_rank']],\n",
    "        how='left',\n",
    "        distance_col='distance'\n",
    "    )\n",
    "    nearest['weighted_distance'] = nearest['distance'] / (nearest['width_rank'].replace(0, 1) ** 2)\n",
    "    nearest = nearest.sort_values('weighted_distance').drop_duplicates(subset=['accident_id'], keep='first')\n",
    "    \n",
    "    matched_accidents = nearest[['accident_id', 'index_right']].copy()\n",
    "    matched_accidents.columns = ['accident_id', 'road_idx']\n",
    "    matched_accidents = matched_accidents.dropna(subset=['road_idx'])\n",
    "    matched_accidents['road_idx'] = matched_accidents['road_idx'].astype(int)\n",
    "    \n",
    "    logging.info(f\"Matched {len(matched_accidents)} accidents out of {len(accidents_gdf_local)}\")\n",
    "    \n",
    "    # Reassign accidents from footway/cycleway to wider roads if possible\n",
    "    footway_cycleway_accidents = matched_accidents[\n",
    "        matched_accidents['road_idx'].isin(\n",
    "            roads_gdf_local[roads_gdf_local['class'].isin(['footway', 'cycleway'])].index\n",
    "        )\n",
    "    ]\n",
    "    if not footway_cycleway_accidents.empty:\n",
    "        logging.info(f\"Reassigning {len(footway_cycleway_accidents)} accidents from footway/cycleway...\")\n",
    "        accidents_to_reassign = accidents_gdf_local[accidents_gdf_local['accident_id'].isin(footway_cycleway_accidents['accident_id'])].copy()\n",
    "        wider_roads = roads_gdf_buffered[roads_gdf_buffered['width_rank'] >= 4]\n",
    "        if not wider_roads.empty:\n",
    "            reassigned = gpd.sjoin_nearest(\n",
    "                accidents_to_reassign,\n",
    "                wider_roads[['geometry', 'class']],\n",
    "                how='left',\n",
    "                max_distance=10\n",
    "            )\n",
    "            reassigned_matches = reassigned[['accident_id', 'index_right']].copy()\n",
    "            reassigned_matches.columns = ['accident_id', 'road_idx']\n",
    "            reassigned_matches = reassigned_matches.dropna(subset=['road_idx'])\n",
    "            reassigned_matches['road_idx'] = reassigned_matches['road_idx'].astype(int)\n",
    "            matched_accidents = matched_accidents[~matched_accidents['accident_id'].isin(reassigned_matches['accident_id'])]\n",
    "            matched_accidents = pd.concat([matched_accidents, reassigned_matches], ignore_index=True)\n",
    "            logging.info(f\"Reassigned {len(reassigned_matches)} accidents to wider roads\")\n",
    "    \n",
    "    # Count accidents per road\n",
    "    accident_counts = matched_accidents.groupby('road_idx').size().reindex(roads_gdf_local.index, fill_value=0)\n",
    "    roads_gdf_local['accident_count'] = accident_counts\n",
    "    \n",
    "    logging.info(f\"Accidents by road type:\\n{roads_gdf_local.groupby('class')['accident_count'].sum()}\")\n",
    "    \n",
    "    # Filter roads by minimum length\n",
    "    roads_gdf_local = roads_gdf_local[roads_gdf_local['length_m'] >= MIN_ROAD_LENGTH]\n",
    "    \n",
    "    # Calculate accident density\n",
    "    roads_gdf_local['accident_density'] = roads_gdf_local['accident_count'] / (roads_gdf_local['length_m'] / 1000)\n",
    "    roads_gdf_local['accident_density'] = roads_gdf_local['accident_density'].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # Adjust density by width rank\n",
    "    roads_gdf_local['accident_density'] = roads_gdf_local['accident_density'] * (roads_gdf_local['width_rank'].replace(0, 1) / 5)\n",
    "    \n",
    "    logging.info(f\"Road type counts:\\n{roads_gdf_local['class'].value_counts()}\")\n",
    "    print(f\"Road type counts:\\n{roads_gdf_local['class'].value_counts()}\")\n",
    "    \n",
    "    # Summarize by road type\n",
    "    summary = roads_gdf_local.groupby('class').agg({\n",
    "        'length_m': 'sum',\n",
    "        'accident_count': 'sum',\n",
    "        'accident_density': 'mean',\n",
    "        'width_rank': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    summary = summary[summary['length_m'] > 1000]\n",
    "    summary = summary[summary['width_rank'] > 0]\n",
    "    \n",
    "    print(\"\\n--- Road Type Accident Density Summary ---\")\n",
    "    print(summary[['class', 'length_m', 'accident_count', 'accident_density', 'width_rank']].round(2))\n",
    "    \n",
    "    if len(summary) >= 2:\n",
    "        corr, p_value = spearmanr(summary['width_rank'], summary['accident_density'])\n",
    "        logging.info(f\"Spearman's correlation between road width rank and accident density: {corr:.3f} (p-value: {p_value:.3f})\")\n",
    "        print(f\"Spearman's correlation: {corr:.3f} (p-value: {p_value:.3f})\")\n",
    "    else:\n",
    "        logging.warning(\"Insufficient road types for correlation analysis.\")\n",
    "        print(\"Insufficient road types for correlation analysis.\")\n",
    "    \n",
    "    # Compute average road accident density per neighborhood\n",
    "    logging.info(\"Computing average road accident density per neighborhood...\")\n",
    "    logging.info(f\"Roads bounds: {roads_gdf_local.total_bounds}\")\n",
    "    logging.info(f\"Neighborhoods bounds: {neighborhoods_gdf.total_bounds}\")\n",
    "    \n",
    "    roads_gdf_with_idx = roads_gdf_local[['geometry', 'class', 'length_m', 'width_rank', 'accident_density']].reset_index()\n",
    "    neighborhoods_gdf_with_idx = neighborhoods_gdf[['geometry', 'LIE_NAME']].reset_index()\n",
    "    \n",
    "    logging.info(f\"Roads DataFrame shape before join: {roads_gdf_with_idx.shape}\")\n",
    "    logging.info(f\"Neighborhoods DataFrame shape before join: {neighborhoods_gdf_with_idx.shape}\")\n",
    "    \n",
    "    # Perform spatial join\n",
    "    road_neighborhoods = gpd.sjoin(\n",
    "        roads_gdf_with_idx,\n",
    "        neighborhoods_gdf_with_idx,\n",
    "        how='left',\n",
    "        predicate='intersects'\n",
    "    )\n",
    "    logging.info(f\"Road-neighborhood join resulted in {len(road_neighborhoods)} matches with columns: {road_neighborhoods.columns.tolist()}\")\n",
    "    \n",
    "    if road_neighborhoods['LIE_NAME'].isna().all():\n",
    "        logging.warning(\"No roads intersect with neighborhoods. Checking for geometry validity and CRS mismatch...\")\n",
    "        # Check CRS\n",
    "        logging.info(f\"Roads CRS: {roads_gdf_with_idx.crs}\")\n",
    "        logging.info(f\"Neighborhoods CRS: {neighborhoods_gdf_with_idx.crs}\")\n",
    "        # Check geometry validity\n",
    "        logging.info(f\"Roads geometry validity: {roads_gdf_with_idx.geometry.is_valid.all()}\")\n",
    "        logging.info(f\"Neighborhoods geometry validity: {neighborhoods_gdf_with_idx.geometry.is_valid.all()}\")\n",
    "        \n",
    "        # Fix geometries if necessary\n",
    "        roads_gdf_with_idx['geometry'] = roads_gdf_with_idx['geometry'].apply(fix_geometry)\n",
    "        neighborhoods_gdf_with_idx['geometry'] = neighborhoods_gdf_with_idx['geometry'].apply(fix_geometry)\n",
    "        \n",
    "        # Reproject if CRS mismatch\n",
    "        target_crs = 'EPSG:3826'\n",
    "        if roads_gdf_with_idx.crs != target_crs:\n",
    "            logging.info(f\"Reprojecting roads to {target_crs}\")\n",
    "            roads_gdf_with_idx = roads_gdf_with_idx.to_crs(target_crs)\n",
    "        if neighborhoods_gdf_with_idx.crs != target_crs:\n",
    "            logging.info(f\"Reprojecting neighborhoods to {target_crs}\")\n",
    "            neighborhoods_gdf_with_idx = neighborhoods_gdf_with_idx.to_crs(target_crs)\n",
    "        \n",
    "        # Retry spatial join\n",
    "        road_neighborhoods = gpd.sjoin(\n",
    "            roads_gdf_with_idx,\n",
    "            neighborhoods_gdf_with_idx,\n",
    "            how='left',\n",
    "            predicate='intersects'\n",
    "        )\n",
    "        logging.info(f\"Retried road-neighborhood join resulted in {len(road_neighborhoods)} matches\")\n",
    "        \n",
    "        if road_neighborhoods['LIE_NAME'].isna().all():\n",
    "            logging.warning(\"Still no intersections found. Buffering geometries...\")\n",
    "            roads_buffered = roads_gdf_with_idx.copy()\n",
    "            neighborhoods_buffered = neighborhoods_gdf_with_idx.copy()\n",
    "            roads_buffered['geometry'] = roads_buffered['geometry'].buffer(50)\n",
    "            neighborhoods_buffered['geometry'] = neighborhoods_buffered['geometry'].buffer(50)\n",
    "            \n",
    "            road_neighborhoods = gpd.sjoin(\n",
    "                roads_buffered,\n",
    "                neighborhoods_buffered,\n",
    "                how='left',\n",
    "                predicate='intersects'\n",
    "            )\n",
    "            logging.info(f\"Buffered road-neighborhood join resulted in {len(road_neighborhoods)} matches\")\n",
    "            \n",
    "            if road_neighborhoods['LIE_NAME'].isna().all():\n",
    "                logging.error(\"No intersections found even after buffering. Assigning default 0.\")\n",
    "                neighborhoods_gdf['avg_road_accident_density'] = 0\n",
    "            else:\n",
    "                avg_accident_density = road_neighborhoods.groupby('LIE_NAME')['accident_density'].mean()\n",
    "                avg_accident_density = avg_accident_density.reindex(neighborhoods_gdf['LIE_NAME'], fill_value=0)\n",
    "                neighborhoods_gdf['avg_road_accident_density'] = avg_accident_density.fillna(0)\n",
    "        else:\n",
    "            avg_accident_density = road_neighborhoods.groupby('LIE_NAME')['accident_density'].mean()\n",
    "            avg_accident_density = avg_accident_density.reindex(neighborhoods_gdf['LIE_NAME'], fill_value=0)\n",
    "            neighborhoods_gdf['avg_road_accident_density'] = avg_accident_density.fillna(0)\n",
    "    else:\n",
    "        avg_accident_density = road_neighborhoods.groupby('LIE_NAME')['accident_density'].mean()\n",
    "        avg_accident_density = avg_accident_density.reindex(neighborhoods_gdf['LIE_NAME'], fill_value=0)\n",
    "        neighborhoods_gdf['avg_road_accident_density'] = avg_accident_density.fillna(0)\n",
    "    \n",
    "    assigned_count = sum(~neighborhoods_gdf['avg_road_accident_density'].isna())\n",
    "    logging.info(f\"Assigned avg_road_accident_density to {assigned_count} neighborhoods\")\n",
    "    logging.info(f\"Avg road accident density stats:\\n{neighborhoods_gdf['avg_road_accident_density'].describe()}\")\n",
    "    \n",
    "    # Generate plots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    summary_sorted = summary.sort_values('width_rank', ascending=False)\n",
    "    sns.barplot(data=summary_sorted, x='class', y='accident_density', hue='width_rank', dodge=False)\n",
    "    plt.xlabel('Road Type')\n",
    "    plt.ylabel('Mean Accident Density (Accidents per km)')\n",
    "    plt.title('Mean Accident Density by Road Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Width Rank')\n",
    "    plt.tight_layout()\n",
    "    bar_path = os.path.join(BASE_DIR, 'road_type_accident_bar.png')\n",
    "    plt.savefig(bar_path)\n",
    "    plt.close()\n",
    "    logging.info(f\"Bar chart saved to {bar_path}\")\n",
    "    print(f\"Bar chart saved to {bar_path}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=roads_gdf_local[roads_gdf_local['class'].isin(summary['class'])], \n",
    "                x='class', y='accident_density', hue='width_rank', dodge=False)\n",
    "    plt.xlabel('Road Type')\n",
    "    plt.ylabel('Accident Density (Accidents per km)')\n",
    "    plt.title('Distribution of Accident Density by Road Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yscale('log')\n",
    "    plt.legend(title='Width Rank')\n",
    "    plt.tight_layout()\n",
    "    box_path = os.path.join(BASE_DIR, 'road_type_accident_box.png')\n",
    "    plt.savefig(box_path)\n",
    "    plt.close()\n",
    "    logging.info(f\"Box chart saved to {box_path}\")\n",
    "    print(f\"Box chart saved to {box_path}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=summary, x='width_rank', y='accident_density', \n",
    "                    size='length_m', sizes=(50, 500), hue='class', style='class', alpha=0.7)\n",
    "    z = np.polyfit(summary['width_rank'], summary['accident_density'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(summary['width_rank'], p(summary['width_rank']), \"r--\", alpha=0.5)\n",
    "    plt.xlabel('Road Width Rank (1=Path, 5=Motorway)')\n",
    "    plt.ylabel('Mean Accident Density (Accidents per km)')\n",
    "    plt.title('Road Type vs. Accident Density')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    scatter_path = os.path.join(BASE_DIR, 'road_type_accident_scatter.png')\n",
    "    plt.savefig(scatter_path)\n",
    "    plt.close()\n",
    "    logging.info(f\"Scatter plot saved to {scatter_path}\")\n",
    "    print(f\"Scatter plot saved to {scatter_path}\")\n",
    "    \n",
    "    top_types = summary.nlargest(3, 'accident_density')[['class', 'accident_density']]\n",
    "    logging.info(f\"Top 3 road types by accident density:\\n{top_types.round(2)}\")\n",
    "    print(f\"Top 3 road types by accident density:\\n{top_types.round(2)}\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ae081",
   "metadata": {},
   "source": [
    "Cell 3: Walkability Computation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3b05a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_walkability_components(neighborhoods_gdf, sample_size=5):\n",
    "    \"\"\"\n",
    "    Compute walkability components for a sample of neighborhoods.\n",
    "    \n",
    "    Args:\n",
    "        neighborhoods_gdf (gpd.GeoDataFrame): GeoDataFrame of neighborhoods.\n",
    "        sample_size (int): Number of neighborhoods to sample.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with walkability components for sampled neighborhoods.\n",
    "    \"\"\"\n",
    "    if not all(col in neighborhoods_gdf.columns for col in ['ndvi_mean', 'tree_count', 'transit_count', 'intersection_density', 'accident_count', 'area_km2', 'avg_road_accident_density', 'elderly_percentage']):\n",
    "        logging.error(\"Required columns missing in neighborhoods_gdf for walkability computation.\")\n",
    "        raise KeyError(\"Missing required columns in neighborhoods_gdf.\")\n",
    "    \n",
    "    sample_gdf = neighborhoods_gdf.sample(min(sample_size, len(neighborhoods_gdf)), random_state=42)\n",
    "    \n",
    "    components = {\n",
    "        'LIE_NAME': [],\n",
    "        'land_use_diversity': [],\n",
    "        'green_space_score': [],\n",
    "        'transit_score': [],\n",
    "        'road_connectivity': [],\n",
    "        'safety_score': [],\n",
    "        'elderly_accessibility': [],\n",
    "        'pedestrian_infrastructure_score': [],\n",
    "        'walkability_score': [],\n",
    "        'walkability_category': []\n",
    "    }\n",
    "    \n",
    "    ndvi_min, ndvi_max = neighborhoods_gdf['ndvi_mean'].min(), neighborhoods_gdf['ndvi_mean'].max()\n",
    "    tree_min, tree_max = neighborhoods_gdf['tree_count'].min(), neighborhoods_gdf['tree_count'].max()\n",
    "    transit_min, transit_max = neighborhoods_gdf['transit_count'].min(), neighborhoods_gdf['transit_count'].max()\n",
    "    intersection_density_min = neighborhoods_gdf['intersection_density'].min()\n",
    "    intersection_density_max = neighborhoods_gdf['intersection_density'].max()\n",
    "    accident_count_min, accident_count_max = neighborhoods_gdf['accident_count'].min(), neighborhoods_gdf['accident_count'].max()\n",
    "    accident_density_max = neighborhoods_gdf['avg_road_accident_density'].max() if not neighborhoods_gdf['avg_road_accident_density'].isna().all() else 1.0\n",
    "    pedestrian_road_max = neighborhoods_gdf.get('pedestrian_road_density', pd.Series(0)).max() or 1.0\n",
    "    \n",
    "    accident_count_density = neighborhoods_gdf['accident_count'] / neighborhoods_gdf['area_km2'].replace(0, 1e-6)\n",
    "    accident_count_density_max = accident_count_density.max() if accident_count_density.max() > 0 else 1.0\n",
    "    \n",
    "    for idx, row in sample_gdf.iterrows():\n",
    "        land_use_cols = [f\"land_use_{category.lower()}_percent\" for category in CATEGORY_PRIORITY.keys()]\n",
    "        land_use_values = [row.get(col, 0.1) / 100 for col in land_use_cols]  # Default to 0.1 (10%) if missing\n",
    "        logging.debug(f\"LIE_NAME: {row['LIE_NAME']}, Land use values: {land_use_values}\")\n",
    "        land_use_weights_list = [land_use_weights.get(category.lower(), 1.0) for category in CATEGORY_PRIORITY.keys()]\n",
    "        weighted_values = [p * w for p, w in zip(land_use_values, land_use_weights_list) if p > 0]\n",
    "        if not weighted_values:\n",
    "            weighted_values = [1.0 / len(land_use_values)] * len(land_use_values)\n",
    "        total = sum(weighted_values)\n",
    "        if total > 0:\n",
    "            weighted_values = [v / total for v in weighted_values]\n",
    "            entropy = -np.sum([p * np.log2(p + 1e-10) for p in weighted_values])\n",
    "            max_entropy = np.log2(len(weighted_values))\n",
    "            land_use_diversity = entropy / max_entropy if max_entropy > 0 else 0.5\n",
    "        else:\n",
    "            land_use_diversity = 0.5\n",
    "        \n",
    "        ndvi_normalized = ((row['ndvi_mean'] - ndvi_min) / (ndvi_max - ndvi_min + 1e-6)) if (ndvi_max - ndvi_min) > 0 else 0\n",
    "        tree_density = row['tree_count'] / row['area_km2'] if row['area_km2'] > 0 else 0\n",
    "        tree_density_max = (neighborhoods_gdf['tree_count'] / neighborhoods_gdf['area_km2']).replace(0, 1e-6).max()\n",
    "        tree_density_normalized = (tree_density / (tree_density_max + 1e-6)) if tree_density_max > 0 else 0\n",
    "        open_area = row.get('land_use_city_open_area_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        green_space_score = (0.4 * ndvi_normalized + 0.3 * tree_density_normalized + 0.3 * open_area)\n",
    "        \n",
    "        transit_raw = (row['transit_count'] - transit_min) / (transit_max - transit_min + 1e-6) if (transit_max - transit_min) > 0 else 0\n",
    "        transit_score = transit_raw\n",
    "        \n",
    "        intersection_density = row['intersection_density']\n",
    "        intersection_density_normalized = (intersection_density - intersection_density_min) / (intersection_density_max - intersection_density_min + 1e-6) if (intersection_density_max - intersection_density_min) > 0 else 0\n",
    "        road_connectivity = intersection_density_normalized\n",
    "        \n",
    "        accident_count_density = row['accident_count'] / row['area_km2'] if row['area_km2'] > 0 else 0\n",
    "        accident_count_density = min(accident_count_density, accident_count_density_max * 0.5)\n",
    "        safety_score_count = 1 - (accident_count_density / (accident_count_density_max + 1e-6)) if accident_count_density_max > 0 else 1\n",
    "        accident_density = row['avg_road_accident_density'] if pd.notna(row['avg_road_accident_density']) else 0\n",
    "        safety_score_roads = 1 - (accident_density / (accident_density_max + 1e-6)) if accident_density_max > 0 else 1\n",
    "        pedestrian_roads = row.get('pedestrian_road_density', 0.0)\n",
    "        pedestrian_roads_safety = min(pedestrian_roads / (pedestrian_road_max + 1e-6), 1.0) if pedestrian_road_max > 0 else 0.1\n",
    "        safety_score = (0.3 * safety_score_count + 0.3 * safety_score_roads + 0.4 * pedestrian_roads_safety) if row['accident_count'] != 0 else (0.5 * safety_score_roads + 0.5 * pedestrian_roads_safety)\n",
    "        safety_score = np.clip(safety_score, 0, 1)\n",
    "        \n",
    "        elderly_percentage = row['elderly_percentage'] / 100\n",
    "        medical_access = row.get('land_use_medical_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        elderly_accessibility = 0.3 * elderly_percentage + 0.4 * medical_access + 0.3 * pedestrian_roads_safety\n",
    "        elderly_accessibility = np.clip(elderly_accessibility, 0, 1)\n",
    "        \n",
    "        pedestrian_road_score = pedestrian_roads / (pedestrian_road_max + 1e-6) if pedestrian_road_max > 0 else 0\n",
    "        amenity_access = row.get('land_use_amenity_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        pedestrian_infrastructure_score = 0.5 * pedestrian_road_score + 0.5 * amenity_access\n",
    "        pedestrian_infrastructure_score = np.clip(pedestrian_infrastructure_score, 0, 1)\n",
    "        \n",
    "        base_score = (\n",
    "            0.35 * land_use_diversity +\n",
    "            0.35 * green_space_score +\n",
    "            0.15 * transit_score +\n",
    "            0.10 * road_connectivity +\n",
    "            0.05 * pedestrian_infrastructure_score\n",
    "        )\n",
    "        safety_modifier = 0.7 + 0.3 * safety_score\n",
    "        elderly_modifier = 0.9 + 0.1 * elderly_accessibility\n",
    "        walkability_score = base_score * safety_modifier * elderly_modifier\n",
    "        walkability_score = np.clip(walkability_score, 0, 1)\n",
    "        \n",
    "        if pd.isna(walkability_score):\n",
    "            logging.warning(f\"Walkability score is NaN for {row['LIE_NAME']}. Setting to 0.\")\n",
    "            walkability_score = 0\n",
    "            category = 'low'\n",
    "        elif walkability_score < 0.33:\n",
    "            category = 'low'\n",
    "        elif walkability_score < 0.66:\n",
    "            category = 'medium'\n",
    "        else:\n",
    "            category = 'high'\n",
    "        \n",
    "        components['LIE_NAME'].append(row['LIE_NAME'])\n",
    "        components['land_use_diversity'].append(land_use_diversity)\n",
    "        components['green_space_score'].append(green_space_score)\n",
    "        components['transit_score'].append(transit_score)\n",
    "        components['road_connectivity'].append(road_connectivity)\n",
    "        components['safety_score'].append(safety_score)\n",
    "        components['elderly_accessibility'].append(elderly_accessibility)\n",
    "        components['pedestrian_infrastructure_score'].append(pedestrian_infrastructure_score)\n",
    "        components['walkability_score'].append(walkability_score)\n",
    "        components['walkability_category'].append(category)\n",
    "    \n",
    "    return pd.DataFrame(components)\n",
    "\n",
    "def compute_walkability_components_all(neighborhoods_df, data):\n",
    "    \"\"\"\n",
    "    Compute walkability components for all neighborhoods.\n",
    "    \n",
    "    Args:\n",
    "        neighborhoods_df (gpd.GeoDataFrame): GeoDataFrame of neighborhoods.\n",
    "        data (dict): Dictionary containing roads and other datasets.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with walkability components for all neighborhoods.\n",
    "    \"\"\"\n",
    "    if neighborhoods_df.empty:\n",
    "        logging.error(\"neighborhoods_df is empty.\")\n",
    "        raise ValueError(\"neighborhoods_df cannot be empty.\")\n",
    "    if 'roads' not in data or data['roads'].empty:\n",
    "        logging.error(\"Roads data is missing or empty.\")\n",
    "        raise ValueError(\"Roads data cannot be empty.\")\n",
    "    \n",
    "    required_cols = ['LIE_NAME', 'geometry', 'ndvi_mean', 'tree_count', 'transit_count', 'intersection_density', \n",
    "                     'accident_count', 'area_km2', 'avg_road_accident_density', 'elderly_percentage']\n",
    "    missing_cols = [col for col in required_cols if col not in neighborhoods_df.columns]\n",
    "    if missing_cols:\n",
    "        logging.error(f\"Missing columns in neighborhoods_df: {missing_cols}\")\n",
    "        raise KeyError(f\"Missing columns in neighborhoods_df: {missing_cols}\")\n",
    "    \n",
    "    for col in required_cols:\n",
    "        if col == 'geometry':\n",
    "            null_count = neighborhoods_df[col].isna().sum()\n",
    "            invalid_count = (~neighborhoods_df[col].is_valid).sum()\n",
    "            logging.info(f\"Geometry column: {null_count} nulls, {invalid_count} invalid geometries.\")\n",
    "        else:\n",
    "            null_count = neighborhoods_df[col].isna().sum()\n",
    "            zero_count = (neighborhoods_df[col] == 0).sum()\n",
    "            logging.info(f\"{col}: {null_count} nulls, {zero_count} zeros.\")\n",
    "    \n",
    "    land_use_cols = [f\"land_use_{category.lower()}_percent\" for category in CATEGORY_PRIORITY.keys()]\n",
    "    for col in land_use_cols:\n",
    "        if col not in neighborhoods_df.columns:\n",
    "            logging.warning(f\"Land use column {col} not found in neighborhoods_df. Using default value 0.1.\")\n",
    "            neighborhoods_df[col] = 0.1  # Default value for missing land use columns\n",
    "        else:\n",
    "            logging.info(f\"{col} stats:\\n{neighborhoods_df[col].describe()}\")\n",
    "    \n",
    "    neighborhoods_df = neighborhoods_df.copy()\n",
    "    neighborhoods_df = neighborhoods_df.to_crs('EPSG:3826')\n",
    "    roads_df = data['roads'].copy()\n",
    "    roads_df = roads_df.to_crs('EPSG:3826')\n",
    "    \n",
    "    neighborhoods_df['geometry'] = neighborhoods_df['geometry'].apply(fix_geometry)\n",
    "    invalid_geoms = neighborhoods_df[~neighborhoods_df.geometry.is_valid]\n",
    "    if not invalid_geoms.empty:\n",
    "        logging.warning(f\"Found {len(invalid_geoms)} invalid geometries in neighborhoods_df after fixing.\")\n",
    "        neighborhoods_df = neighborhoods_df[neighborhoods_df.geometry.is_valid]\n",
    "        if neighborhoods_df.empty:\n",
    "            logging.error(\"All geometries in neighborhoods_df are invalid after fixing.\")\n",
    "            raise ValueError(\"No valid geometries in neighborhoods_df.\")\n",
    "    \n",
    "    roads_df['geometry'] = roads_df['geometry'].apply(fix_geometry)\n",
    "    invalid_roads = roads_df[~roads_df.geometry.is_valid]\n",
    "    if not invalid_roads.empty:\n",
    "        logging.warning(f\"Found {len(invalid_roads)} invalid geometries in roads_df after fixing.\")\n",
    "        roads_df = roads_df[roads_df.geometry.is_valid]\n",
    "        if roads_df.empty:\n",
    "            logging.error(\"All geometries in roads_df are invalid after fixing.\")\n",
    "            raise ValueError(\"No valid geometries in roads_df.\")\n",
    "    \n",
    "    pedestrian_road_types = ['footway', 'pedestrian', 'cycleway']\n",
    "    pedestrian_roads_df = roads_df[roads_df['class'].isin(pedestrian_road_types)].copy()\n",
    "    logging.info(f\"Filtered {len(pedestrian_roads_df)} roads of types {pedestrian_road_types} out of {len(roads_df)} total roads.\")\n",
    "    \n",
    "    overlap = check_spatial_overlap(neighborhoods_df, pedestrian_roads_df, \"neighborhoods\", \"pedestrian_roads\")\n",
    "    pedestrian_roads = gpd.sjoin(\n",
    "        neighborhoods_df[['geometry', 'LIE_NAME']],\n",
    "        pedestrian_roads_df[['geometry', 'length_m']],\n",
    "        how='left', predicate='intersects'\n",
    "    )\n",
    "    if not overlap or pedestrian_roads['length_m'].isna().all():\n",
    "        logging.warning(\"No spatial overlap or matches between neighborhoods and pedestrian roads. Buffering geometries...\")\n",
    "        neighborhoods_buffered = neighborhoods_df.copy()\n",
    "        neighborhoods_buffered['geometry'] = neighborhoods_buffered['geometry'].buffer(50)\n",
    "        pedestrian_roads = gpd.sjoin(\n",
    "            neighborhoods_buffered[['geometry', 'LIE_NAME']],\n",
    "            pedestrian_roads_df[['geometry', 'length_m']],\n",
    "            how='left', predicate='intersects'\n",
    "        )\n",
    "    \n",
    "    logging.info(f\"Pedestrian roads join resulted in {len(pedestrian_roads)} matches.\")\n",
    "    pedestrian_roads['length_m'] = pedestrian_roads['length_m'].fillna(0)\n",
    "    pedestrian_road_lengths = pedestrian_roads.groupby('LIE_NAME')['length_m'].sum()\n",
    "    pedestrian_road_lengths = pedestrian_road_lengths.reindex(neighborhoods_df['LIE_NAME'], fill_value=0)\n",
    "    \n",
    "    neighborhoods_df['pedestrian_road_density'] = (pedestrian_road_lengths / 1000) / neighborhoods_df['area_km2'].replace(0, 1e-6)\n",
    "    logging.info(f\"Pedestrian road density stats:\\n{neighborhoods_df['pedestrian_road_density'].describe()}\")\n",
    "    \n",
    "    components = {\n",
    "        'LIE_NAME': [],\n",
    "        'land_use_diversity': [],\n",
    "        'green_space_score': [],\n",
    "        'transit_score': [],\n",
    "        'road_connectivity': [],\n",
    "        'safety_score': [],\n",
    "        'elderly_accessibility': [],\n",
    "        'pedestrian_infrastructure_score': [],\n",
    "        'walkability_score': [],\n",
    "        'walkability_category': []\n",
    "    }\n",
    "    \n",
    "    ndvi_min, ndvi_max = neighborhoods_df['ndvi_mean'].min(), neighborhoods_df['ndvi_mean'].max()\n",
    "    tree_min, tree_max = neighborhoods_df['tree_count'].min(), neighborhoods_df['tree_count'].max()\n",
    "    transit_min, transit_max = neighborhoods_df['transit_count'].min(), neighborhoods_df['transit_count'].max()\n",
    "    intersection_density_min = neighborhoods_df['intersection_density'].min()\n",
    "    intersection_density_max = neighborhoods_df['intersection_density'].max()\n",
    "    accident_count_min, accident_count_max = neighborhoods_df['accident_count'].min(), neighborhoods_df['accident_count'].max()\n",
    "    accident_density_max = neighborhoods_df['avg_road_accident_density'].max() if not neighborhoods_df['avg_road_accident_density'].isna().all() else 1.0\n",
    "    pedestrian_road_max = neighborhoods_df['pedestrian_road_density'].max() if neighborhoods_df['pedestrian_road_density'].max() > 0 else 1.0\n",
    "    \n",
    "    accident_count_density = neighborhoods_df['accident_count'] / neighborhoods_df['area_km2'].replace(0, 1e-6)\n",
    "    accident_count_density_max = accident_count_density.max() if accident_count_density.max() > 0 else 1.0\n",
    "    \n",
    "    for idx, row in tqdm(neighborhoods_df.iterrows(), total=len(neighborhoods_df), desc=\"Computing walkability scores\"):\n",
    "        land_use_cols = [f\"land_use_{category.lower()}_percent\" for category in CATEGORY_PRIORITY.keys()]\n",
    "        land_use_values = [row.get(col, 0.1) / 100 for col in land_use_cols]  # Default to 0.1 (10%) if missing\n",
    "        logging.debug(f\"LIE_NAME: {row['LIE_NAME']}, Land use values: {land_use_values}\")\n",
    "        land_use_weights_list = [land_use_weights.get(category.lower(), 1.0) for category in CATEGORY_PRIORITY.keys()]\n",
    "        weighted_values = [p * w for p, w in zip(land_use_values, land_use_weights_list) if p > 0]\n",
    "        if not weighted_values:\n",
    "            weighted_values = [1.0 / len(land_use_values)] * len(land_use_values)\n",
    "        total = sum(weighted_values)\n",
    "        if total > 0:\n",
    "            weighted_values = [v / total for v in weighted_values]\n",
    "            entropy = -np.sum([p * np.log2(p + 1e-10) for p in weighted_values])\n",
    "            max_entropy = np.log2(len(weighted_values))\n",
    "            land_use_diversity = entropy / max_entropy if max_entropy > 0 else 0.5\n",
    "        else:\n",
    "            land_use_diversity = 0.5\n",
    "        \n",
    "        ndvi_normalized = ((row['ndvi_mean'] - ndvi_min) / (ndvi_max - ndvi_min + 1e-6)) if (ndvi_max - ndvi_min) > 0 else 0\n",
    "        tree_density = row['tree_count'] / row['area_km2'] if row['area_km2'] > 0 else 0\n",
    "        tree_density_max = (neighborhoods_df['tree_count'] / neighborhoods_df['area_km2']).replace(0, 1e-6).max()\n",
    "        tree_density_normalized = (tree_density / (tree_density_max + 1e-6)) if tree_density_max > 0 else 0\n",
    "        open_area = row.get('land_use_city_open_area_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        green_space_score = (0.4 * ndvi_normalized + 0.3 * tree_density_normalized + 0.3 * open_area)\n",
    "        \n",
    "        transit_raw = (row['transit_count'] - transit_min) / (transit_max - transit_min + 1e-6) if (transit_max - transit_min) > 0 else 0\n",
    "        transit_score = transit_raw\n",
    "        \n",
    "        intersection_density = row['intersection_density']\n",
    "        intersection_density_normalized = (intersection_density - intersection_density_min) / (intersection_density_max - intersection_density_min + 1e-6) if (intersection_density_max - intersection_density_min) > 0 else 0\n",
    "        road_connectivity = intersection_density_normalized\n",
    "        \n",
    "        accident_count_density = row['accident_count'] / row['area_km2'] if row['area_km2'] > 0 else 0\n",
    "        accident_count_density = min(accident_count_density, accident_count_density_max * 0.5)\n",
    "        safety_score_count = 1 - (accident_count_density / (accident_count_density_max + 1e-6)) if accident_count_density_max > 0 else 1\n",
    "        accident_density = row['avg_road_accident_density'] if pd.notna(row['avg_road_accident_density']) else 0\n",
    "        safety_score_roads = 1 - (accident_density / (accident_density_max + 1e-6)) if accident_density_max > 0 else 1\n",
    "        pedestrian_roads = row.get('pedestrian_road_density', 0.0)\n",
    "        pedestrian_roads_safety = min(pedestrian_roads / (pedestrian_road_max + 1e-6), 1.0) if pedestrian_road_max > 0 else 0.1\n",
    "        safety_score = (0.3 * safety_score_count + 0.3 * safety_score_roads + 0.4 * pedestrian_roads_safety) if row['accident_count'] != 0 else (0.5 * safety_score_roads + 0.5 * pedestrian_roads_safety)\n",
    "        safety_score = np.clip(safety_score, 0, 1)\n",
    "        \n",
    "        elderly_percentage = row['elderly_percentage'] / 100\n",
    "        medical_access = row.get('land_use_medical_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        elderly_accessibility = 0.3 * elderly_percentage + 0.4 * medical_access + 0.3 * pedestrian_roads_safety\n",
    "        elderly_accessibility = np.clip(elderly_accessibility, 0, 1)\n",
    "        \n",
    "        pedestrian_road_score = pedestrian_roads / (pedestrian_road_max + 1e-6) if pedestrian_road_max > 0 else 0\n",
    "        amenity_access = row.get('land_use_amenity_percent', 0.1) / 100  # Default to 0.1 if missing\n",
    "        pedestrian_infrastructure_score = 0.5 * pedestrian_road_score + 0.5 * amenity_access\n",
    "        pedestrian_infrastructure_score = np.clip(pedestrian_infrastructure_score, 0, 1)\n",
    "        \n",
    "        base_score = (\n",
    "            0.35 * land_use_diversity +\n",
    "            0.35 * green_space_score +\n",
    "            0.15 * transit_score +\n",
    "            0.10 * road_connectivity +\n",
    "            0.05 * pedestrian_infrastructure_score\n",
    "        )\n",
    "        safety_modifier = 0.7 + 0.3 * safety_score\n",
    "        elderly_modifier = 0.9 + 0.1 * elderly_accessibility\n",
    "        walkability_score = base_score * safety_modifier * elderly_modifier\n",
    "        walkability_score = np.clip(walkability_score, 0, 1)\n",
    "        \n",
    "        if pd.isna(walkability_score):\n",
    "            logging.warning(f\"Walkability score is NaN for {row['LIE_NAME']}. Setting to 0.\")\n",
    "            walkability_score = 0\n",
    "            category = 'low'\n",
    "        elif walkability_score < 0.33:\n",
    "            category = 'low'\n",
    "        elif walkability_score < 0.66:\n",
    "            category = 'medium'\n",
    "        else:\n",
    "            category = 'high'\n",
    "        \n",
    "        components['LIE_NAME'].append(row['LIE_NAME'])\n",
    "        components['land_use_diversity'].append(land_use_diversity)\n",
    "        components['green_space_score'].append(green_space_score)\n",
    "        components['transit_score'].append(transit_score)\n",
    "        components['road_connectivity'].append(road_connectivity)\n",
    "        components['safety_score'].append(safety_score)\n",
    "        components['elderly_accessibility'].append(elderly_accessibility)\n",
    "        components['pedestrian_infrastructure_score'].append(pedestrian_infrastructure_score)\n",
    "        components['walkability_score'].append(walkability_score)\n",
    "        components['walkability_category'].append(category)\n",
    "    \n",
    "    df_components = pd.DataFrame(components)\n",
    "    logging.info(f\"Land use diversity distribution:\\n{df_components['land_use_diversity'].describe()}\")\n",
    "    logging.info(f\"Green space score distribution:\\n{df_components['green_space_score'].describe()}\")\n",
    "    logging.info(f\"Transit score distribution:\\n{df_components['transit_score'].describe()}\")\n",
    "    logging.info(f\"Road connectivity distribution:\\n{df_components['road_connectivity'].describe()}\")\n",
    "    logging.info(f\"Safety score distribution:\\n{df_components['safety_score'].describe()}\")\n",
    "    logging.info(f\"Elderly accessibility distribution:\\n{df_components['elderly_accessibility'].describe()}\")\n",
    "    logging.info(f\"Pedestrian infrastructure score distribution:\\n{df_components['pedestrian_infrastructure_score'].describe()}\")\n",
    "    logging.info(f\"Walkability score distribution:\\n{df_components['walkability_score'].describe()}\")\n",
    "    \n",
    "    return df_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d0683",
   "metadata": {},
   "source": [
    "Cell 4 Main Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c3d3ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely import make_valid\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    logging.info(\"Stage 1: Loading and preparing data...\")\n",
    "    \n",
    "    # Define file paths and their corresponding keys\n",
    "    data_files = {\n",
    "        'neighborhoods': LANDUSE_NDVI_PATH,\n",
    "        'buildings': OSM_BUILDINGS_PATH,\n",
    "        'roads': OSM_ROADS_PATH,\n",
    "        'trees': OSM_TREES_PATH,\n",
    "        'transit': OSM_TRANSIT_PATH,\n",
    "        'urban_masterplan': URBAN_MASTERPLAN_PATH,\n",
    "        'accidents': ACCIDENTS_PATH,\n",
    "        'population': POPULATION_PATH\n",
    "    }\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # Load data with progress bar\n",
    "    for key, path in tqdm(data_files.items(), desc=\"Loading files\"):\n",
    "        try:\n",
    "            if key == 'population':\n",
    "                with open(path, 'r') as f:\n",
    "                    data[key] = pd.DataFrame(json.load(f))\n",
    "                # Log columns of population_df to debug missing columns\n",
    "                logging.info(f\"Columns in population_df after loading: {list(data[key].columns)}\")\n",
    "            elif path.endswith('.geoparquet'):\n",
    "                data[key] = gpd.read_parquet(path)\n",
    "            else:\n",
    "                data[key] = gpd.read_file(path)\n",
    "            logging.info(f\"Loaded {key} with shape {data[key].shape}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load {key} from {path}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # Log columns of neighborhoods_gdf to debug missing 'area_km2'\n",
    "    neighborhoods_gdf = data['neighborhoods']\n",
    "    logging.info(f\"Columns in neighborhoods_gdf after loading: {list(neighborhoods_gdf.columns)}\")\n",
    "    \n",
    "    # Ensure all GeoDataFrames are in the same CRS\n",
    "    target_crs = 'EPSG:3826'\n",
    "    for key in ['neighborhoods', 'buildings', 'roads', 'trees', 'transit', 'urban_masterplan', 'accidents']:\n",
    "        if key in data and isinstance(data[key], gpd.GeoDataFrame):\n",
    "            if data[key].crs != target_crs:\n",
    "                data[key] = data[key].to_crs(target_crs)\n",
    "                logging.info(f\"Converted {key} to CRS {target_crs}\")\n",
    "    \n",
    "    # Fix geometries in all GeoDataFrames\n",
    "    for key in ['neighborhoods', 'buildings', 'roads', 'trees', 'transit', 'urban_masterplan', 'accidents']:\n",
    "        if key in data and isinstance(data[key], gpd.GeoDataFrame):\n",
    "            data[key]['geometry'] = data[key]['geometry'].apply(fix_geometry)\n",
    "            invalid_geoms = data[key][~data[key].geometry.is_valid]\n",
    "            if not invalid_geoms.empty:\n",
    "                logging.warning(f\"Found {len(invalid_geoms)} invalid geometries in {key} after fixing.\")\n",
    "                data[key] = data[key][data[key].geometry.is_valid]\n",
    "    \n",
    "    # Compute intersections for neighborhoods\n",
    "    logging.info(\"Computing intersections for neighborhoods...\")\n",
    "    roads_gdf = data['roads']\n",
    "    \n",
    "    # Log columns of roads_gdf to debug missing 'length_m'\n",
    "    logging.info(f\"Columns in roads_gdf after loading: {list(roads_gdf.columns)}\")\n",
    "    \n",
    "    # Extract endpoints from road segments\n",
    "    logging.info(\"Extracting endpoints from road segments...\")\n",
    "    endpoints = []\n",
    "    road_indices = []\n",
    "    for idx, row in tqdm(roads_gdf.iterrows(), total=len(roads_gdf), desc=\"Extracting endpoints\"):\n",
    "        geom = row['geometry']\n",
    "        if geom.geom_type == 'LineString':\n",
    "            coords = list(geom.coords)\n",
    "            start_point = Point(coords[0])\n",
    "            end_point = Point(coords[-1])\n",
    "            if start_point.is_valid and end_point.is_valid:\n",
    "                endpoints.extend([start_point, end_point])\n",
    "                road_indices.extend([idx, idx])\n",
    "        elif geom.geom_type == 'MultiLineString':\n",
    "            for line in geom.geoms:\n",
    "                coords = list(line.coords)\n",
    "                start_point = Point(coords[0])\n",
    "                end_point = Point(coords[-1])\n",
    "                if start_point.is_valid and end_point.is_valid:\n",
    "                    endpoints.extend([start_point, end_point])\n",
    "                    road_indices.extend([idx, idx])\n",
    "    \n",
    "    if not endpoints:\n",
    "        logging.warning(\"No valid endpoints extracted from road segments. Using fallback method for intersections.\")\n",
    "        neighborhoods_gdf = data['neighborhoods']\n",
    "        road_neighborhoods = gpd.sjoin(roads_gdf[['geometry']], neighborhoods_gdf[['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "        intersection_counts = road_neighborhoods.groupby('index_right').size()\n",
    "        neighborhoods_gdf['intersection_count'] = intersection_counts.reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "    else:\n",
    "        endpoints_gdf = gpd.GeoDataFrame({'geometry': endpoints, 'road_idx': road_indices}, crs=target_crs)\n",
    "        \n",
    "        # Create a spatial index for endpoints\n",
    "        endpoints_sindex = endpoints_gdf.sindex\n",
    "        \n",
    "        # Cluster endpoints to identify intersections (points shared by 3 or more roads)\n",
    "        logging.info(\"Building endpoint-to-road mapping...\")\n",
    "        endpoint_to_roads = {}\n",
    "        for idx, point in tqdm(endpoints_gdf.iterrows(), total=len(endpoints_gdf), desc=\"Building endpoint-to-road mapping\"):\n",
    "            point_geom = point['geometry']\n",
    "            road_idx = point['road_idx']\n",
    "            point_key = (round(point_geom.x, 6), round(point_geom.y, 6))  # Round to avoid floating-point precision issues\n",
    "            if point_key not in endpoint_to_roads:\n",
    "                endpoint_to_roads[point_key] = set()\n",
    "            endpoint_to_roads[point_key].add(road_idx)\n",
    "        \n",
    "        logging.info(\"Identifying intersections...\")\n",
    "        intersections = []\n",
    "        for point_key, road_ids in tqdm(endpoint_to_roads.items(), desc=\"Identifying intersections\"):\n",
    "            if len(road_ids) >= 3:  # Intersection if shared by 3 or more roads\n",
    "                intersections.append(Point(point_key))\n",
    "        \n",
    "        if not intersections:\n",
    "            logging.warning(\"No intersections found using endpoint clustering. Using fallback method.\")\n",
    "            neighborhoods_gdf = data['neighborhoods']\n",
    "            road_neighborhoods = gpd.sjoin(roads_gdf[['geometry']], neighborhoods_gdf[['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "            intersection_counts = road_neighborhoods.groupby('index_right').size()\n",
    "            neighborhoods_gdf['intersection_count'] = intersection_counts.reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "        else:\n",
    "            intersections_gdf = gpd.GeoDataFrame({'geometry': intersections}, crs=target_crs)\n",
    "            \n",
    "            # Count intersections per neighborhood\n",
    "            logging.info(\"Counting intersections per neighborhood...\")\n",
    "            neighborhoods_gdf = data['neighborhoods']\n",
    "            intersections_joined = gpd.sjoin(intersections_gdf, neighborhoods_gdf[['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "            intersection_counts = intersections_joined.groupby('index_right').size()\n",
    "            neighborhoods_gdf['intersection_count'] = intersection_counts.reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "    \n",
    "    # Compute or verify area_km2\n",
    "    if 'area_km2' not in neighborhoods_gdf.columns:\n",
    "        logging.warning(\"'area_km2' column missing in neighborhoods_gdf. Computing from geometry...\")\n",
    "        # Compute area in square meters, then convert to square kilometers\n",
    "        neighborhoods_gdf['area_m2'] = neighborhoods_gdf['geometry'].area\n",
    "        neighborhoods_gdf['area_km2'] = neighborhoods_gdf['area_m2'] / 1_000_000  # Convert m to km\n",
    "        logging.info(f\"Computed area_km2 stats:\\n{neighborhoods_gdf['area_km2'].describe()}\")\n",
    "    else:\n",
    "        logging.info(f\"area_km2 already present. Stats:\\n{neighborhoods_gdf['area_km2'].describe()}\")\n",
    "    \n",
    "    # Compute intersection density\n",
    "    neighborhoods_gdf['intersection_density'] = neighborhoods_gdf['intersection_count'] / neighborhoods_gdf['area_km2'].replace(0, 1e-6)\n",
    "    logging.info(f\"Intersection count stats:\\n{neighborhoods_gdf['intersection_count'].describe()}\")\n",
    "    logging.info(f\"Intersection density stats:\\n{neighborhoods_gdf['intersection_density'].describe()}\")\n",
    "    \n",
    "    # Cache the result\n",
    "    try:\n",
    "        neighborhoods_gdf.to_parquet(INTERSECTION_CACHE_PATH)\n",
    "        logging.info(f\"Saved neighborhoods with intersections to {INTERSECTION_CACHE_PATH}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save neighborhoods with intersections: {e}\")\n",
    "    \n",
    "    data['neighborhoods'] = neighborhoods_gdf\n",
    "    \n",
    "    # Compute tree count per neighborhood\n",
    "    logging.info(\"Computing tree count per neighborhood...\")\n",
    "    trees_gdf = data['trees']\n",
    "    trees_joined = gpd.sjoin(trees_gdf[['geometry']], data['neighborhoods'][['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "    tree_counts = trees_joined.groupby('index_right').size()\n",
    "    data['neighborhoods']['tree_count'] = tree_counts.reindex(data['neighborhoods'].index, fill_value=0)\n",
    "    \n",
    "    # Compute transit count per neighborhood\n",
    "    logging.info(\"Computing transit count per neighborhood...\")\n",
    "    transit_gdf = data['transit']\n",
    "    transit_joined = gpd.sjoin(transit_gdf[['geometry']], data['neighborhoods'][['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "    transit_counts = transit_joined.groupby('index_right').size()\n",
    "    data['neighborhoods']['transit_count'] = transit_counts.reindex(data['neighborhoods'].index, fill_value=0)\n",
    "    \n",
    "    # Compute accident count per neighborhood\n",
    "    logging.info(\"Computing accident count per neighborhood...\")\n",
    "    accidents_gdf = data['accidents']\n",
    "    accidents_buffered = accidents_gdf.copy()\n",
    "    accidents_buffered['geometry'] = accidents_buffered['geometry'].buffer(BUFFER_DISTANCE)\n",
    "    accidents_joined = gpd.sjoin(accidents_buffered[['geometry']], data['neighborhoods'][['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "    accident_counts = accidents_joined.groupby('index_right').size()\n",
    "    data['neighborhoods']['accident_count'] = accident_counts.reindex(data['neighborhoods'].index, fill_value=0)\n",
    "    \n",
    "    # Compute road density per neighborhood\n",
    "    logging.info(\"Computing road density per neighborhood...\")\n",
    "    roads_gdf = data['roads']\n",
    "    \n",
    "    # Log columns of roads_gdf to debug missing 'length_m'\n",
    "    logging.info(f\"Columns in roads_gdf before computing road density: {list(roads_gdf.columns)}\")\n",
    "    \n",
    "    # Compute length_m if missing\n",
    "    if 'length_m' not in roads_gdf.columns:\n",
    "        logging.warning(\"'length_m' column missing in roads_gdf. Computing from geometry...\")\n",
    "        roads_gdf['length_m'] = roads_gdf['geometry'].length  # Length in meters (since CRS is EPSG:3826)\n",
    "        logging.info(f\"Computed length_m stats:\\n{roads_gdf['length_m'].describe()}\")\n",
    "    \n",
    "    roads_joined = gpd.sjoin(roads_gdf[['geometry', 'length_m']], data['neighborhoods'][['geometry', 'LIE_NAME']], how='left', predicate='intersects')\n",
    "    road_lengths = roads_joined.groupby('index_right')['length_m'].sum()\n",
    "    data['neighborhoods']['road_density'] = road_lengths.reindex(data['neighborhoods'].index, fill_value=0) / (data['neighborhoods']['area_km2'] * 1000)\n",
    "    logging.info(f\"Road density stats:\\n{data['neighborhoods']['road_density'].describe()}\")\n",
    "    \n",
    "    # Merge population data\n",
    "    logging.info(\"Merging population data...\")\n",
    "    population_df = data['population']\n",
    "    population_df['LIE_NAME'] = population_df['LIE_NAME'].astype(str).str.strip()\n",
    "    data['neighborhoods']['LIE_NAME'] = data['neighborhoods']['LIE_NAME'].astype(str).str.strip()\n",
    "    \n",
    "    # Check for possible column names for total_population and elderly_percentage\n",
    "    expected_cols = ['total_population', 'elderly_percentage']\n",
    "    population_cols = list(population_df.columns)\n",
    "    missing_cols = [col for col in expected_cols if col not in population_cols]\n",
    "    \n",
    "    if missing_cols:\n",
    "        logging.warning(f\"Expected columns {missing_cols} not found in population_df. Attempting to find alternatives...\")\n",
    "        # Possible alternative names\n",
    "        total_pop_alt = None\n",
    "        elderly_alt = None\n",
    "        for col in population_cols:\n",
    "            col_lower = col.lower()\n",
    "            if 'population' in col_lower and total_pop_alt is None:\n",
    "                total_pop_alt = col\n",
    "                logging.info(f\"Found alternative for total_population: {col}\")\n",
    "            if 'elderly' in col_lower and elderly_alt is None:\n",
    "                elderly_alt = col\n",
    "                logging.info(f\"Found alternative for elderly_percentage: {col}\")\n",
    "        \n",
    "        # Rename columns if alternatives are found\n",
    "        if total_pop_alt:\n",
    "            population_df = population_df.rename(columns={total_pop_alt: 'total_population'})\n",
    "        else:\n",
    "            logging.warning(\"No alternative found for total_population. Setting to 0.\")\n",
    "            population_df['total_population'] = 0\n",
    "        if elderly_alt:\n",
    "            population_df = population_df.rename(columns={elderly_alt: 'elderly_percentage'})\n",
    "        else:\n",
    "            logging.warning(\"No alternative found for elderly_percentage. Setting to 0.\")\n",
    "            population_df['elderly_percentage'] = 0\n",
    "    \n",
    "    # Perform the merge\n",
    "    data['neighborhoods'] = data['neighborhoods'].merge(\n",
    "        population_df[['LIE_NAME', 'total_population', 'elderly_percentage']],\n",
    "        on='LIE_NAME',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Compute land use percentages\n",
    "    logging.info(\"Computing land use percentages for neighborhoods...\")\n",
    "    urban_masterplan_gdf = data['urban_masterplan']\n",
    "    print_percentage_calculation(data['neighborhoods'], urban_masterplan_gdf, sample_size=3)\n",
    "    \n",
    "    for idx, row in data['neighborhoods'].iterrows():\n",
    "        neighborhood_geom = row['geometry']\n",
    "        if not neighborhood_geom.is_valid:\n",
    "            continue\n",
    "        relevant_masterplan = urban_masterplan_gdf[urban_masterplan_gdf.intersects(neighborhood_geom)]\n",
    "        if relevant_masterplan.empty:\n",
    "            continue\n",
    "        \n",
    "        temp_gdf = gpd.GeoDataFrame({'geometry': [neighborhood_geom]}, crs='EPSG:3826')\n",
    "        intersected = gpd.overlay(temp_gdf, relevant_masterplan, how='intersection', keep_geom_type=False)\n",
    "        if intersected.empty:\n",
    "            continue\n",
    "        \n",
    "        intersected['geometry'] = intersected['geometry'].apply(fix_geometry)\n",
    "        intersected = intersected[intersected.geometry.is_valid & ~intersected.geometry.is_empty]\n",
    "        if intersected.empty:\n",
    "            continue\n",
    "        \n",
    "        intersected['priority'] = intersected['Category'].map(CATEGORY_PRIORITY)\n",
    "        intersected = intersected.sort_values(by='priority', ascending=False)\n",
    "        \n",
    "        total_area = intersected.geometry.union_all().area\n",
    "        remaining_geom = intersected.geometry.union_all()\n",
    "        category_areas = {}\n",
    "        for category in intersected['Category'].unique():\n",
    "            category_rows = intersected[intersected['Category'] == category]\n",
    "            category_geom = category_rows.geometry.union_all()\n",
    "            try:\n",
    "                category_area_geom = category_geom.intersection(remaining_geom)\n",
    "                category_area = category_area_geom.area\n",
    "                category_areas[category] = category_area\n",
    "                remaining_geom = remaining_geom.difference(category_area_geom)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Topology error for category {category} in neighborhood {row['LIE_NAME']}: {e}\")\n",
    "                category_areas[category] = 0.0\n",
    "        \n",
    "        for category in CATEGORY_PRIORITY.keys():\n",
    "            area = category_areas.get(category, 0.0)\n",
    "            percentage = (area / total_area * 100) if total_area > 0 else 0.0\n",
    "            data['neighborhoods'].at[idx, f'land_use_{category.lower()}_percent'] = percentage\n",
    "    \n",
    "    # Fill NaN values in land use percentages\n",
    "    for category in CATEGORY_PRIORITY.keys():\n",
    "        col = f'land_use_{category.lower()}_percent'\n",
    "        data['neighborhoods'][col] = data['neighborhoods'][col].fillna(0.0)\n",
    "    \n",
    "    # Fill NaN values in other columns\n",
    "    for col in ['intersection_count', 'intersection_density', 'tree_count', 'transit_count', 'accident_count', 'road_density', 'total_population', 'elderly_percentage']:\n",
    "        data['neighborhoods'][col] = data['neighborhoods'][col].fillna(0)\n",
    "    \n",
    "    # Print data structure summary\n",
    "    print_data_structure(data)\n",
    "    \n",
    "    logging.info(\"Finished loading and preparing data.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48993e82",
   "metadata": {},
   "source": [
    "Cell 5 compute_intersection_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d2d1971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intersection_counts(neighborhoods_gdf, roads_gdf):\n",
    "    logging.info(\"Computing intersection counts for neighborhoods...\")\n",
    "    \n",
    "    # Extract endpoints from road segments\n",
    "    def get_endpoints(line):\n",
    "        if line is None or line.is_empty:\n",
    "            return []\n",
    "        coords = list(line.coords)\n",
    "        return [Point(coords[0]), Point(coords[-1])]\n",
    "    \n",
    "    endpoints = []\n",
    "    for idx, row in tqdm(roads_gdf.iterrows(), total=len(roads_gdf), desc=\"Extracting endpoints\"):\n",
    "        points = get_endpoints(row['geometry'])\n",
    "        for point in points:\n",
    "            endpoints.append({'geometry': point, 'road_idx': idx})\n",
    "    \n",
    "    endpoints_gdf = gpd.GeoDataFrame(endpoints, crs='EPSG:3826')\n",
    "    \n",
    "    # Build a mapping of endpoints to road indices\n",
    "    endpoint_to_roads = {}\n",
    "    for idx, row in tqdm(endpoints_gdf.iterrows(), total=len(endpoints_gdf), desc=\"Building endpoint-to-road mapping\"):\n",
    "        point = row['geometry']\n",
    "        road_idx = row['road_idx']\n",
    "        point_tuple = (point.x, point.y)\n",
    "        if point_tuple not in endpoint_to_roads:\n",
    "            endpoint_to_roads[point_tuple] = set()\n",
    "        endpoint_to_roads[point_tuple].add(road_idx)\n",
    "    \n",
    "    # Identify intersections (endpoints shared by 3 or more roads)\n",
    "    intersections = []\n",
    "    for point_tuple, road_indices in tqdm(endpoint_to_roads.items(), desc=\"Identifying intersections\"):\n",
    "        if len(road_indices) >= 3:  # Intersection if 3 or more roads share the endpoint\n",
    "            intersections.append({'geometry': Point(point_tuple)})\n",
    "    \n",
    "    if not intersections:\n",
    "        logging.warning(\"No intersections found. Setting intersection counts to 0.\")\n",
    "        neighborhoods_gdf['intersection_count'] = 0\n",
    "        neighborhoods_gdf['intersection_density'] = 0.0\n",
    "        return neighborhoods_gdf\n",
    "    \n",
    "    intersections_gdf = gpd.GeoDataFrame(intersections, crs='EPSG:3826')\n",
    "    \n",
    "    # Spatial join to count intersections per neighborhood\n",
    "    intersection_counts = gpd.sjoin(\n",
    "        neighborhoods_gdf[['geometry', 'LIE_NAME']],\n",
    "        intersections_gdf,\n",
    "        how='left',\n",
    "        predicate='contains'\n",
    "    )\n",
    "    intersection_counts = intersection_counts.groupby('LIE_NAME').size().reindex(neighborhoods_gdf['LIE_NAME'], fill_value=0)\n",
    "    neighborhoods_gdf['intersection_count'] = intersection_counts\n",
    "    \n",
    "    # Compute intersection density (intersections per km)\n",
    "    neighborhoods_gdf['intersection_density'] = neighborhoods_gdf['intersection_count'] / neighborhoods_gdf['area_km2']\n",
    "    neighborhoods_gdf['intersection_density'] = neighborhoods_gdf['intersection_density'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    logging.info(f\"Intersection count stats: {neighborhoods_gdf['intersection_count'].describe()}\")\n",
    "    logging.info(f\"Intersection density stats: {neighborhoods_gdf['intersection_density'].describe()}\")\n",
    "    \n",
    "    return neighborhoods_gdf\n",
    "\n",
    "def build_graph(data, force_recompute=False):\n",
    "    logging.info(\"Stage 2: Building the graph...\")\n",
    "    \n",
    "    # Compute data hash to check if graph needs recomputing\n",
    "    data_hash = compute_data_hash(data)\n",
    "    cached_hash = None\n",
    "    if os.path.exists(GRAPH_DATA_HASH_PATH):\n",
    "        with open(GRAPH_DATA_HASH_PATH, 'r') as f:\n",
    "            cached_hash = f.read().strip()\n",
    "    \n",
    "    if not force_recompute and cached_hash == data_hash and all(\n",
    "        os.path.exists(path) for path in [GRAPH_NODES_CACHE_PATH, GRAPH_EDGES_CACHE_PATH, GRAPH_NODE_ID_CACHE_PATH]\n",
    "    ):\n",
    "        logging.info(\"Data unchanged. Loading graph from cache...\")\n",
    "        nodes_df = cudf.read_parquet(GRAPH_NODES_CACHE_PATH)\n",
    "        edges_df = cudf.read_parquet(GRAPH_EDGES_CACHE_PATH)\n",
    "        with open(GRAPH_NODE_ID_CACHE_PATH, 'r') as f:\n",
    "            node_id_to_index = json.load(f)\n",
    "        G = cugraph.Graph()\n",
    "        G.from_cudf_edgelist(\n",
    "            edges_df,\n",
    "            source='src',\n",
    "            destination='dst',\n",
    "            edge_attr='weight'\n",
    "        )\n",
    "        G._nodes = nodes_df\n",
    "        logging.info(\"Graph loaded from cache.\")\n",
    "        return G\n",
    "    \n",
    "    neighborhoods_gdf = data['neighborhoods'].copy()\n",
    "    buildings_gdf = data['buildings'].copy()\n",
    "    roads_gdf = data['roads'].copy()\n",
    "    trees_gdf = data['trees'].copy()\n",
    "    transit_gdf = data['transit'].copy()\n",
    "    \n",
    "    # Create nodes for neighborhoods, buildings, roads, trees, and transit\n",
    "    nodes = []\n",
    "    node_id_to_index = {}\n",
    "    current_idx = 0\n",
    "    \n",
    "    # Neighborhood nodes\n",
    "    for idx, row in neighborhoods_gdf.iterrows():\n",
    "        node_id = f\"neighborhood_{row['LIE_NAME']}\"\n",
    "        node_id_to_index[node_id] = current_idx\n",
    "        nodes.append({\n",
    "            'node_idx': current_idx,\n",
    "            'node_id': node_id,\n",
    "            'type': 'neighborhood',\n",
    "            'LIE_NAME': row['LIE_NAME'],\n",
    "            'geometry': row['geometry'].centroid,\n",
    "            'ndvi_mean': row['ndvi_mean'],\n",
    "            'total_population': row['total_population'],\n",
    "            'elderly_percentage': row['elderly_percentage'],\n",
    "            'area_km2': row['area_km2']\n",
    "        })\n",
    "        current_idx += 1\n",
    "    \n",
    "    # Building nodes\n",
    "    for idx, row in buildings_gdf.iterrows():\n",
    "        node_id = f\"building_{idx}\"\n",
    "        node_id_to_index[node_id] = current_idx\n",
    "        nodes.append({\n",
    "            'node_idx': current_idx,\n",
    "            'node_id': node_id,\n",
    "            'type': 'building',\n",
    "            'LIE_NAME': None,\n",
    "            'geometry': row['geometry'].centroid,\n",
    "            'building_type': row['building'],\n",
    "            'area_m2': row['area_m2']\n",
    "        })\n",
    "        current_idx += 1\n",
    "    \n",
    "    # Road nodes\n",
    "    for idx, row in roads_gdf.iterrows():\n",
    "        node_id = f\"road_{idx}\"\n",
    "        node_id_to_index[node_id] = current_idx\n",
    "        nodes.append({\n",
    "            'node_idx': current_idx,\n",
    "            'node_id': node_id,\n",
    "            'type': 'road',\n",
    "            'LIE_NAME': None,\n",
    "            'geometry': row['geometry'].centroid,\n",
    "            'class': row['class'],\n",
    "            'length_m': row['length_m']\n",
    "        })\n",
    "        current_idx += 1\n",
    "    \n",
    "    # Tree nodes\n",
    "    for idx, row in trees_gdf.iterrows():\n",
    "        node_id = f\"tree_{idx}\"\n",
    "        node_id_to_index[node_id] = current_idx\n",
    "        nodes.append({\n",
    "            'node_idx': current_idx,\n",
    "            'node_id': node_id,\n",
    "            'type': 'tree',\n",
    "            'LIE_NAME': None,\n",
    "            'geometry': row['geometry']\n",
    "        })\n",
    "        current_idx += 1\n",
    "    \n",
    "    # Transit nodes\n",
    "    for idx, row in transit_gdf.iterrows():\n",
    "        node_id = f\"transit_{idx}\"\n",
    "        node_id_to_index[node_id] = current_idx\n",
    "        nodes.append({\n",
    "            'node_idx': current_idx,\n",
    "            'node_id': node_id,\n",
    "            'type': 'transit',\n",
    "            'LIE_NAME': None,\n",
    "            'geometry': row['geometry'],\n",
    "            'class': row['class']\n",
    "        })\n",
    "        current_idx += 1\n",
    "    \n",
    "    nodes_df = pd.DataFrame(nodes)\n",
    "    nodes_gdf = gpd.GeoDataFrame(nodes_df, geometry='geometry', crs='EPSG:3826')\n",
    "    nodes_df = cudf.from_pandas(nodes_df.drop(columns=['geometry']))\n",
    "    \n",
    "    # Create edges based on spatial proximity\n",
    "    edges = []\n",
    "    nodes_gdf_sindex = nodes_gdf.sindex\n",
    "    \n",
    "    # Neighborhood-to-neighborhood edges (shared borders)\n",
    "    logging.info(\"Creating neighborhood-to-neighborhood edges...\")\n",
    "    for idx1, row1 in neighborhoods_gdf.iterrows():\n",
    "        geom1 = row1['geometry']\n",
    "        node_idx1 = node_id_to_index[f\"neighborhood_{row1['LIE_NAME']}\"]\n",
    "        possible_matches = list(nodes_gdf_sindex.query(geom1, predicate='intersects'))\n",
    "        for idx2 in possible_matches:\n",
    "            row2 = nodes_gdf.iloc[idx2]\n",
    "            if row2['type'] != 'neighborhood':\n",
    "                continue\n",
    "            if row1['LIE_NAME'] == row2['LIE_NAME']:\n",
    "                continue\n",
    "            geom2 = neighborhoods_gdf[neighborhoods_gdf['LIE_NAME'] == row2['LIE_NAME']]['geometry'].iloc[0]\n",
    "            if geom1.intersects(geom2):\n",
    "                node_idx2 = node_id_to_index[f\"neighborhood_{row2['LIE_NAME']}\"]\n",
    "                edges.append({\n",
    "                    'src': node_idx1,\n",
    "                    'dst': node_idx2,\n",
    "                    'weight': 1.0\n",
    "                })\n",
    "    \n",
    "    # Other edges (neighborhood to building, road, tree, transit)\n",
    "    logging.info(\"Creating edges between neighborhoods and other entities...\")\n",
    "    for idx, row in tqdm(nodes_gdf.iterrows(), total=len(nodes_gdf), desc=\"Creating edges\"):\n",
    "        if row['type'] == 'neighborhood':\n",
    "            continue\n",
    "        geom = row['geometry']\n",
    "        possible_matches = list(neighborhoods_gdf.sindex.query(geom, predicate='contains'))\n",
    "        for match_idx in possible_matches:\n",
    "            neighborhood = neighborhoods_gdf.iloc[match_idx]\n",
    "            if neighborhood['geometry'].contains(geom):\n",
    "                node_idx1 = node_id_to_index[row['node_id']]\n",
    "                node_idx2 = node_id_to_index[f\"neighborhood_{neighborhood['LIE_NAME']}\"]\n",
    "                weight = 1.0\n",
    "                if row['type'] == 'transit':\n",
    "                    weight = 2.0  # Higher weight for transit nodes\n",
    "                edges.append({\n",
    "                    'src': node_idx1,\n",
    "                    'dst': node_idx2,\n",
    "                    'weight': weight\n",
    "                })\n",
    "                edges.append({\n",
    "                    'src': node_idx2,\n",
    "                    'dst': node_idx1,\n",
    "                    'weight': weight\n",
    "                })\n",
    "    \n",
    "    edges_df = cudf.DataFrame(edges)\n",
    "    \n",
    "    # Build the graph\n",
    "    G = cugraph.Graph()\n",
    "    G.from_cudf_edgelist(\n",
    "        edges_df,\n",
    "        source='src',\n",
    "        destination='dst',\n",
    "        edge_attr='weight'\n",
    "    )\n",
    "    G._nodes = nodes_df\n",
    "    \n",
    "    # Cache the graph\n",
    "    nodes_df.to_parquet(GRAPH_NODES_CACHE_PATH)\n",
    "    edges_df.to_parquet(GRAPH_EDGES_CACHE_PATH)\n",
    "    with open(GRAPH_NODE_ID_CACHE_PATH, 'w') as f:\n",
    "        json.dump(node_id_to_index, f)\n",
    "    with open(GRAPH_DATA_HASH_PATH, 'w') as f:\n",
    "        f.write(data_hash)\n",
    "    \n",
    "    logging.info(\"Graph construction completed.\")\n",
    "    return G\n",
    "\n",
    "def prepare_gnn_data(G):\n",
    "    logging.info(\"Stage 3: Preparing data for GNN...\")\n",
    "    \n",
    "    nodes_df = G._nodes.to_pandas()\n",
    "    edges_df = G.edgelist.edgelist_df.to_pandas()\n",
    "    \n",
    "    # Create node features\n",
    "    feature_columns = [\n",
    "        'ndvi_mean', 'total_population', 'elderly_percentage', 'area_km2',\n",
    "        'area_m2', 'length_m'\n",
    "    ]\n",
    "    features = []\n",
    "    for idx, row in nodes_df.iterrows():\n",
    "        node_features = []\n",
    "        for col in feature_columns:\n",
    "            value = row.get(col, 0.0)\n",
    "            if pd.isna(value):\n",
    "                value = 0.0\n",
    "            node_features.append(value)\n",
    "        \n",
    "        # One-hot encode node type\n",
    "        node_type = row['type']\n",
    "        type_encoding = [0] * 5  # 5 types: neighborhood, building, road, tree, transit\n",
    "        type_mapping = {\n",
    "            'neighborhood': 0,\n",
    "            'building': 1,\n",
    "            'road': 2,\n",
    "            'tree': 3,\n",
    "            'transit': 4\n",
    "        }\n",
    "        type_idx = type_mapping.get(node_type, 0)\n",
    "        type_encoding[type_idx] = 1\n",
    "        node_features.extend(type_encoding)\n",
    "        \n",
    "        features.append(node_features)\n",
    "    \n",
    "    feature_matrix = np.array(features, dtype=np.float32)\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    numerical_features = feature_matrix[:, :len(feature_columns)]\n",
    "    means = numerical_features.mean(axis=0)\n",
    "    stds = numerical_features.std(axis=0)\n",
    "    stds[stds == 0] = 1  # Avoid division by zero\n",
    "    numerical_features = (numerical_features - means) / stds\n",
    "    feature_matrix[:, :len(feature_columns)] = numerical_features\n",
    "    \n",
    "    # Create edge indices for PyG\n",
    "    edge_index = torch.tensor(\n",
    "        np.array([edges_df['src'].values, edges_df['dst'].values]),\n",
    "        dtype=torch.long\n",
    "    )\n",
    "    edge_attr = torch.tensor(edges_df['weight'].values, dtype=torch.float)\n",
    "    \n",
    "    # Create target (walkability score) for neighborhood nodes\n",
    "    y = np.zeros(len(nodes_df), dtype=np.float32)\n",
    "    if 'walkability_score' in nodes_df.columns:\n",
    "        walkability_scores = nodes_df['walkability_score'].fillna(0).values\n",
    "        mask = nodes_df['type'] == 'neighborhood'\n",
    "        y[mask] = walkability_scores[mask]\n",
    "    else:\n",
    "        logging.warning(\"Walkability scores not found in nodes_df. Setting targets to 0.\")\n",
    "    \n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "    \n",
    "    node_type_mapping = {\n",
    "        'neighborhood': 0,\n",
    "        'building': 1,\n",
    "        'road': 2,\n",
    "        'tree': 3,\n",
    "        'transit': 4\n",
    "    }\n",
    "    node_type = nodes_df['type'].map(node_type_mapping).fillna(-1).astype(int).values\n",
    "    node_type = torch.tensor(node_type, dtype=torch.long)\n",
    "    \n",
    "    data = Data(\n",
    "        x=torch.tensor(feature_matrix, dtype=torch.float),\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=y,\n",
    "        node_type=node_type\n",
    "    )\n",
    "    \n",
    "    logging.info(\"GNN data prepared.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b04d9d",
   "metadata": {},
   "source": [
    "Cell 6: Graph Construction (build_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4158e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def compute_neighborhood_neighborhood_edges(args):\n",
    "    idx, row, neighborhoods_gdf, neighborhood_sindex = args\n",
    "    edges = []\n",
    "    geom = row['geometry']\n",
    "    possible_matches_index = list(neighborhood_sindex.intersection(geom.bounds))\n",
    "    for other_idx in possible_matches_index:\n",
    "        if other_idx != idx:\n",
    "            other_row = neighborhoods_gdf.iloc[other_idx]\n",
    "            other_geom = other_row['geometry']\n",
    "            try:\n",
    "                if geom.buffer(1e-3).intersects(other_geom.buffer(1e-3)) or geom.buffer(1e-3).touches(other_geom.buffer(1e-3)):\n",
    "                    src = f\"neighborhood_{idx}\"\n",
    "                    dst = f\"neighborhood_{other_idx}\"\n",
    "                    edges.append({'src': src, 'dst': dst})\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error checking intersection between neighborhood {idx} and {other_idx}: {e}\")\n",
    "    return edges\n",
    "\n",
    "def compute_neighborhood_building_edges(args):\n",
    "    idx, row, buildings_gdf, building_sindex = args\n",
    "    edges = []\n",
    "    geom = row['geometry']\n",
    "    possible_matches_index = list(building_sindex.intersection(geom.bounds))\n",
    "    for building_idx in possible_matches_index:\n",
    "        building_row = buildings_gdf.iloc[building_idx]\n",
    "        building_geom = building_row['geometry']\n",
    "        try:\n",
    "            if geom.buffer(1e-3).intersects(building_geom.buffer(1e-3)):\n",
    "                src = f\"neighborhood_{idx}\"\n",
    "                dst = f\"building_{building_idx}\"\n",
    "                edges.append({'src': src, 'dst': dst})\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error checking intersection between neighborhood {idx} and building {building_idx}: {e}\")\n",
    "    return edges\n",
    "\n",
    "def compute_neighborhood_road_edges(args):\n",
    "    idx, row, roads_gdf, road_sindex = args\n",
    "    edges = []\n",
    "    geom = row['geometry']\n",
    "    possible_matches_index = list(road_sindex.intersection(geom.bounds))\n",
    "    for road_idx in possible_matches_index:\n",
    "        road_row = roads_gdf.iloc[road_idx]\n",
    "        road_geom = road_row['geometry']\n",
    "        try:\n",
    "            if geom.buffer(1e-3).intersects(road_geom.buffer(1e-3)):\n",
    "                src = f\"neighborhood_{idx}\"\n",
    "                dst = f\"road_{road_idx}\"\n",
    "                edges.append({'src': src, 'dst': dst})\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error checking intersection between neighborhood {idx} and road {road_idx}: {e}\")\n",
    "    return edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0cdc1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(data, force_recompute=False):\n",
    "    logging.info(\"Stage 2: Building city graph...\")\n",
    "    current_hash = compute_data_hash(data)\n",
    "    nodes_df = None\n",
    "    edges_df = None\n",
    "    node_id_to_vertex = {}\n",
    "    vertex_to_index = {}\n",
    "\n",
    "    if not force_recompute and os.path.exists(GRAPH_NODES_CACHE_PATH) and os.path.exists(GRAPH_EDGES_CACHE_PATH):\n",
    "        try:\n",
    "            with open(GRAPH_DATA_HASH_PATH, 'r') as f:\n",
    "                cached_hash = f.read()\n",
    "            if cached_hash == current_hash:\n",
    "                logging.info(\"Data hash matches cached hash. Loading graph from cache...\")\n",
    "                nodes_df = cudf.read_parquet(GRAPH_NODES_CACHE_PATH)\n",
    "                edges_df = cudf.read_parquet(GRAPH_EDGES_CACHE_PATH)\n",
    "                with open(GRAPH_NODE_ID_CACHE_PATH, 'r') as f:\n",
    "                    node_id_to_vertex = json.load(f)\n",
    "                G = cugraph.Graph()\n",
    "                G._nodes = nodes_df\n",
    "                if not edges_df.empty:\n",
    "                    G.from_cudf_edgelist(edges_df, source='src', destination='dst')\n",
    "                logging.info(f\"Loaded graph from cache: {len(nodes_df)} nodes, {len(edges_df)} edges\")\n",
    "                return G\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load cached graph: {e}. Recomputing graph...\")\n",
    "\n",
    "    logging.info(\"Constructing graph nodes...\")\n",
    "    neighborhoods_gdf = data['neighborhoods']\n",
    "    buildings_gdf = data['buildings']\n",
    "    roads_gdf = data['roads']\n",
    "\n",
    "    # Compute area_m2 for buildings if not present\n",
    "    if 'area_m2' not in buildings_gdf.columns:\n",
    "        logging.warning(\"'area_m2' column missing in buildings_gdf. Computing from geometry...\")\n",
    "        buildings_gdf['area_m2'] = buildings_gdf['geometry'].area\n",
    "        logging.info(f\"Computed area_m2 stats:\\n{buildings_gdf['area_m2'].describe()}\")\n",
    "\n",
    "    # Create nodes with both vertex IDs and integer indices\n",
    "    logging.info(\"Adding neighborhood nodes...\")\n",
    "    neighborhood_nodes = []\n",
    "    for idx, row in tqdm(neighborhoods_gdf.iterrows(), total=len(neighborhoods_gdf), desc=\"Neighborhood nodes\"):\n",
    "        vertex = f\"neighborhood_{idx}\"\n",
    "        node_id_to_vertex[idx] = vertex\n",
    "        vertex_to_index[vertex] = idx  # Map vertex to integer index\n",
    "        neighborhood_nodes.append({\n",
    "            'index': idx,  # Integer index for GNN\n",
    "            'vertex': vertex,  # String vertex ID\n",
    "            'type': 'neighborhood',\n",
    "            'LIE_NAME': row['LIE_NAME'],\n",
    "            'ndvi_mean': row['ndvi_mean'],\n",
    "            'tree_count': row['tree_count'],\n",
    "            'transit_count': row['transit_count'],\n",
    "            'accident_count': row['accident_count'],\n",
    "            'road_density': row['road_density'],\n",
    "            'intersection_density': row['intersection_density'],\n",
    "            'total_population': row['total_population'],\n",
    "            'elderly_percentage': row['elderly_percentage'],\n",
    "            **{f'land_use_{category.lower()}_percent': row.get(f'land_use_{category.lower()}_percent', 0.0) for category in CATEGORY_PRIORITY.keys()}\n",
    "        })\n",
    "\n",
    "    logging.info(\"Adding building nodes...\")\n",
    "    building_nodes = []\n",
    "    for idx, row in tqdm(buildings_gdf.iterrows(), total=len(buildings_gdf), desc=\"Building nodes\"):\n",
    "        offset = len(neighborhoods_gdf)\n",
    "        vertex = f\"building_{idx}\"\n",
    "        node_id_to_vertex[idx + offset] = vertex\n",
    "        vertex_to_index[vertex] = idx + offset\n",
    "        building_nodes.append({\n",
    "            'index': idx + offset,\n",
    "            'vertex': vertex,\n",
    "            'type': 'building',\n",
    "            'building': row['building'] if pd.notna(row['building']) else 'unknown',\n",
    "            'area_m2': row['area_m2']\n",
    "        })\n",
    "\n",
    "    logging.info(\"Adding road nodes...\")\n",
    "    road_nodes = []\n",
    "    for idx, row in tqdm(roads_gdf.iterrows(), total=len(roads_gdf), desc=\"Road nodes\"):\n",
    "        offset = len(neighborhoods_gdf) + len(buildings_gdf)\n",
    "        vertex = f\"road_{idx}\"\n",
    "        node_id_to_vertex[idx + offset] = vertex\n",
    "        vertex_to_index[vertex] = idx + offset\n",
    "        road_nodes.append({\n",
    "            'index': idx + offset,\n",
    "            'vertex': vertex,\n",
    "            'type': 'road',\n",
    "            'class': row['class'] if pd.notna(row['class']) else 'unknown',\n",
    "            'length_m': row['length_m']\n",
    "        })\n",
    "\n",
    "    # Combine all nodes\n",
    "    nodes = neighborhood_nodes + building_nodes + road_nodes\n",
    "    nodes_df = cudf.DataFrame(nodes)\n",
    "\n",
    "    # Convert GeoDataFrames to cudf for GPU-accelerated operations\n",
    "    logging.info(\"Converting GeoDataFrames to cudf for GPU processing...\")\n",
    "    neighborhoods_cudf = cudf.from_pandas(neighborhoods_gdf.drop(columns=['geometry']))\n",
    "    buildings_cudf = cudf.from_pandas(buildings_gdf.drop(columns=['geometry']))\n",
    "    roads_cudf = cudf.from_pandas(roads_gdf.drop(columns=['geometry']))\n",
    "\n",
    "    # Extract bounding box coordinates as separate columns, ensuring scalar values\n",
    "    logging.info(\"Extracting bounding box coordinates...\")\n",
    "    # Apply fix_geometry to ensure all geometries are valid\n",
    "    neighborhoods_gdf['geometry'] = neighborhoods_gdf['geometry'].apply(fix_geometry)\n",
    "    buildings_gdf['geometry'] = buildings_gdf['geometry'].apply(fix_geometry)\n",
    "    roads_gdf['geometry'] = roads_gdf['geometry'].apply(fix_geometry)\n",
    "\n",
    "    # Extract bounds and convert to scalar floats\n",
    "    bounds_df = neighborhoods_gdf['geometry'].apply(lambda geom: pd.Series(geom.bounds, index=['min_x', 'min_y', 'max_x', 'max_y'])).astype(float).fillna(0.0)\n",
    "    neighborhoods_cudf['min_x'] = cudf.Series(bounds_df['min_x'].values, dtype='float64')\n",
    "    neighborhoods_cudf['min_y'] = cudf.Series(bounds_df['min_y'].values, dtype='float64')\n",
    "    neighborhoods_cudf['max_x'] = cudf.Series(bounds_df['max_x'].values, dtype='float64')\n",
    "    neighborhoods_cudf['max_y'] = cudf.Series(bounds_df['max_y'].values, dtype='float64')\n",
    "\n",
    "    bounds_df = buildings_gdf['geometry'].apply(lambda geom: pd.Series(geom.bounds, index=['min_x', 'min_y', 'max_x', 'max_y'])).astype(float).fillna(0.0)\n",
    "    buildings_cudf['min_x'] = cudf.Series(bounds_df['min_x'].values, dtype='float64')\n",
    "    buildings_cudf['min_y'] = cudf.Series(bounds_df['min_y'].values, dtype='float64')\n",
    "    buildings_cudf['max_x'] = cudf.Series(bounds_df['max_x'].values, dtype='float64')\n",
    "    buildings_cudf['max_y'] = cudf.Series(bounds_df['max_y'].values, dtype='float64')\n",
    "\n",
    "    bounds_df = roads_gdf['geometry'].apply(lambda geom: pd.Series(geom.bounds, index=['min_x', 'min_y', 'max_x', 'max_y'])).astype(float).fillna(0.0)\n",
    "    roads_cudf['min_x'] = cudf.Series(bounds_df['min_x'].values, dtype='float64')\n",
    "    roads_cudf['min_y'] = cudf.Series(bounds_df['min_y'].values, dtype='float64')\n",
    "    roads_cudf['max_x'] = cudf.Series(bounds_df['max_x'].values, dtype='float64')\n",
    "    roads_cudf['max_y'] = cudf.Series(bounds_df['max_y'].values, dtype='float64')\n",
    "\n",
    "    # Log the data types to debug\n",
    "    logging.info(f\"neighborhoods_cudf['min_x'] dtype: {neighborhoods_cudf['min_x'].dtype}\")\n",
    "    logging.info(f\"buildings_cudf['min_x'] dtype: {buildings_cudf['min_x'].dtype}\")\n",
    "    logging.info(f\"roads_cudf['min_x'] dtype: {roads_cudf['min_x'].dtype}\")\n",
    "\n",
    "    # Create edges using integer indices\n",
    "    logging.info(\"Creating edges using GPU-accelerated spatial joins...\")\n",
    "    edges = []\n",
    "\n",
    "    # Neighborhood-Neighborhood edges\n",
    "    logging.info(\"Computing neighborhood-neighborhood edges...\")\n",
    "    for i in tqdm(range(len(neighborhoods_cudf)), desc=\"Neighborhood-Neighborhood edges\"):\n",
    "        row = neighborhoods_cudf.iloc[i]\n",
    "        # Extract scalar bounding box coordinates and convert to Python scalar\n",
    "        geom_min_x = float(row['min_x'].values[0])\n",
    "        geom_min_y = float(row['min_y'].values[0])\n",
    "        geom_max_x = float(row['max_x'].values[0])\n",
    "        geom_max_y = float(row['max_y'].values[0])\n",
    "        # Log the type of geom_min_x for debugging\n",
    "        logging.debug(f\"geom_min_x type: {type(geom_min_x)}, value: {geom_min_x}\")\n",
    "        # Find potential matches based on bounding box overlap using direct scalar comparisons\n",
    "        matches = neighborhoods_cudf[\n",
    "            ~((geom_max_x < neighborhoods_cudf['min_x']) |\n",
    "              (geom_min_x > neighborhoods_cudf['max_x']) |\n",
    "              (geom_max_y < neighborhoods_cudf['min_y']) |\n",
    "              (geom_min_y > neighborhoods_cudf['max_y'])) &\n",
    "            (neighborhoods_cudf.index != i)\n",
    "        ]\n",
    "        for j in matches.index.values_host:\n",
    "            src_vertex = f\"neighborhood_{i}\"\n",
    "            dst_vertex = f\"neighborhood_{j}\"\n",
    "            src = vertex_to_index[src_vertex]\n",
    "            dst = vertex_to_index[dst_vertex]\n",
    "            edges.append({'src': src, 'dst': dst})\n",
    "\n",
    "    # Neighborhood-Building edges\n",
    "    logging.info(\"Computing neighborhood-building edges...\")\n",
    "    for i in tqdm(range(len(neighborhoods_cudf)), desc=\"Neighborhood-Building edges\"):\n",
    "        row = neighborhoods_cudf.iloc[i]\n",
    "        geom_min_x = float(row['min_x'].values[0])\n",
    "        geom_min_y = float(row['min_y'].values[0])\n",
    "        geom_max_x = float(row['max_x'].values[0])\n",
    "        geom_max_y = float(row['max_y'].values[0])\n",
    "        matches = buildings_cudf[\n",
    "            ~((geom_max_x < buildings_cudf['min_x']) |\n",
    "              (geom_min_x > buildings_cudf['max_x']) |\n",
    "              (geom_max_y < buildings_cudf['min_y']) |\n",
    "              (geom_min_y > buildings_cudf['max_y']))\n",
    "        ]\n",
    "        for j in matches.index.values_host:\n",
    "            src_vertex = f\"neighborhood_{i}\"\n",
    "            dst_vertex = f\"building_{j}\"\n",
    "            src = vertex_to_index[src_vertex]\n",
    "            dst = vertex_to_index[dst_vertex]\n",
    "            edges.append({'src': src, 'dst': dst})\n",
    "\n",
    "    # Neighborhood-Road edges\n",
    "    logging.info(\"Computing neighborhood-road edges...\")\n",
    "    for i in tqdm(range(len(neighborhoods_cudf)), desc=\"Neighborhood-Road edges\"):\n",
    "        row = neighborhoods_cudf.iloc[i]\n",
    "        geom_min_x = float(row['min_x'].values[0])\n",
    "        geom_min_y = float(row['min_y'].values[0])\n",
    "        geom_max_x = float(row['max_x'].values[0])\n",
    "        geom_max_y = float(row['max_y'].values[0])\n",
    "        matches = roads_cudf[\n",
    "            ~((geom_max_x < roads_cudf['min_x']) |\n",
    "              (geom_min_x > roads_cudf['max_x']) |\n",
    "              (geom_max_y < roads_cudf['min_y']) |\n",
    "              (geom_min_y > roads_cudf['max_y']))\n",
    "        ]\n",
    "        for j in matches.index.values_host:\n",
    "            src_vertex = f\"neighborhood_{i}\"\n",
    "            dst_vertex = f\"road_{j}\"\n",
    "            src = vertex_to_index[src_vertex]\n",
    "            dst = vertex_to_index[dst_vertex]\n",
    "            edges.append({'src': src, 'dst': dst})\n",
    "\n",
    "    edges_df = cudf.DataFrame(edges)\n",
    "    logging.info(f\"Created {len(edges_df)} total edges\")\n",
    "\n",
    "    # Validate edges\n",
    "    valid_indices = set(nodes_df['index'].to_pandas())\n",
    "    if edges_df.empty:\n",
    "        logging.warning(\"No edges created. Graph will have nodes but no edges.\")\n",
    "    else:\n",
    "        edges_df = edges_df[edges_df['src'].isin(valid_indices) & edges_df['dst'].isin(valid_indices)]\n",
    "        logging.info(f\"After validation, {len(edges_df)} edges remain\")\n",
    "        if not edges_df.empty:\n",
    "            logging.info(f\"Sample edges after validation:\\n{edges_df.head().to_pandas()}\")\n",
    "\n",
    "    # Create the graph\n",
    "    G = cugraph.Graph()\n",
    "    G._nodes = nodes_df\n",
    "    if not edges_df.empty:\n",
    "        G.from_cudf_edgelist(edges_df, source='src', destination='dst')\n",
    "    else:\n",
    "        logging.warning(\"No valid edges created. Graph will have nodes but no edges.\")\n",
    "\n",
    "    # Save graph data to cache\n",
    "    logging.info(\"Saving graph data to cache...\")\n",
    "    try:\n",
    "        nodes_df.to_parquet(GRAPH_NODES_CACHE_PATH)\n",
    "        edges_df.to_parquet(GRAPH_EDGES_CACHE_PATH)\n",
    "        with open(GRAPH_DATA_HASH_PATH, 'w') as f:\n",
    "            f.write(current_hash)\n",
    "        with open(GRAPH_NODE_ID_CACHE_PATH, 'w') as f:\n",
    "            json.dump(node_id_to_vertex, f)\n",
    "        logging.info(\"Successfully saved graph data to cache.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save graph data to cache: {e}\")\n",
    "\n",
    "    logging.info(f\"City graph constructed: {len(nodes_df)} nodes, {len(edges_df)} edges\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14e080",
   "metadata": {},
   "source": [
    "Cell 7: Rule-Based Walkability Scores (compute_walkability_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3ef4aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_walkability_scores(G, data):\n",
    "    \"\"\"\n",
    "    Compute walkability scores for neighborhood nodes in the graph and assign them.\n",
    "    \n",
    "    Args:\n",
    "        G (cugraph.Graph): The city graph with nodes and edges.\n",
    "        data (dict): Dictionary containing roads and other datasets.\n",
    "    \n",
    "    Returns:\n",
    "        cugraph.Graph: Updated graph with walkability scores assigned to neighborhood nodes.\n",
    "    \"\"\"\n",
    "    logging.info(\"Computing walkability scores for neighborhoods...\")\n",
    "    nodes_df = G._nodes.to_pandas()\n",
    "    \n",
    "    walkability_components = compute_walkability_components_all(data['neighborhoods'], data)\n",
    "    \n",
    "    logging.info(f\"Number of neighborhood nodes in nodes_df: {len(nodes_df[nodes_df['type'] == 'neighborhood'])}\")\n",
    "    logging.info(f\"Number of entries in walkability_components: {len(walkability_components)}\")\n",
    "    logging.info(f\"Sample LIE_NAME in nodes_df: {nodes_df[nodes_df['type'] == 'neighborhood']['LIE_NAME'].head().tolist()}\")\n",
    "    logging.info(f\"Sample LIE_NAME in walkability_components: {walkability_components['LIE_NAME'].head().tolist()}\")\n",
    "    \n",
    "    nodes_df = nodes_df.merge(\n",
    "        walkability_components[['LIE_NAME', 'walkability_score', 'walkability_category']],\n",
    "        on='LIE_NAME',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    unmatched = nodes_df[(nodes_df['type'] == 'neighborhood') & (nodes_df['walkability_score'].isna())]\n",
    "    if len(unmatched) > 0:\n",
    "        logging.warning(f\"Found {len(unmatched)} neighborhood nodes without walkability scores. Filling with 0.\")\n",
    "        nodes_df.loc[nodes_df['type'] == 'neighborhood', 'walkability_score'] = nodes_df['walkability_score'].fillna(0)\n",
    "        nodes_df.loc[nodes_df['type'] == 'neighborhood', 'walkability_category'] = nodes_df['walkability_category'].fillna('low')\n",
    "    \n",
    "    G._nodes = cudf.from_pandas(nodes_df)\n",
    "    \n",
    "    logging.info(\"Finished computing walkability scores.\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989dbf84",
   "metadata": {},
   "source": [
    "Cell 8 prepare_gnn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8a057108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gnn_data(G):\n",
    "    logging.info(\"Preparing data for GNN training...\")\n",
    "    nodes_df = G._nodes\n",
    "    edges_df = G.edgelist.edgelist_df if G.edgelist else cudf.DataFrame()\n",
    "\n",
    "    numerical_features = [\n",
    "        'ndvi_mean', 'tree_count', 'transit_count', 'accident_count', \n",
    "        'road_density', 'intersection_density', 'total_population', \n",
    "        'elderly_percentage', 'area_m2', 'length_m', 'avg_road_accident_density', \n",
    "        'pedestrian_road_density'\n",
    "    ] + [f'land_use_{cat.lower()}_percent' for cat in CATEGORY_PRIORITY.keys()]\n",
    "\n",
    "    building_types = nodes_df[nodes_df['type'] == 'building']['building'].to_pandas().unique()\n",
    "    road_classes = nodes_df[nodes_df['type'] == 'road']['class'].to_pandas().unique()\n",
    "    categorical_features = (\n",
    "        [f'building_{bt}' for bt in building_types if pd.notna(bt)] +\n",
    "        [f'road_class_{rc}' for rc in road_classes if pd.notna(rc)]\n",
    "    )\n",
    "\n",
    "    all_features = numerical_features + categorical_features\n",
    "\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    node_types = []\n",
    "\n",
    "    for node_type in tqdm(['neighborhood', 'building', 'road'], desc=\"Normalizing features by node type\"):\n",
    "        subset = nodes_df[nodes_df['type'] == node_type].to_pandas()\n",
    "        if subset.empty:\n",
    "            logging.warning(f\"No nodes of type {node_type} found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        subset_features = pd.DataFrame(0.0, index=subset.index, columns=all_features)\n",
    "\n",
    "        if node_type == 'neighborhood':\n",
    "            for col in numerical_features:\n",
    "                if col in subset.columns:\n",
    "                    subset_features[col] = subset[col].astype(float).fillna(0)\n",
    "                else:\n",
    "                    logging.warning(f\"Column {col} missing in neighborhood nodes. Setting to 0.\")\n",
    "        elif node_type == 'building':\n",
    "            if 'area_m2' in subset.columns:\n",
    "                subset_features['area_m2'] = subset['area_m2'].astype(float).fillna(0)\n",
    "        else:  # road\n",
    "            if 'length_m' in subset.columns:\n",
    "                subset_features['length_m'] = subset['length_m'].astype(float).fillna(0)\n",
    "\n",
    "        if node_type == 'building':\n",
    "            for bt in building_types:\n",
    "                if pd.notna(bt):\n",
    "                    subset_features[f'building_{bt}'] = (subset['building'] == bt).astype(float)\n",
    "        elif node_type == 'road':\n",
    "            for rc in road_classes:\n",
    "                if pd.notna(rc):\n",
    "                    subset_features[f'road_class_{rc}'] = (subset['class'] == rc).astype(float)\n",
    "\n",
    "        # Z-score normalization for numerical features\n",
    "        for col in numerical_features:\n",
    "            if col in subset_features.columns and subset_features[col].std() > 0:\n",
    "                subset_features[col] = (\n",
    "                    (subset_features[col] - subset_features[col].mean()) / subset_features[col].std()\n",
    "                ).fillna(0)\n",
    "            else:\n",
    "                logging.debug(f\"Column {col} has zero variance or is missing for {node_type}. Setting to 0.\")\n",
    "\n",
    "        logging.info(f\"Node type {node_type}: {len(subset)} nodes, feature shape: {subset_features.shape}\")\n",
    "\n",
    "        features_list.append(subset_features.values)\n",
    "\n",
    "        if node_type == 'neighborhood':\n",
    "            labels = subset['walkability_score'].astype(float).fillna(0).values\n",
    "            labels_list.append(labels[:, None])  # Shape [n, 1]\n",
    "        else:\n",
    "            labels_list.append(np.zeros((len(subset), 1)))\n",
    "\n",
    "        node_types.extend([node_type] * len(subset))\n",
    "\n",
    "    try:\n",
    "        features = np.vstack(features_list)\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Failed to stack features: {e}\")\n",
    "        raise\n",
    "\n",
    "    labels = np.vstack(labels_list)\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    if not edges_df.empty:\n",
    "        edge_index = torch.tensor(edges_df[['src', 'dst']].to_pandas().values.T, dtype=torch.long)\n",
    "        logging.info(f\"Edge index created with {edge_index.shape[1]} edges\")\n",
    "        max_index = nodes_df['index'].max()\n",
    "        if edge_index.max() > max_index or edge_index.min() < 0:\n",
    "            logging.warning(f\"Edge indices out of bounds: min={edge_index.min()}, max={edge_index.max()}, expected max={max_index}\")\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        logging.warning(\"No edges found in graph.\")\n",
    "\n",
    "    data = Data(\n",
    "        x=features_tensor,\n",
    "        edge_index=edge_index,\n",
    "        y=labels_tensor\n",
    "    )\n",
    "\n",
    "    data.node_types = node_types\n",
    "\n",
    "    logging.info(f\"Prepared GNN data: {features_tensor.shape[0]} nodes, {edge_index.shape[1]} edges\")\n",
    "    logging.info(f\"Feature matrix shape: {features_tensor.shape}\")\n",
    "    logging.info(f\"Label tensor shape: {labels_tensor.shape}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9a6b5",
   "metadata": {},
   "source": [
    "Cell 9: WalkabilityGNN, train_gnn_model, predict_walkability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "635ecc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNWalkabilityPredictor(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GNNWalkabilityPredictor, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 64, heads=2, concat=True)\n",
    "        self.bn1 = BatchNorm(64 * 2)\n",
    "        self.conv2 = GATConv(64 * 2, 32, heads=1, concat=True)\n",
    "        self.bn2 = BatchNorm(32)\n",
    "        self.fc1 = torch.nn.Linear(32, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        if edge_index.numel() > 0:\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = self.bn2(x)\n",
    "            x = F.relu(x)\n",
    "        else:\n",
    "            logging.warning(\"No edges in the graph. Using linear layer for node features only.\")\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "def train_gnn_model(data_gnn):\n",
    "    logging.info(\"Stage 4: Training GNN model...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_gnn = data_gnn.to(device)\n",
    "    \n",
    "    neighborhood_mask = np.array([t == 'neighborhood' for t in data_gnn.node_types])\n",
    "    train_indices = np.where(neighborhood_mask)[0]\n",
    "    \n",
    "    if len(train_indices) == 0:\n",
    "        logging.error(\"No neighborhood nodes found for training.\")\n",
    "        raise ValueError(\"No neighborhood nodes found for training.\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    train_idx = np.random.choice(train_indices, size=int(0.8 * len(train_indices)), replace=False)\n",
    "    val_idx = np.setdiff1d(train_indices, train_idx)\n",
    "    \n",
    "    train_mask = torch.zeros(data_gnn.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(data_gnn.num_nodes, dtype=torch.bool)\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    data_gnn.train_mask = train_mask\n",
    "    data_gnn.val_mask = val_mask\n",
    "    \n",
    "    neighborhood_labels = data_gnn.y[neighborhood_mask].cpu().numpy()\n",
    "    logging.info(f\"Target (walkability_score) distribution for neighborhood nodes:\\n{pd.Series(neighborhood_labels.flatten()).describe()}\")\n",
    "    \n",
    "    model = GNNWalkabilityPredictor(num_features=data_gnn.x.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = os.path.join(CHECKPOINT_DIR, 'best_gnn_model.pth')\n",
    "    epochs = 300\n",
    "    patience = 20\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training epochs\"):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_gnn)\n",
    "        loss = criterion(out[data_gnn.train_mask], data_gnn.y[data_gnn.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(data_gnn)\n",
    "            val_loss = criterion(val_out[data_gnn.val_mask], data_gnn.y[data_gnn.val_mask])\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            logging.info(f\"Epoch {epoch}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                logging.info(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    logging.info(\"Finished training GNN model.\")\n",
    "    return model\n",
    "\n",
    "def predict_walkability(G, model):\n",
    "    \"\"\"\n",
    "    Predict walkability scores using the trained GNN model.\n",
    "    \n",
    "    Args:\n",
    "        G (cugraph.Graph): The city graph with nodes and edges.\n",
    "        model (GNNWalkabilityPredictor): The trained GNN model.\n",
    "    \n",
    "    Returns:\n",
    "        cugraph.Graph: Updated graph with GNN-predicted walkability scores.\n",
    "    \"\"\"\n",
    "    logging.info(\"Predicting walkability with GNN...\")\n",
    "    nodes_df = G._nodes.to_pandas()\n",
    "    \n",
    "    data = prepare_gnn_data(G)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(data).squeeze()\n",
    "    \n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions = np.clip(predictions, 0, 1)\n",
    "    \n",
    "    nodes_df['walkability_gnn'] = np.nan\n",
    "    nodes_df.loc[nodes_df['type'] == 'neighborhood', 'walkability_gnn'] = predictions[nodes_df['type'] == 'neighborhood']\n",
    "    \n",
    "    G._nodes = cudf.from_pandas(nodes_df)\n",
    "    logging.info(f\"Walkability GNN stats after prediction:\\n{nodes_df[nodes_df['type'] == 'neighborhood']['walkability_gnn'].describe()}\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406821f",
   "metadata": {},
   "source": [
    "Cell 10: Interactive Map Generation (create_interactive_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9d059c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_map(G, data):\n",
    "    \"\"\"Generate an interactive Kepler.gl map to visualize walkability scores.\"\"\"\n",
    "    logging.info(\"Generating interactive Kepler.gl map...\")\n",
    "    \n",
    "    nodes_df = G._nodes.to_pandas()\n",
    "    neighborhoods_gdf = data['neighborhoods'].copy()\n",
    "\n",
    "    # Standardize LIE_NAME for merging\n",
    "    nodes_df['LIE_NAME'] = nodes_df['LIE_NAME'].astype(str).str.strip()\n",
    "    neighborhoods_gdf['LIE_NAME'] = neighborhoods_gdf['LIE_NAME'].astype(str).str.strip()\n",
    "\n",
    "    # Filter for neighborhood nodes and select necessary columns\n",
    "    neighborhood_nodes = nodes_df[nodes_df['type'] == 'neighborhood'][['LIE_NAME', 'walkability_score', 'walkability_gnn', 'walkability_category']]\n",
    "\n",
    "    # Log for debugging\n",
    "    nodes_lie_names = set(neighborhood_nodes['LIE_NAME'])\n",
    "    gdf_lie_names = set(neighborhoods_gdf['LIE_NAME'])\n",
    "    logging.info(f\"Neighborhood nodes count: {len(neighborhood_nodes)}\")\n",
    "    logging.info(f\"Neighborhoods_gdf count: {len(neighborhoods_gdf)}\")\n",
    "    logging.info(f\"Sample LIE_NAME in nodes_df: {list(nodes_lie_names)[:5]}\")\n",
    "    logging.info(f\"Sample LIE_NAME in neighborhoods_gdf: {list(gdf_lie_names)[:5]}\")\n",
    "    logging.info(f\"Common LIE_NAMEs: {len(nodes_lie_names & gdf_lie_names)}\")\n",
    "    logging.info(f\"Nodes LIE_NAMEs not in GDF: {list(nodes_lie_names - gdf_lie_names)}\")\n",
    "    logging.info(f\"GDF LIE_NAMEs not in nodes: {list(gdf_lie_names - nodes_lie_names)}\")\n",
    "    logging.info(f\"Nodes nulls: {neighborhood_nodes.isna().sum().to_dict()}\")\n",
    "    logging.info(f\"GDF geometry nulls: {neighborhoods_gdf['geometry'].isna().sum()}\")\n",
    "\n",
    "    # Merge data\n",
    "    map_data = neighborhoods_gdf[['LIE_NAME', 'geometry']].merge(\n",
    "        neighborhood_nodes,\n",
    "        on='LIE_NAME',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Drop duplicates in-place\n",
    "    map_data.drop_duplicates(subset=['LIE_NAME'], keep='first', inplace=True)\n",
    "\n",
    "    # Log merge results and score distributions\n",
    "    logging.info(f\"Merged map_data rows: {len(map_data)}\")\n",
    "    logging.info(f\"Walkability score nulls: {map_data['walkability_score'].isna().sum()}\")\n",
    "    logging.info(f\"Walkability GNN nulls: {map_data['walkability_gnn'].isna().sum()}\")\n",
    "    logging.info(f\"Walkability score distribution in map_data:\\n{map_data['walkability_score'].describe()}\")\n",
    "    logging.info(f\"Walkability GNN distribution in map_data:\\n{map_data['walkability_gnn'].describe()}\")\n",
    "    logging.info(f\"Walkability category distribution in map_data:\\n{map_data['walkability_category'].value_counts()}\")\n",
    "\n",
    "    # Fill NaN values\n",
    "    map_data['walkability_score'] = map_data['walkability_score'].fillna(0)\n",
    "    map_data['walkability_gnn'] = map_data['walkability_gnn'].fillna(0)\n",
    "    map_data['walkability_category'] = map_data['walkability_category'].fillna('low')\n",
    "\n",
    "    # Convert to GeoDataFrame and transform CRS\n",
    "    map_data = gpd.GeoDataFrame(map_data, geometry='geometry', crs='EPSG:3826')\n",
    "    map_data['geometry'] = map_data['geometry'].to_crs('EPSG:4326')\n",
    "    \n",
    "    # Prepare data for Kepler.gl\n",
    "    kepler_data = {\n",
    "        'neighborhoods': map_data[['LIE_NAME', 'walkability_score', 'walkability_gnn', 'walkability_category', 'geometry']].to_json()\n",
    "    }\n",
    "\n",
    "    # Kepler.gl configuration\n",
    "    config = {\n",
    "        \"version\": \"v1\",\n",
    "        \"config\": {\n",
    "            \"visState\": {\n",
    "                \"layers\": [\n",
    "                    {\n",
    "                        \"id\": \"neighborhoods\",\n",
    "                        \"type\": \"geojson\",\n",
    "                        \"config\": {\n",
    "                            \"dataId\": \"neighborhoods\",\n",
    "                            \"label\": \"Neighborhoods\",\n",
    "                            \"color\": [18, 147, 154],\n",
    "                            \"columns\": {\n",
    "                                \"geojson\": \"geometry\"\n",
    "                            },\n",
    "                            \"isVisible\": True,\n",
    "                            \"visConfig\": {\n",
    "                                \"opacity\": 0.7,\n",
    "                                \"strokeOpacity\": 0.9,\n",
    "                                \"thickness\": 1,\n",
    "                                \"strokeColor\": [255, 255, 255],\n",
    "                                \"colorRange\": {\n",
    "                                    \"name\": \"Global Warming\",\n",
    "                                    \"type\": \"sequential\",\n",
    "                                    \"colors\": [\n",
    "                                        \"#5A1846\", \"#900C3F\", \"#C70039\",\n",
    "                                        \"#E3611C\", \"#F1920E\", \"#FFC107\"\n",
    "                                    ]\n",
    "                                },\n",
    "                                \"strokeColorRange\": {\n",
    "                                    \"name\": \"Global Warming\",\n",
    "                                    \"type\": \"sequential\",\n",
    "                                    \"colors\": [\n",
    "                                        \"#5A1846\", \"#900C3F\", \"#C70039\",\n",
    "                                        \"#E3611C\", \"#F1920E\", \"#FFC107\"\n",
    "                                    ]\n",
    "                                },\n",
    "                                \"colorField\": {\n",
    "                                    \"name\": \"walkability_gnn\",\n",
    "                                    \"type\": \"real\"\n",
    "                                },\n",
    "                                \"colorScale\": \"quantile\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"visualChannels\": {\n",
    "                            \"colorField\": {\n",
    "                                \"name\": \"walkability_gnn\",\n",
    "                                \"type\": \"real\"\n",
    "                            },\n",
    "                            \"colorScale\": \"quantile\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"interactionConfig\": {\n",
    "                    \"tooltip\": {\n",
    "                        \"fieldsToShow\": {\n",
    "                            \"neighborhoods\": [\n",
    "                                {\"name\": \"LIE_NAME\", \"format\": None},\n",
    "                                {\"name\": \"walkability_score\", \"format\": \"{:.3f}\"},\n",
    "                                {\"name\": \"walkability_gnn\", \"format\": \"{:.3f}\"},\n",
    "                                {\"name\": \"walkability_category\", \"format\": None}\n",
    "                            ]\n",
    "                        },\n",
    "                        \"enabled\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"mapState\": {\n",
    "                \"latitude\": 25.0330,\n",
    "                \"longitude\": 121.5654,\n",
    "                \"zoom\": 11\n",
    "            },\n",
    "            \"mapStyle\": {\n",
    "                \"styleType\": \"dark\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    map_1 = KeplerGl(height=800, data=kepler_data, config=config)\n",
    "    map_path = os.path.join(BASE_DIR, 'taipei_walkability_map.html')\n",
    "    map_1.save_to_html(file_name=map_path)\n",
    "    logging.info(f\"Interactive map generated and saved as {map_path}\")\n",
    "    print(f\"Map saved to {map_path}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0683d",
   "metadata": {},
   "source": [
    "Cell 11: Main Execution (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f13b11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:48:50,546 - INFO - Ensured subgraph directory exists: /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/subgraphs\n",
      "2025-04-23 11:48:50,548 - INFO - Stage 1: Loading and preparing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting load_and_prepare_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/8 [00:00<?, ?it/s]2025-04-23 11:48:50,670 - INFO - Loaded neighborhoods with shape (456, 57)\n",
      "Loading files:  12%|        | 1/8 [00:00<00:00,  8.24it/s]2025-04-23 11:48:52,003 - INFO - Loaded buildings with shape (74306, 9)\n",
      "Loading files:  25%|       | 2/8 [00:01<00:05,  1.20it/s]2025-04-23 11:48:52,071 - INFO - Loaded roads with shape (81444, 2)\n",
      "2025-04-23 11:48:52,097 - INFO - Loaded trees with shape (5019, 12)\n",
      "2025-04-23 11:48:52,179 - INFO - Loaded transit with shape (29892, 11)\n",
      "Loading files:  62%|   | 5/8 [00:01<00:00,  3.59it/s]2025-04-23 11:48:52,849 - INFO - Loaded urban_masterplan with shape (15521, 15)\n",
      "Loading files:  75%|  | 6/8 [00:02<00:00,  2.64it/s]2025-04-23 11:48:53,643 - INFO - Loaded accidents with shape (56133, 8)\n",
      "Loading files:  88%| | 7/8 [00:03<00:00,  2.04it/s]2025-04-23 11:48:53,645 - INFO - Columns in population_df after loading: ['LIE_NAME', 'Total_Population', 'Elderly_Percentage']\n",
      "2025-04-23 11:48:53,646 - INFO - Loaded population with shape (456, 3)\n",
      "Loading files: 100%|| 8/8 [00:03<00:00,  2.58it/s]\n",
      "2025-04-23 11:48:53,647 - INFO - Columns in neighborhoods_gdf after loading: ['LIE_NAME', 'SECT_NAME', '2024population', 'land_use_city_open_area_count', 'land_use_city_open_area_area_m2', 'land_use_city_open_area_percent', 'land_use_commercial_count', 'land_use_commercial_area_m2', 'land_use_commercial_percent', 'land_use_infrastructure_count', 'land_use_infrastructure_area_m2', 'land_use_infrastructure_percent', 'land_use_government_count', 'land_use_government_area_m2', 'land_use_government_percent', 'land_use_public_transportation_count', 'land_use_public_transportation_area_m2', 'land_use_public_transportation_percent', 'land_use_education_count', 'land_use_education_area_m2', 'land_use_education_percent', 'land_use_medical_count', 'land_use_medical_area_m2', 'land_use_medical_percent', 'land_use_amenity_count', 'land_use_amenity_area_m2', 'land_use_amenity_percent', 'land_use_road_count', 'land_use_road_area_m2', 'land_use_road_percent', 'land_use_pedestrian_count', 'land_use_pedestrian_area_m2', 'land_use_pedestrian_percent', 'land_use_natural_count', 'land_use_natural_area_m2', 'land_use_natural_percent', 'land_use_special_zone_count', 'land_use_special_zone_area_m2', 'land_use_special_zone_percent', 'land_use_river_count', 'land_use_river_area_m2', 'land_use_river_percent', 'land_use_military_count', 'land_use_military_area_m2', 'land_use_military_percent', 'land_use_residential_count', 'land_use_residential_area_m2', 'land_use_residential_percent', 'land_use_industrial_count', 'land_use_industrial_area_m2', 'land_use_industrial_percent', 'land_use_agriculture_count', 'land_use_agriculture_area_m2', 'land_use_agriculture_percent', 'ndvi_mean', 'ndvi_median', 'geometry']\n",
      "2025-04-23 11:48:53,845 - INFO - Converted buildings to CRS EPSG:3826\n",
      "2025-04-23 11:48:53,896 - INFO - Converted trees to CRS EPSG:3826\n",
      "2025-04-23 11:48:53,933 - INFO - Converted transit to CRS EPSG:3826\n",
      "2025-04-23 11:48:54,017 - INFO - Converted urban_masterplan to CRS EPSG:3826\n",
      "2025-04-23 11:48:54,054 - INFO - Converted accidents to CRS EPSG:3826\n",
      "2025-04-23 11:48:58,835 - INFO - Computing intersections for neighborhoods...\n",
      "2025-04-23 11:48:58,837 - INFO - Columns in roads_gdf after loading: ['class', 'geometry']\n",
      "2025-04-23 11:48:58,838 - INFO - Extracting endpoints from road segments...\n",
      "Extracting endpoints: 100%|| 81444/81444 [00:04<00:00, 17157.15it/s]\n",
      "2025-04-23 11:49:03,746 - INFO - Building endpoint-to-road mapping...\n",
      "Building endpoint-to-road mapping: 100%|| 162888/162888 [00:02<00:00, 54571.67it/s]\n",
      "2025-04-23 11:49:06,733 - INFO - Identifying intersections...\n",
      "Identifying intersections: 100%|| 101237/101237 [00:00<00:00, 1130814.96it/s]\n",
      "2025-04-23 11:49:06,837 - INFO - Counting intersections per neighborhood...\n",
      "2025-04-23 11:49:06,889 - WARNING - 'area_km2' column missing in neighborhoods_gdf. Computing from geometry...\n",
      "2025-04-23 11:49:06,892 - INFO - Computed area_km2 stats:\n",
      "count    456.000000\n",
      "mean       0.588925\n",
      "std        1.351428\n",
      "min        0.031744\n",
      "25%        0.134566\n",
      "50%        0.209650\n",
      "75%        0.425264\n",
      "max       16.324434\n",
      "Name: area_km2, dtype: float64\n",
      "2025-04-23 11:49:06,894 - INFO - Intersection count stats:\n",
      "count    456.000000\n",
      "mean      33.800439\n",
      "std       24.763978\n",
      "min        1.000000\n",
      "25%       16.000000\n",
      "50%       26.000000\n",
      "75%       46.000000\n",
      "max      185.000000\n",
      "Name: intersection_count, dtype: float64\n",
      "2025-04-23 11:49:06,895 - INFO - Intersection density stats:\n",
      "count    456.000000\n",
      "mean     126.190854\n",
      "std       83.149602\n",
      "min        2.960154\n",
      "25%       66.874411\n",
      "50%      111.292996\n",
      "75%      165.079134\n",
      "max      490.471026\n",
      "Name: intersection_density, dtype: float64\n",
      "2025-04-23 11:49:06,907 - INFO - Saved neighborhoods with intersections to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/neighborhoods_with_intersections.geoparquet\n",
      "2025-04-23 11:49:06,908 - INFO - Computing tree count per neighborhood...\n",
      "2025-04-23 11:49:06,950 - INFO - Computing transit count per neighborhood...\n",
      "2025-04-23 11:49:07,061 - INFO - Computing accident count per neighborhood...\n",
      "2025-04-23 11:49:07,977 - INFO - Computing road density per neighborhood...\n",
      "2025-04-23 11:49:07,978 - INFO - Columns in roads_gdf before computing road density: ['class', 'geometry']\n",
      "2025-04-23 11:49:07,978 - WARNING - 'length_m' column missing in roads_gdf. Computing from geometry...\n",
      "2025-04-23 11:49:07,986 - INFO - Computed length_m stats:\n",
      "count     81444.000000\n",
      "mean        145.622456\n",
      "std        2304.902398\n",
      "min           0.030284\n",
      "25%          28.160770\n",
      "50%          61.698697\n",
      "75%         130.534001\n",
      "max      426414.891763\n",
      "Name: length_m, dtype: float64\n",
      "2025-04-23 11:49:08,334 - INFO - Road density stats:\n",
      "count     456.000000\n",
      "mean      158.024830\n",
      "std       171.789340\n",
      "min         7.561174\n",
      "25%        55.500294\n",
      "50%        96.985664\n",
      "75%       214.942848\n",
      "max      1657.324822\n",
      "Name: road_density, dtype: float64\n",
      "2025-04-23 11:49:08,334 - INFO - Merging population data...\n",
      "2025-04-23 11:49:08,335 - WARNING - Expected columns ['total_population', 'elderly_percentage'] not found in population_df. Attempting to find alternatives...\n",
      "2025-04-23 11:49:08,336 - INFO - Found alternative for total_population: Total_Population\n",
      "2025-04-23 11:49:08,336 - INFO - Found alternative for elderly_percentage: Elderly_Percentage\n",
      "2025-04-23 11:49:08,339 - INFO - Computing land use percentages for neighborhoods...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Percentage Calculation Process ---\n",
      "\n",
      "Neighborhood:  (Index: 373)\n",
      "Total unique master plan area: 63777.59 m\n",
      "Area of City_Open_Area (priority 10): 478.13 m\n",
      "Area of Education (priority 6): 8173.36 m\n",
      "Area of Commercial (priority 4): 23017.42 m\n",
      "Area of Residential (priority 3): 32108.69 m\n",
      "\n",
      "Percentages:\n",
      "City_Open_Area: 0.75%\n",
      "Education: 12.82%\n",
      "Commercial: 36.09%\n",
      "Residential: 50.34%\n",
      "Sum of percentages: 100.00%\n",
      "\n",
      "Neighborhood:  (Index: 39)\n",
      "Total unique master plan area: 1061285.95 m\n",
      "Area of Education (priority 6): 80442.15 m\n",
      "Area of Residential (priority 3): 196204.41 m\n",
      "Area of Natural (priority 2): 775753.11 m\n",
      "Area of River (priority 1): 2754.93 m\n",
      "Area of Government (priority 1): 6131.35 m\n",
      "\n",
      "Percentages:\n",
      "Education: 7.58%\n",
      "Residential: 18.49%\n",
      "Natural: 73.10%\n",
      "River: 0.26%\n",
      "Government: 0.58%\n",
      "Sum of percentages: 100.00%\n",
      "\n",
      "Neighborhood:  (Index: 340)\n",
      "Total unique master plan area: 98073.11 m\n",
      "Area of City_Open_Area (priority 10): 4608.53 m\n",
      "Area of Public_Transportation (priority 8): 5304.93 m\n",
      "Area of Commercial (priority 4): 15463.83 m\n",
      "Area of Residential (priority 3): 50273.32 m\n",
      "Area of Special_Zone (priority 1): 22422.50 m\n",
      "\n",
      "Percentages:\n",
      "City_Open_Area: 4.70%\n",
      "Public_Transportation: 5.41%\n",
      "Commercial: 15.77%\n",
      "Residential: 51.26%\n",
      "Special_Zone: 22.86%\n",
      "Sum of percentages: 100.00%\n",
      "--- End of Percentage Calculation Process ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:49:09,013 - WARNING - Topology error for category Residential in neighborhood : TopologyException: found non-noded intersection between LINESTRING (305235 2.7814e+06, 305232 2.7814e+06) and LINESTRING (305233 2.7814e+06, 305238 2.7814e+06) at 305235.20948094811 2781398.7662400398\n",
      "2025-04-23 11:49:09,274 - WARNING - Topology error for category Natural in neighborhood : TopologyException: found non-noded intersection between LINESTRING (305351 2.78185e+06, 305350 2.78185e+06) and LINESTRING (305350 2.78185e+06, 305350 2.78185e+06) at 305349.93489947024 2781846.2793679931\n",
      "2025-04-23 11:49:10,096 - WARNING - Topology error for category Agriculture in neighborhood : TopologyException: found non-noded intersection between LINESTRING (299444 2.78096e+06, 299444 2.78096e+06) and LINESTRING (299444 2.78096e+06, 299444 2.78096e+06) at 299443.97226843517 2780959.3288864125\n",
      "2025-04-23 11:49:11,086 - WARNING - Topology error for category Pedestrian in neighborhood : TopologyException: found non-noded intersection between LINESTRING (296871 2.77919e+06, 296870 2.77919e+06) and LINESTRING (296871 2.77919e+06, 296869 2.77919e+06) at 296869.99175471725 2779190.4644867191\n",
      "2025-04-23 11:49:11,209 - WARNING - Topology error for category Infrastructure in neighborhood : TopologyException: found non-noded intersection between LINESTRING (296911 2.77884e+06, 296911 2.77884e+06) and LINESTRING (296911 2.77884e+06, 296911 2.77884e+06) at 296911.44015440479 2778839.5138171767\n",
      "2025-04-23 11:49:13,760 - WARNING - Topology error for category Government in neighborhood : TopologyException: found non-noded intersection between LINESTRING (301533 2.77502e+06, 301533 2.77502e+06) and LINESTRING (301533 2.77502e+06, 301533 2.77502e+06) at 301532.96899694926 2775020.80209503\n",
      "2025-04-23 11:49:15,145 - WARNING - Topology error for category River in neighborhood : TopologyException: found non-noded intersection between LINESTRING (312333 2.77328e+06, 312333 2.77328e+06) and LINESTRING (312332 2.77328e+06, 312333 2.77328e+06) at 312332.69765419257 2773277.367184672\n",
      "2025-04-23 11:49:16,020 - WARNING - Topology error for category Road in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311644 2.77189e+06, 311657 2.7719e+06) and LINESTRING (311630 2.77189e+06, 311657 2.7719e+06) at 311657.42832653591 2771895.1006993004\n",
      "2025-04-23 11:49:16,732 - WARNING - Topology error for category Special_Zone in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) and LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) at 311955.22635489638 2771352.7457217239\n",
      "2025-04-23 11:49:16,751 - WARNING - Topology error for category Road in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311345 2.77161e+06, 311344 2.77161e+06) and LINESTRING (311344 2.77161e+06, 311344 2.77161e+06) at 311344.20670072001 2771612.8331892812\n",
      "2025-04-23 11:49:16,766 - WARNING - Topology error for category Infrastructure in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) and LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) at 311955.22635489638 2771352.7457217239\n",
      "2025-04-23 11:49:16,787 - WARNING - Topology error for category Government in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311038 2.77019e+06, 311035 2.77019e+06) and LINESTRING (311038 2.77019e+06, 311035 2.77019e+06) at 311037.75737428927 2770193.7686056904\n",
      "2025-04-23 11:49:16,800 - WARNING - Topology error for category River in neighborhood : TopologyException: found non-noded intersection between LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) and LINESTRING (311955 2.77135e+06, 311955 2.77135e+06) at 311955.22635489638 2771352.7457217239\n",
      "2025-04-23 11:49:18,662 - WARNING - Topology error for category Infrastructure in neighborhood : TopologyException: found non-noded intersection between LINESTRING (312826 2.76904e+06, 312824 2.76904e+06) and LINESTRING (312825 2.76904e+06, 312824 2.76904e+06) at 312824.50008723215 2769040.8990552658\n",
      "2025-04-23 11:49:19,268 - WARNING - Topology error for category Commercial in neighborhood : TopologyException: found non-noded intersection between LINESTRING (307950 2.76963e+06, 307949 2.76962e+06) and LINESTRING (307949 2.76962e+06, 307949 2.76962e+06) at 307948.62715117587 2769624.3576414455\n",
      "2025-04-23 11:49:19,397 - WARNING - Topology error for category River in neighborhood : TopologyException: found non-noded intersection between LINESTRING (312138 2.77015e+06, 312138 2.77014e+06) and LINESTRING (312138 2.77015e+06, 312138 2.77014e+06) at 312138.34700008662 2770150.6440004231\n",
      "2025-04-23 11:49:21,774 - WARNING - Topology error for category Road in neighborhood : TopologyException: found non-noded intersection between LINESTRING (308001 2.76569e+06, 308001 2.76569e+06) and LINESTRING (308001 2.76569e+06, 308000 2.76568e+06) at 308000.95038661739 2765685.1649155417\n",
      "2025-04-23 11:49:22,126 - WARNING - Topology error for category Residential in neighborhood : TopologyException: found non-noded intersection between LINESTRING (304449 2.76649e+06, 304450 2.7665e+06) and LINESTRING (304449 2.76648e+06, 304450 2.7665e+06) at 304449.97013593506 2766495.7391462782\n",
      "2025-04-23 11:49:22,451 - WARNING - Topology error for category Commercial in neighborhood : TopologyException: found non-noded intersection between LINESTRING (307982 2.76418e+06, 307986 2.76418e+06) and LINESTRING (307982 2.76418e+06, 307984 2.76418e+06) at 307982.32430909772 2764175.6883213609\n",
      "2025-04-23 11:49:22,685 - WARNING - Topology error for category Residential in neighborhood : TopologyException: found non-noded intersection between LINESTRING (307982 2.76418e+06, 307986 2.76418e+06) and LINESTRING (307982 2.76418e+06, 307984 2.76418e+06) at 307982.32430909772 2764175.6883213609\n",
      "2025-04-23 11:49:22,739 - WARNING - Topology error for category Natural in neighborhood : TopologyException: found non-noded intersection between LINESTRING (310276 2.76631e+06, 310277 2.76631e+06) and LINESTRING (310277 2.76631e+06, 310277 2.76631e+06) at 310277.46693728981 2766309.5977024199\n",
      "2025-04-23 11:49:22,853 - WARNING - Topology error for category River in neighborhood : TopologyException: found non-noded intersection between LINESTRING (307907 2.76419e+06, 307910 2.76418e+06) and LINESTRING (307907 2.76419e+06, 307907 2.76419e+06) at 307906.68941059953 2764186.3632669998\n",
      "2025-04-23 11:49:22,890 - WARNING - Topology error for category Infrastructure in neighborhood : TopologyException: found non-noded intersection between LINESTRING (307982 2.76418e+06, 307986 2.76418e+06) and LINESTRING (307982 2.76418e+06, 307984 2.76418e+06) at 307982.32430909772 2764175.6883213609\n",
      "2025-04-23 11:49:22,953 - WARNING - Topology error for category Road in neighborhood : TopologyException: found non-noded intersection between LINESTRING (309012 2.76609e+06, 309011 2.76609e+06) and LINESTRING (309011 2.76609e+06, 309016 2.76609e+06) at 309011.33430958074 2766091.7154930364\n",
      "2025-04-23 11:49:24,266 - INFO - Finished loading and preparing data.\n",
      "2025-04-23 11:49:24,321 - INFO - Computing correlation between road types and accident density...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Structure Summary ---\n",
      "\n",
      "Dataset: neighborhoods\n",
      "Shape: (456, 67)\n",
      "Columns and Data Types:\n",
      "LIE_NAME                            object\n",
      "SECT_NAME                           object\n",
      "2024population                       int32\n",
      "land_use_city_open_area_count        int32\n",
      "land_use_city_open_area_area_m2    float64\n",
      "                                    ...   \n",
      "transit_count                        int64\n",
      "accident_count                       int64\n",
      "road_density                       float64\n",
      "total_population                     int64\n",
      "elderly_percentage                 float64\n",
      "Length: 67, dtype: object\n",
      "Missing values (total): 0\n",
      "Missing values per column:\n",
      "LIE_NAME                           0\n",
      "SECT_NAME                          0\n",
      "2024population                     0\n",
      "land_use_city_open_area_count      0\n",
      "land_use_city_open_area_area_m2    0\n",
      "                                  ..\n",
      "transit_count                      0\n",
      "accident_count                     0\n",
      "road_density                       0\n",
      "total_population                   0\n",
      "elderly_percentage                 0\n",
      "Length: 67, dtype: int64\n",
      "Unique LIE_NAME: 456\n",
      "Sample data (first 2 rows):\n",
      "  LIE_NAME SECT_NAME  2024population  land_use_city_open_area_count  \\\n",
      "0                          856                              0   \n",
      "1                         1509                              0   \n",
      "\n",
      "   land_use_city_open_area_area_m2  land_use_city_open_area_percent  \\\n",
      "0                              0.0                              0.0   \n",
      "1                              0.0                              0.0   \n",
      "\n",
      "   land_use_commercial_count  land_use_commercial_area_m2  \\\n",
      "0                          0                          0.0   \n",
      "1                          0                          0.0   \n",
      "\n",
      "   land_use_commercial_percent  land_use_infrastructure_count  ...  \\\n",
      "0                          0.0                              0  ...   \n",
      "1                          0.0                              4  ...   \n",
      "\n",
      "   intersection_count       area_m2   area_km2  intersection_density  \\\n",
      "0                 110  1.632443e+07  16.324434              6.738365   \n",
      "1                  94  1.171922e+07  11.719218              8.021013   \n",
      "\n",
      "   tree_count  transit_count  accident_count  road_density  total_population  \\\n",
      "0         106            400              70      7.561174               857   \n",
      "1          54            313              33      9.913151              1485   \n",
      "\n",
      "   elderly_percentage  \n",
      "0               28.24  \n",
      "1               25.72  \n",
      "\n",
      "[2 rows x 67 columns]\n",
      "\n",
      "Dataset: buildings\n",
      "Shape: (74306, 9)\n",
      "Columns and Data Types:\n",
      "full_id       object\n",
      "osm_id        object\n",
      "building      object\n",
      "            object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "Missing values (total): 49\n",
      "Missing values per column:\n",
      "full_id      0\n",
      "osm_id       0\n",
      "building    31\n",
      "           0\n",
      "         0\n",
      "        18\n",
      "         0\n",
      "         0\n",
      "geometry     0\n",
      "dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "    full_id   osm_id    building                    \\\n",
      "0  r2633015  2633015   dormitory  <NA>  <NA>  <NA>  Unknown  Unknown   \n",
      "1  r2633016  2633016  university  <NA>  <NA>  <NA>  Unknown  Unknown   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((304401.483 2780904.12, 304430.995 27...  \n",
      "1  POLYGON ((304357.549 2780790.65, 304352.56 278...  \n",
      "\n",
      "Dataset: roads\n",
      "Shape: (81444, 3)\n",
      "Columns and Data Types:\n",
      "class         object\n",
      "geometry    geometry\n",
      "length_m     float64\n",
      "dtype: object\n",
      "Missing values (total): 604\n",
      "Missing values per column:\n",
      "class       604\n",
      "geometry      0\n",
      "length_m      0\n",
      "dtype: int64\n",
      "Road class counts:\n",
      "class\n",
      "service          21575\n",
      "footway          19776\n",
      "residential      15429\n",
      "tertiary          5402\n",
      "steps             4301\n",
      "secondary         4059\n",
      "path              3857\n",
      "unclassified      1957\n",
      "primary           1292\n",
      "cycleway           878\n",
      "track              741\n",
      "trunk              609\n",
      "pedestrian         323\n",
      "motorway           316\n",
      "living_street      267\n",
      "unknown             56\n",
      "bridleway            2\n",
      "Name: count, dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "     class                                           geometry       length_m\n",
      "0     None  LINESTRING (324778.511 2780945.263, 324826.86 ...  426414.891763\n",
      "1  service  LINESTRING (296169.224 2759463.114, 296160.343...    1055.960489\n",
      "\n",
      "Dataset: trees\n",
      "Shape: (5019, 12)\n",
      "Columns and Data Types:\n",
      "id               object\n",
      "geometry       geometry\n",
      "version           int32\n",
      "sources          object\n",
      "subtype          object\n",
      "class            object\n",
      "surface          object\n",
      "names            object\n",
      "level           float64\n",
      "source_tags      object\n",
      "wikidata         object\n",
      "elevation       float64\n",
      "dtype: object\n",
      "Missing values (total): 24487\n",
      "Missing values per column:\n",
      "id                0\n",
      "geometry          0\n",
      "version           0\n",
      "sources           0\n",
      "subtype           0\n",
      "class             0\n",
      "surface        5013\n",
      "names          4553\n",
      "level          5015\n",
      "source_tags       0\n",
      "wikidata       4943\n",
      "elevation      4963\n",
      "dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "                                 id  \\\n",
      "0  08b4ba2399d31fff0003c5f62a41c335   \n",
      "1  08b4ba0ae3a22fff0003ca54f368c81d   \n",
      "\n",
      "                                            geometry  version  \\\n",
      "0  POLYGON ((161777.639 2544255.739, 161813.286 2...        0   \n",
      "1  POLYGON ((297620.639 2760911.484, 297592.092 2...        0   \n",
      "\n",
      "                                             sources subtype   class surface  \\\n",
      "0  [{'property': '', 'dataset': 'OpenStreetMap', ...    land  island    None   \n",
      "1  [{'property': '', 'dataset': 'OpenStreetMap', ...  forest    wood    None   \n",
      "\n",
      "                                               names  level  \\\n",
      "0  {'primary': '', 'common': [('af', 'Taiwan'),...    NaN   \n",
      "1                                               None    NaN   \n",
      "\n",
      "                               source_tags wikidata  elevation  \n",
      "0  [(place, island), (type, multipolygon)]   Q22502        NaN  \n",
      "1  [(natural, wood), (type, multipolygon)]     None        NaN  \n",
      "\n",
      "Dataset: transit\n",
      "Shape: (29892, 11)\n",
      "Columns and Data Types:\n",
      "id               object\n",
      "geometry       geometry\n",
      "version           int32\n",
      "sources          object\n",
      "subtype          object\n",
      "class            object\n",
      "surface          object\n",
      "names            object\n",
      "level           float64\n",
      "source_tags      object\n",
      "wikidata         object\n",
      "dtype: object\n",
      "Missing values (total): 101060\n",
      "Missing values per column:\n",
      "id                 0\n",
      "geometry           0\n",
      "version            0\n",
      "sources            0\n",
      "subtype            0\n",
      "class              0\n",
      "surface        28287\n",
      "names          17731\n",
      "level          25803\n",
      "source_tags        0\n",
      "wikidata       29239\n",
      "dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "                                 id  \\\n",
      "0  08b4ba0ac6758fff0001be0bbe7a4ada   \n",
      "1  08b4ba0ae332afff0001a76b5977464d   \n",
      "\n",
      "                                            geometry  version  \\\n",
      "0  LINESTRING (320296.896 2765488.056, 320042.372...        0   \n",
      "1                     POINT (296843.534 2759002.204)        0   \n",
      "\n",
      "                                             sources  subtype       class  \\\n",
      "0  [{'property': '', 'dataset': 'OpenStreetMap', ...    power  power_line   \n",
      "1  [{'property': '', 'dataset': 'OpenStreetMap', ...  barrier        gate   \n",
      "\n",
      "  surface names  level                         source_tags wikidata  \n",
      "0    None  None    NaN  [(power, line), (voltage, 345000)]     None  \n",
      "1    None  None    NaN                   [(barrier, gate)]     None  \n",
      "\n",
      "Dataset: urban_masterplan\n",
      "Shape: (15521, 15)\n",
      "Columns and Data Types:\n",
      "            object\n",
      "            object\n",
      "            object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "         object\n",
      "         object\n",
      "         object\n",
      "Category      object\n",
      "Area         float64\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "Missing values (total): 92705\n",
      "Missing values per column:\n",
      "              0\n",
      "              5\n",
      "              5\n",
      "        15508\n",
      "            5\n",
      "            5\n",
      "            0\n",
      "        15409\n",
      "        15205\n",
      "       15521\n",
      "       15521\n",
      "       15521\n",
      "Category        0\n",
      "Area            0\n",
      "geometry        0\n",
      "dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "                     \\\n",
      "0  1  32  19  None  PEA        None  None  None  None  None   \n",
      "1  2  32  19  None  PEA        None  None  None  None  None   \n",
      "\n",
      "         Category      Area                                           geometry  \n",
      "0  City_Open_Area   823.190  MULTIPOLYGON (((303340.099 2771175.776, 303329...  \n",
      "1  City_Open_Area  4721.047  MULTIPOLYGON (((303230.925 2771108.301, 303088...  \n",
      "\n",
      "Dataset: accidents\n",
      "Shape: (56133, 8)\n",
      "Columns and Data Types:\n",
      "Month            object\n",
      "Day               int32\n",
      "Hours             int32\n",
      "Minute            int32\n",
      "Location         object\n",
      "Speed_limit       int32\n",
      "Roadtype          int32\n",
      "geometry       geometry\n",
      "dtype: object\n",
      "Missing values (total): 0\n",
      "Missing values per column:\n",
      "Month          0\n",
      "Day            0\n",
      "Hours          0\n",
      "Minute         0\n",
      "Location       0\n",
      "Speed_limit    0\n",
      "Roadtype       0\n",
      "geometry       0\n",
      "dtype: int64\n",
      "Sample data (first 2 rows):\n",
      "     Month  Day  Hours  Minute              Location  Speed_limit  Roadtype  \\\n",
      "0  January    1      0      46  44216           50         4   \n",
      "1  January    1      0      46  44216           50         4   \n",
      "\n",
      "                        geometry  \n",
      "0  POINT (305807.42 2770096.759)  \n",
      "1  POINT (305807.42 2770096.759)  \n",
      "\n",
      "Dataset: population\n",
      "Shape: (456, 3)\n",
      "Columns and Data Types:\n",
      "LIE_NAME               object\n",
      "Total_Population        int64\n",
      "Elderly_Percentage    float64\n",
      "dtype: object\n",
      "Missing values (total): 0\n",
      "Missing values per column:\n",
      "LIE_NAME              0\n",
      "Total_Population      0\n",
      "Elderly_Percentage    0\n",
      "dtype: int64\n",
      "Unique LIE_NAME: 456\n",
      "Sample data (first 2 rows):\n",
      "  LIE_NAME  Total_Population  Elderly_Percentage\n",
      "0                   12021               16.10\n",
      "1                   11200               22.68\n",
      "--- End of Data Structure Summary ---\n",
      "\n",
      "Starting compute_road_type_accident_correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:49:24,837 - INFO - Assigning accidents to nearest road...\n",
      "2025-04-23 11:49:29,861 - INFO - Matched 56133 accidents out of 56133\n",
      "2025-04-23 11:49:29,866 - INFO - Reassigning 4991 accidents from footway/cycleway...\n",
      "2025-04-23 11:49:29,976 - INFO - Reassigned 1429 accidents to wider roads\n",
      "2025-04-23 11:49:29,983 - INFO - Accidents by road type:\n",
      "class\n",
      "bridleway            0\n",
      "cycleway           247\n",
      "footway           3315\n",
      "living_street       79\n",
      "motorway           109\n",
      "path                86\n",
      "pedestrian          84\n",
      "primary           6535\n",
      "residential      10110\n",
      "secondary        16180\n",
      "service           5011\n",
      "steps               47\n",
      "tertiary          9135\n",
      "track                8\n",
      "trunk             2493\n",
      "unclassified      1665\n",
      "unknown             66\n",
      "Name: accident_count, dtype: int64\n",
      "2025-04-23 11:49:29,990 - INFO - Road type counts:\n",
      "class\n",
      "service          21204\n",
      "footway          16755\n",
      "residential      14861\n",
      "tertiary          5113\n",
      "secondary         3869\n",
      "path              3610\n",
      "steps             2968\n",
      "unclassified      1894\n",
      "primary           1209\n",
      "cycleway           825\n",
      "track              716\n",
      "trunk              593\n",
      "motorway           313\n",
      "pedestrian         297\n",
      "living_street      264\n",
      "unknown             54\n",
      "bridleway            2\n",
      "Name: count, dtype: int64\n",
      "2025-04-23 11:49:30,000 - INFO - Spearman's correlation between road width rank and accident density: 0.798 (p-value: 0.001)\n",
      "2025-04-23 11:49:30,000 - INFO - Computing average road accident density per neighborhood...\n",
      "2025-04-23 11:49:30,004 - INFO - Roads bounds: [ -49201.34316331 2687086.8646322   340402.47812579 3107530.84473387]\n",
      "2025-04-23 11:49:30,005 - INFO - Neighborhoods bounds: [ 296266.05303084 2761514.89561711  317197.26073793 2789176.16901603]\n",
      "2025-04-23 11:49:30,010 - INFO - Roads DataFrame shape before join: (75149, 6)\n",
      "2025-04-23 11:49:30,010 - INFO - Neighborhoods DataFrame shape before join: (456, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road type counts:\n",
      "class\n",
      "service          21204\n",
      "footway          16755\n",
      "residential      14861\n",
      "tertiary          5113\n",
      "secondary         3869\n",
      "path              3610\n",
      "steps             2968\n",
      "unclassified      1894\n",
      "primary           1209\n",
      "cycleway           825\n",
      "track              716\n",
      "trunk              593\n",
      "motorway           313\n",
      "pedestrian         297\n",
      "living_street      264\n",
      "unknown             54\n",
      "bridleway            2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Road Type Accident Density Summary ---\n",
      "            class    length_m  accident_count  accident_density  width_rank\n",
      "1        cycleway   263682.07             245              0.26           1\n",
      "2         footway  1767503.72            3235              0.73           1\n",
      "3   living_street    23929.78              77              1.58           3\n",
      "4        motorway   215317.82             109              2.74           5\n",
      "5            path   720602.60              84              0.09           1\n",
      "6      pedestrian    31830.26              82              0.47           1\n",
      "7         primary   212330.19            6433             44.39           4\n",
      "8     residential  1455020.72           10037              4.87           3\n",
      "9       secondary   534770.12           15993             36.32           4\n",
      "10        service  2502054.44            5001              0.68           2\n",
      "11          steps   161013.29              37              0.10           1\n",
      "12       tertiary   755660.86            9060             11.17           3\n",
      "13          track   159053.47               8              0.02           2\n",
      "14          trunk   265713.76            2469             11.69           5\n",
      "Spearman's correlation: 0.798 (p-value: 0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:49:30,324 - INFO - Road-neighborhood join resulted in 85340 matches with columns: ['index_left', 'geometry', 'class', 'length_m', 'width_rank', 'accident_density', 'index_right0', 'index_right', 'LIE_NAME']\n",
      "2025-04-23 11:49:30,329 - INFO - Assigned avg_road_accident_density to 0 neighborhoods\n",
      "2025-04-23 11:49:30,332 - INFO - Avg road accident density stats:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: avg_road_accident_density, dtype: float64\n",
      "2025-04-23 11:49:30,471 - INFO - Bar chart saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_bar.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar chart saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_bar.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:49:30,922 - INFO - Box chart saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_box.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box chart saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_box.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:49:31,194 - INFO - Scatter plot saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_scatter.png\n",
      "2025-04-23 11:49:31,197 - INFO - Top 3 road types by accident density:\n",
      "        class  accident_density\n",
      "7     primary             44.39\n",
      "9   secondary             36.32\n",
      "14      trunk             11.69\n",
      "2025-04-23 11:49:31,198 - INFO - Stage 2: Building city graph...\n",
      "2025-04-23 11:49:31,199 - INFO - Dataset neighborhoods column types:\n",
      "LIE_NAME                            object\n",
      "SECT_NAME                           object\n",
      "2024population                       int32\n",
      "land_use_city_open_area_count        int32\n",
      "land_use_city_open_area_area_m2    float64\n",
      "                                    ...   \n",
      "accident_count                       int64\n",
      "road_density                       float64\n",
      "total_population                     int64\n",
      "elderly_percentage                 float64\n",
      "avg_road_accident_density          float64\n",
      "Length: 68, dtype: object\n",
      "2025-04-23 11:49:31,207 - INFO - Dataset buildings column types:\n",
      "full_id       object\n",
      "osm_id        object\n",
      "building      object\n",
      "            object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,209 - INFO - Dataset roads column types:\n",
      "class         object\n",
      "geometry    geometry\n",
      "length_m     float64\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,211 - INFO - Dataset trees column types:\n",
      "id               object\n",
      "geometry       geometry\n",
      "version           int32\n",
      "sources          object\n",
      "subtype          object\n",
      "class            object\n",
      "surface          object\n",
      "names            object\n",
      "level           float64\n",
      "source_tags      object\n",
      "wikidata         object\n",
      "elevation       float64\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,215 - INFO - Dataset transit column types:\n",
      "id               object\n",
      "geometry       geometry\n",
      "version           int32\n",
      "sources          object\n",
      "subtype          object\n",
      "class            object\n",
      "surface          object\n",
      "names            object\n",
      "level           float64\n",
      "source_tags      object\n",
      "wikidata         object\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,218 - INFO - Dataset urban_masterplan column types:\n",
      "            object\n",
      "            object\n",
      "            object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "          object\n",
      "         object\n",
      "         object\n",
      "         object\n",
      "Category      object\n",
      "Area         float64\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,221 - INFO - Dataset accidents column types:\n",
      "Month            object\n",
      "Day               int32\n",
      "Hours             int32\n",
      "Minute            int32\n",
      "Location         object\n",
      "Speed_limit       int32\n",
      "Roadtype          int32\n",
      "geometry       geometry\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,223 - INFO - Dataset population column types:\n",
      "LIE_NAME               object\n",
      "Total_Population        int64\n",
      "Elderly_Percentage    float64\n",
      "dtype: object\n",
      "2025-04-23 11:49:31,224 - INFO - Constructing graph nodes...\n",
      "2025-04-23 11:49:31,224 - WARNING - 'area_m2' column missing in buildings_gdf. Computing from geometry...\n",
      "2025-04-23 11:49:31,239 - INFO - Computed area_m2 stats:\n",
      "count    74306.000000\n",
      "mean       326.713464\n",
      "std        783.686503\n",
      "min          0.603543\n",
      "25%         97.315016\n",
      "50%        182.929099\n",
      "75%        304.603966\n",
      "max      62939.914744\n",
      "Name: area_m2, dtype: float64\n",
      "2025-04-23 11:49:31,239 - INFO - Adding neighborhood nodes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatter plot saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/road_type_accident_scatter.png\n",
      "Top 3 road types by accident density:\n",
      "        class  accident_density\n",
      "7     primary             44.39\n",
      "9   secondary             36.32\n",
      "14      trunk             11.69\n",
      "Starting build_graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neighborhood nodes: 100%|| 456/456 [00:00<00:00, 22439.17it/s]\n",
      "2025-04-23 11:49:31,262 - INFO - Adding building nodes...\n",
      "Building nodes: 100%|| 74306/74306 [00:01<00:00, 47930.66it/s]\n",
      "2025-04-23 11:49:32,814 - INFO - Adding road nodes...\n",
      "Road nodes: 100%|| 81444/81444 [00:01<00:00, 47950.44it/s]\n",
      "2025-04-23 11:49:35,680 - INFO - Converting GeoDataFrames to cudf for GPU processing...\n",
      "2025-04-23 11:49:35,827 - INFO - Extracting bounding box coordinates...\n",
      "2025-04-23 11:49:46,911 - INFO - neighborhoods_cudf['min_x'] dtype: float64\n",
      "2025-04-23 11:49:46,912 - INFO - buildings_cudf['min_x'] dtype: float64\n",
      "2025-04-23 11:49:46,912 - INFO - roads_cudf['min_x'] dtype: float64\n",
      "2025-04-23 11:49:46,913 - INFO - Creating edges using GPU-accelerated spatial joins...\n",
      "2025-04-23 11:49:46,913 - INFO - Computing neighborhood-neighborhood edges...\n",
      "Neighborhood-Neighborhood edges: 100%|| 456/456 [00:30<00:00, 15.07it/s] \n",
      "2025-04-23 11:50:17,173 - INFO - Computing neighborhood-building edges...\n",
      "Neighborhood-Building edges: 100%|| 456/456 [00:31<00:00, 14.51it/s]\n",
      "2025-04-23 11:50:48,604 - INFO - Computing neighborhood-road edges...\n",
      "Neighborhood-Road edges: 100%|| 456/456 [00:34<00:00, 13.30it/s]\n",
      "2025-04-23 11:51:22,977 - INFO - Created 270909 total edges\n",
      "2025-04-23 11:51:23,010 - INFO - After validation, 270909 edges remain\n",
      "2025-04-23 11:51:23,013 - INFO - Sample edges after validation:\n",
      "   src  dst\n",
      "0    0    1\n",
      "1    0    2\n",
      "2    0    3\n",
      "3    0    4\n",
      "4    0    5\n",
      "2025-04-23 11:51:23,066 - INFO - Saving graph data to cache...\n",
      "2025-04-23 11:51:23,244 - INFO - Successfully saved graph data to cache.\n",
      "2025-04-23 11:51:23,245 - INFO - City graph constructed: 156206 nodes, 270909 edges\n",
      "2025-04-23 11:51:23,273 - INFO - Graph edge count: 270909\n",
      "2025-04-23 11:51:23,274 - INFO - Computing walkability scores for neighborhoods...\n",
      "2025-04-23 11:51:23,344 - INFO - LIE_NAME: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,348 - INFO - Geometry column: 0 nulls, 0 invalid geometries.\n",
      "2025-04-23 11:51:23,349 - INFO - ndvi_mean: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,349 - INFO - tree_count: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,350 - INFO - transit_count: 0 nulls, 1 zeros.\n",
      "2025-04-23 11:51:23,350 - INFO - intersection_density: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,351 - INFO - accident_count: 0 nulls, 1 zeros.\n",
      "2025-04-23 11:51:23,351 - INFO - area_km2: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,352 - INFO - avg_road_accident_density: 456 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,353 - INFO - elderly_percentage: 0 nulls, 0 zeros.\n",
      "2025-04-23 11:51:23,355 - INFO - land_use_city_open_area_percent stats:\n",
      "count    456.000000\n",
      "mean       6.221593\n",
      "std       11.560896\n",
      "min        0.000000\n",
      "25%        0.001498\n",
      "50%        2.200797\n",
      "75%        5.713038\n",
      "max       69.979037\n",
      "Name: land_use_city_open_area_percent, dtype: float64\n",
      "2025-04-23 11:51:23,357 - INFO - land_use_pedestrian_percent stats:\n",
      "count    456.000000\n",
      "mean       0.064544\n",
      "std        0.355046\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        4.837366\n",
      "Name: land_use_pedestrian_percent, dtype: float64\n",
      "2025-04-23 11:51:23,358 - INFO - land_use_public_transportation_percent stats:\n",
      "count    456.000000\n",
      "mean       0.613341\n",
      "std        4.689473\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       90.667497\n",
      "Name: land_use_public_transportation_percent, dtype: float64\n",
      "2025-04-23 11:51:23,360 - INFO - land_use_amenity_percent stats:\n",
      "count    456.000000\n",
      "mean       0.795890\n",
      "std        4.853974\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       65.017829\n",
      "Name: land_use_amenity_percent, dtype: float64\n",
      "2025-04-23 11:51:23,361 - INFO - land_use_education_percent stats:\n",
      "count    456.000000\n",
      "mean       7.542126\n",
      "std       12.095845\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.248535\n",
      "75%       11.645818\n",
      "max       75.589954\n",
      "Name: land_use_education_percent, dtype: float64\n",
      "2025-04-23 11:51:23,363 - INFO - land_use_medical_percent stats:\n",
      "count    456.000000\n",
      "mean       0.520363\n",
      "std        3.381309\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       42.786042\n",
      "Name: land_use_medical_percent, dtype: float64\n",
      "2025-04-23 11:51:23,365 - INFO - land_use_commercial_percent stats:\n",
      "count    456.000000\n",
      "mean      14.431420\n",
      "std       20.375157\n",
      "min        0.000000\n",
      "25%        0.067784\n",
      "50%        6.387013\n",
      "75%       19.681052\n",
      "max      100.000000\n",
      "Name: land_use_commercial_percent, dtype: float64\n",
      "2025-04-23 11:51:23,367 - INFO - land_use_residential_percent stats:\n",
      "count    456.000000\n",
      "mean      39.790192\n",
      "std       28.179468\n",
      "min        0.000000\n",
      "25%       14.049930\n",
      "50%       39.880672\n",
      "75%       61.167476\n",
      "max      100.000000\n",
      "Name: land_use_residential_percent, dtype: float64\n",
      "2025-04-23 11:51:23,369 - INFO - land_use_natural_percent stats:\n",
      "count    456.000000\n",
      "mean      10.192588\n",
      "std       23.965131\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        2.911863\n",
      "max      100.000000\n",
      "Name: land_use_natural_percent, dtype: float64\n",
      "2025-04-23 11:51:23,370 - INFO - land_use_road_percent stats:\n",
      "count    456.000000\n",
      "mean       1.760988\n",
      "std        4.221853\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.329538\n",
      "max       35.154250\n",
      "Name: land_use_road_percent, dtype: float64\n",
      "2025-04-23 11:51:23,372 - INFO - land_use_river_percent stats:\n",
      "count    456.000000\n",
      "mean       7.632397\n",
      "std       17.040975\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.846661\n",
      "max       89.203679\n",
      "Name: land_use_river_percent, dtype: float64\n",
      "2025-04-23 11:51:23,374 - INFO - land_use_infrastructure_percent stats:\n",
      "count    456.000000\n",
      "mean       0.998987\n",
      "std        3.712642\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.365617\n",
      "max       36.080906\n",
      "Name: land_use_infrastructure_percent, dtype: float64\n",
      "2025-04-23 11:51:23,375 - INFO - land_use_government_percent stats:\n",
      "count    456.000000\n",
      "mean       2.085308\n",
      "std        6.998479\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.024700\n",
      "max       82.267893\n",
      "Name: land_use_government_percent, dtype: float64\n",
      "2025-04-23 11:51:23,376 - INFO - land_use_special_zone_percent stats:\n",
      "count    456.000000\n",
      "mean       3.641446\n",
      "std       10.187207\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.999629\n",
      "max       86.916182\n",
      "Name: land_use_special_zone_percent, dtype: float64\n",
      "2025-04-23 11:51:23,378 - INFO - land_use_military_percent stats:\n",
      "count    456.000000\n",
      "mean       0.110635\n",
      "std        1.998646\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       42.194641\n",
      "Name: land_use_military_percent, dtype: float64\n",
      "2025-04-23 11:51:23,381 - INFO - land_use_industrial_percent stats:\n",
      "count    456.000000\n",
      "mean       1.588055\n",
      "std        7.077495\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       57.012809\n",
      "Name: land_use_industrial_percent, dtype: float64\n",
      "2025-04-23 11:51:23,383 - INFO - land_use_agriculture_percent stats:\n",
      "count    456.000000\n",
      "mean       1.109430\n",
      "std        7.227734\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       75.756599\n",
      "Name: land_use_agriculture_percent, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compute_walkability_scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:51:24,643 - INFO - Filtered 20977 roads of types ['footway', 'pedestrian', 'cycleway'] out of 81444 total roads.\n",
      "2025-04-23 11:51:24,644 - INFO - Checking spatial overlap between neighborhoods and pedestrian_roads...\n",
      "2025-04-23 11:51:24,964 - INFO - neighborhoods bounds: [ 296266.05303084 2761514.89561711  317197.26073793 2789176.16901603]\n",
      "2025-04-23 11:51:24,965 - INFO - pedestrian_roads bounds: [ 295216.88848867 2758756.21684514  314125.37860428 2787925.43931427]\n",
      "2025-04-23 11:51:24,965 - INFO - Bounding boxes overlap: True\n",
      "2025-04-23 11:51:24,974 - INFO - Sample intersection check: 337 intersections found out of 10 samples.\n",
      "2025-04-23 11:51:25,026 - INFO - Pedestrian roads join resulted in 20772 matches.\n",
      "2025-04-23 11:51:25,032 - INFO - Pedestrian road density stats:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: pedestrian_road_density, dtype: float64\n",
      "Computing walkability scores:   0%|          | 0/456 [00:00<?, ?it/s]2025-04-23 11:51:25,036 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,037 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,037 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,038 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,039 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,040 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,041 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,042 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,043 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,043 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,044 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,045 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,046 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,046 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,047 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,048 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,049 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,050 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,051 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,052 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,053 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,054 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,055 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,056 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,057 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,057 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,059 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,060 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,060 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,061 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,062 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,063 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,064 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,067 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,068 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,069 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,070 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,071 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,072 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,073 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,073 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,074 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,075 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,076 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,076 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,077 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,078 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,079 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,079 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,080 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,081 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,083 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,084 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,086 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,087 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,088 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,089 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,090 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,090 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,091 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,091 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,092 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,093 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,094 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,095 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,095 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,096 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,097 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,098 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,099 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,100 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,100 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,101 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,102 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,103 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,103 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,106 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,108 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,109 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,110 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,111 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,112 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,112 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,113 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,114 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,115 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,116 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,117 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,118 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,118 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,119 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,120 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,121 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,121 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,122 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,123 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,124 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,126 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,126 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,127 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,128 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,129 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,130 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,131 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,131 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,132 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,134 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,135 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "Computing walkability scores:  24%|       | 108/456 [00:00<00:00, 1071.98it/s]2025-04-23 11:51:25,136 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,137 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,138 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,139 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,140 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,140 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,141 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,142 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,143 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,144 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,145 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,145 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,146 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,147 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,149 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,150 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,151 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,152 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,152 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,153 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,154 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,155 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,156 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,157 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,158 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,159 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,160 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,161 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,162 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,163 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,164 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,165 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,166 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,167 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,168 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,169 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,170 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,171 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,172 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,173 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,174 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,175 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,175 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,176 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,177 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,178 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,179 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,180 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,181 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,182 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,182 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,183 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,184 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,185 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,186 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,187 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,188 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,189 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,190 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,192 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,193 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,194 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,195 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,195 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,196 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,197 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,199 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,200 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,200 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,201 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,202 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,203 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,204 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,205 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,205 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,207 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,207 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,208 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,209 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,210 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,211 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,212 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,213 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,214 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,214 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,215 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,216 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,217 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,218 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,218 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,219 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,221 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,221 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,222 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,223 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,224 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,225 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,227 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,228 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,230 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,232 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,233 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,234 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,236 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,237 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,238 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,240 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,241 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "Computing walkability scores:  47%|     | 216/456 [00:00<00:00, 1035.69it/s]2025-04-23 11:51:25,243 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,244 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,244 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,246 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,247 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,248 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,249 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,250 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,251 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,251 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,253 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,254 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,254 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,259 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,260 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,262 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,263 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,265 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,266 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,267 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,268 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,269 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,271 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,272 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,274 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,276 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,278 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,279 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,280 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,283 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,284 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,285 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,287 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,288 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,291 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,293 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,294 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,295 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,296 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,297 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,298 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,299 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,300 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,301 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,302 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,303 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,308 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,310 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,312 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,313 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,313 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,314 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,315 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,316 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,317 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,318 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,319 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,320 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,321 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,321 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,322 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,323 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,323 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,325 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,326 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,326 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,328 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,328 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,329 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,330 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,331 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,332 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,333 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,334 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,335 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,336 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,337 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,338 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,338 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,339 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,340 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,342 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,343 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,344 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,345 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,347 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,348 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,350 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,350 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,351 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,352 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,353 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,354 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,354 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,355 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,356 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,357 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,357 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,358 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,360 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,360 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,361 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,362 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,364 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "Computing walkability scores:  70%|   | 320/456 [00:00<00:00, 939.98it/s] 2025-04-23 11:51:25,366 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,367 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,368 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,369 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,370 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,370 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,371 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,372 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,373 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,374 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,375 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,375 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,376 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,377 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,378 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,379 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,380 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,382 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,383 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,384 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,385 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,386 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,386 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,387 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,388 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,389 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,389 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,390 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,391 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,392 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,393 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,393 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,394 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,395 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,396 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,397 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,398 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,398 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,399 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,402 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,404 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,404 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,405 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,406 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,407 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,407 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,408 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,409 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,411 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,412 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,413 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,414 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,415 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,415 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,416 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,417 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,418 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,420 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,421 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,421 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,422 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,423 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,424 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,424 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,425 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,427 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,428 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,428 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,429 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,430 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,430 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,431 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,432 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,433 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,433 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,434 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,435 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,436 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,437 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,438 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,441 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,442 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,442 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,443 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,444 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,445 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,446 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,447 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,447 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,448 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,449 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,450 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,450 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,451 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,452 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,453 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,454 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,455 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,456 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,456 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,457 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,458 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,459 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,459 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,460 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,461 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,462 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,463 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,464 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,465 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "Computing walkability scores:  94%|| 430/456 [00:00<00:00, 997.95it/s]2025-04-23 11:51:25,466 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,467 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,467 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,468 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,469 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,470 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,471 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,472 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,473 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,474 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,476 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,477 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,478 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,479 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,479 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,480 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,481 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,482 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,484 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,485 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,486 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,486 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,487 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,488 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,489 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "2025-04-23 11:51:25,490 - WARNING - Walkability score is NaN for . Setting to 0.\n",
      "Computing walkability scores: 100%|| 456/456 [00:00<00:00, 1000.68it/s]\n",
      "2025-04-23 11:51:25,495 - INFO - Land use diversity distribution:\n",
      "count    456.000000\n",
      "mean       0.590197\n",
      "std        0.193468\n",
      "min        0.011974\n",
      "25%        0.503645\n",
      "50%        0.620689\n",
      "75%        0.716859\n",
      "max        0.999975\n",
      "Name: land_use_diversity, dtype: float64\n",
      "2025-04-23 11:51:25,499 - INFO - Green space score distribution:\n",
      "count    456.000000\n",
      "mean       0.192503\n",
      "std        0.100547\n",
      "min        0.008715\n",
      "25%        0.121016\n",
      "50%        0.156520\n",
      "75%        0.242437\n",
      "max        0.542784\n",
      "Name: green_space_score, dtype: float64\n",
      "2025-04-23 11:51:25,501 - INFO - Transit score distribution:\n",
      "count    456.000000\n",
      "mean       0.095848\n",
      "std        0.121321\n",
      "min        0.000000\n",
      "25%        0.028958\n",
      "50%        0.054054\n",
      "75%        0.110039\n",
      "max        1.000000\n",
      "Name: transit_score, dtype: float64\n",
      "2025-04-23 11:51:25,502 - INFO - Road connectivity distribution:\n",
      "count    456.000000\n",
      "mean       0.252775\n",
      "std        0.170559\n",
      "min        0.000000\n",
      "25%        0.131103\n",
      "50%        0.222216\n",
      "75%        0.332544\n",
      "max        1.000000\n",
      "Name: road_connectivity, dtype: float64\n",
      "2025-04-23 11:51:25,504 - INFO - Safety score distribution:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: safety_score, dtype: float64\n",
      "2025-04-23 11:51:25,505 - INFO - Elderly accessibility distribution:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: elderly_accessibility, dtype: float64\n",
      "2025-04-23 11:51:25,507 - INFO - Pedestrian infrastructure score distribution:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: pedestrian_infrastructure_score, dtype: float64\n",
      "2025-04-23 11:51:25,510 - INFO - Walkability score distribution:\n",
      "count    456.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: walkability_score, dtype: float64\n",
      "2025-04-23 11:51:25,543 - INFO - Number of neighborhood nodes in nodes_df: 456\n",
      "2025-04-23 11:51:25,544 - INFO - Number of entries in walkability_components: 456\n",
      "2025-04-23 11:51:25,550 - INFO - Sample LIE_NAME in nodes_df: ['', '', '', '', '']\n",
      "2025-04-23 11:51:25,551 - INFO - Sample LIE_NAME in walkability_components: ['', '', '', '', '']\n",
      "2025-04-23 11:51:25,960 - INFO - Finished computing walkability scores.\n",
      "2025-04-23 11:51:25,962 - INFO - Preparing data for GNN training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prepare_gnn_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing features by node type:   0%|          | 0/3 [00:00<?, ?it/s]2025-04-23 11:51:26,146 - WARNING - Column avg_road_accident_density missing in neighborhood nodes. Setting to 0.\n",
      "2025-04-23 11:51:26,146 - WARNING - Column pedestrian_road_density missing in neighborhood nodes. Setting to 0.\n",
      "2025-04-23 11:51:26,157 - INFO - Node type neighborhood: 456 nodes, feature shape: (456, 127)\n",
      "2025-04-23 11:51:26,499 - INFO - Node type building: 74306 nodes, feature shape: (74306, 127)\n",
      "Normalizing features by node type:  67%|   | 2/3 [00:00<00:00,  4.39it/s]2025-04-23 11:51:26,769 - INFO - Node type road: 81444 nodes, feature shape: (81444, 127)\n",
      "Normalizing features by node type: 100%|| 3/3 [00:00<00:00,  4.09it/s]\n",
      "2025-04-23 11:51:26,872 - INFO - Edge index created with 270909 edges\n",
      "2025-04-23 11:51:26,881 - INFO - Prepared GNN data: 156206 nodes, 270909 edges\n",
      "2025-04-23 11:51:26,882 - INFO - Feature matrix shape: torch.Size([156206, 127])\n",
      "2025-04-23 11:51:26,883 - INFO - Label tensor shape: torch.Size([156206, 1])\n",
      "2025-04-23 11:51:26,887 - INFO - Stage 4: Training GNN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train_gnn_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:51:27,098 - INFO - Target (walkability_score) distribution for neighborhood nodes:\n",
      "count    456.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "dtype: float64\n",
      "Training epochs:   0%|          | 0/300 [00:00<?, ?it/s]2025-04-23 11:51:27,445 - INFO - Epoch 0, Train Loss: 0.3208, Val Loss: 0.2735\n",
      "Training epochs:   3%|         | 10/300 [00:01<00:29,  9.68it/s]2025-04-23 11:51:28,460 - INFO - Epoch 10, Train Loss: 0.0084, Val Loss: 0.0028\n",
      "Training epochs:   7%|         | 20/300 [00:02<00:25, 10.80it/s]2025-04-23 11:51:29,367 - INFO - Epoch 20, Train Loss: 0.0003, Val Loss: 0.0000\n",
      "Training epochs:  10%|         | 30/300 [00:03<00:24, 11.12it/s]2025-04-23 11:51:30,265 - INFO - Epoch 30, Train Loss: 0.0004, Val Loss: 0.0000\n",
      "Training epochs:  13%|        | 40/300 [00:03<00:23, 11.27it/s]2025-04-23 11:51:31,151 - INFO - Epoch 40, Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Training epochs:  17%|        | 50/300 [00:04<00:20, 11.91it/s]2025-04-23 11:51:32,003 - INFO - Epoch 50, Train Loss: 0.0000, Val Loss: 0.0000\n",
      "2025-04-23 11:51:32,005 - INFO - Early stopping at epoch 50\n",
      "Training epochs:  17%|        | 50/300 [00:04<00:24, 10.23it/s]\n",
      "2025-04-23 11:51:32,011 - INFO - Finished training GNN model.\n",
      "2025-04-23 11:51:32,012 - INFO - Predicting walkability with GNN...\n",
      "2025-04-23 11:51:32,082 - INFO - Preparing data for GNN training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predict_walkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing features by node type:   0%|          | 0/3 [00:00<?, ?it/s]2025-04-23 11:51:32,118 - WARNING - Column avg_road_accident_density missing in neighborhood nodes. Setting to 0.\n",
      "2025-04-23 11:51:32,118 - WARNING - Column pedestrian_road_density missing in neighborhood nodes. Setting to 0.\n",
      "2025-04-23 11:51:32,125 - INFO - Node type neighborhood: 456 nodes, feature shape: (456, 127)\n",
      "2025-04-23 11:51:32,415 - INFO - Node type building: 74306 nodes, feature shape: (74306, 127)\n",
      "Normalizing features by node type:  67%|   | 2/3 [00:00<00:00,  5.88it/s]2025-04-23 11:51:32,605 - INFO - Node type road: 81444 nodes, feature shape: (81444, 127)\n",
      "Normalizing features by node type: 100%|| 3/3 [00:00<00:00,  5.65it/s]\n",
      "2025-04-23 11:51:32,685 - INFO - Edge index created with 270909 edges\n",
      "2025-04-23 11:51:32,688 - INFO - Prepared GNN data: 156206 nodes, 270909 edges\n",
      "2025-04-23 11:51:32,688 - INFO - Feature matrix shape: torch.Size([156206, 127])\n",
      "2025-04-23 11:51:32,689 - INFO - Label tensor shape: torch.Size([156206, 1])\n",
      "2025-04-23 11:51:32,982 - INFO - Walkability GNN stats after prediction:\n",
      "count    4.560000e+02\n",
      "mean     4.135814e-04\n",
      "std      1.464419e-03\n",
      "min      1.241403e-07\n",
      "25%      1.656487e-05\n",
      "50%      7.764637e-05\n",
      "75%      2.750272e-04\n",
      "max      1.713020e-02\n",
      "Name: walkability_gnn, dtype: float64\n",
      "2025-04-23 11:51:32,984 - INFO - Generating interactive Kepler.gl map...\n",
      "2025-04-23 11:51:33,086 - INFO - Neighborhood nodes count: 456\n",
      "2025-04-23 11:51:33,086 - INFO - Neighborhoods_gdf count: 456\n",
      "2025-04-23 11:51:33,087 - INFO - Sample LIE_NAME in nodes_df: ['', '', '', '', '']\n",
      "2025-04-23 11:51:33,087 - INFO - Sample LIE_NAME in neighborhoods_gdf: ['', '', '', '', '']\n",
      "2025-04-23 11:51:33,088 - INFO - Common LIE_NAMEs: 456\n",
      "2025-04-23 11:51:33,088 - INFO - Nodes LIE_NAMEs not in GDF: []\n",
      "2025-04-23 11:51:33,089 - INFO - GDF LIE_NAMEs not in nodes: []\n",
      "2025-04-23 11:51:33,090 - INFO - Nodes nulls: {'LIE_NAME': 0, 'walkability_score': 0, 'walkability_gnn': 0, 'walkability_category': 0}\n",
      "2025-04-23 11:51:33,090 - INFO - GDF geometry nulls: 0\n",
      "2025-04-23 11:51:33,093 - INFO - Merged map_data rows: 456\n",
      "2025-04-23 11:51:33,094 - INFO - Walkability score nulls: 0\n",
      "2025-04-23 11:51:33,094 - INFO - Walkability GNN nulls: 0\n",
      "2025-04-23 11:51:33,096 - INFO - Walkability score distribution in map_data:\n",
      "count    456.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: walkability_score, dtype: float64\n",
      "2025-04-23 11:51:33,098 - INFO - Walkability GNN distribution in map_data:\n",
      "count    4.560000e+02\n",
      "mean     4.135814e-04\n",
      "std      1.464419e-03\n",
      "min      1.241403e-07\n",
      "25%      1.656487e-05\n",
      "50%      7.764637e-05\n",
      "75%      2.750272e-04\n",
      "max      1.713020e-02\n",
      "Name: walkability_gnn, dtype: float64\n",
      "2025-04-23 11:51:33,099 - INFO - Walkability category distribution in map_data:\n",
      "walkability_category\n",
      "low    456\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting create_interactive_map...\n",
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:51:33,187 - INFO - Interactive map generated and saved as /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_walkability_map.html\n",
      "2025-04-23 11:51:33,287 - INFO - Final validation - Walkability scores in neighborhood nodes:\n",
      "2025-04-23 11:51:33,290 - INFO - Walkability score distribution:\n",
      "count    456.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: walkability_score, dtype: float64\n",
      "2025-04-23 11:51:33,291 - INFO - Walkability GNN distribution:\n",
      "count    4.560000e+02\n",
      "mean     4.135814e-04\n",
      "std      1.464419e-03\n",
      "min      1.241403e-07\n",
      "25%      1.656487e-05\n",
      "50%      7.764637e-05\n",
      "75%      2.750272e-04\n",
      "max      1.713020e-02\n",
      "Name: walkability_gnn, dtype: float64\n",
      "2025-04-23 11:51:33,292 - INFO - Walkability category distribution:\n",
      "walkability_category\n",
      "low    456\n",
      "Name: count, dtype: int64\n",
      "2025-04-23 11:51:33,293 - INFO - Number of neighborhood nodes with non-zero walkability_score: 0/456\n",
      "2025-04-23 11:51:33,294 - INFO - Number of neighborhood nodes with non-zero walkability_gnn: 456/456\n",
      "2025-04-23 11:51:33,295 - WARNING - Walkability scores have low variation (std < 0.05). Components may need adjustment.\n",
      "2025-04-23 11:51:33,296 - WARNING - GNN predictions have low variation (std < 0.05). Check edge creation and model training.\n",
      "/tmp/ipykernel_1289463/1629835473.py:90: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = pearsonr(neighborhood_nodes['walkability_score'], neighborhood_nodes['walkability_gnn'])\n",
      "2025-04-23 11:51:33,298 - INFO - Correlation between walkability_score and walkability_gnn: nan (p-value: nan)\n",
      "2025-04-23 11:51:33,299 - INFO - Processing complete. Timing summary:\n",
      "2025-04-23 11:51:33,299 - INFO - load_and_prepare_data: 33.77 seconds\n",
      "2025-04-23 11:51:33,299 - INFO - compute_road_type_accident_correlation: 6.88 seconds\n",
      "2025-04-23 11:51:33,300 - INFO - build_graph: 112.07 seconds\n",
      "2025-04-23 11:51:33,300 - INFO - compute_walkability_scores: 2.69 seconds\n",
      "2025-04-23 11:51:33,301 - INFO - prepare_gnn_data: 0.92 seconds\n",
      "2025-04-23 11:51:33,301 - INFO - train_gnn_model: 5.13 seconds\n",
      "2025-04-23 11:51:33,302 - INFO - predict_walkability: 0.97 seconds\n",
      "2025-04-23 11:51:33,302 - INFO - create_interactive_map: 0.21 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_walkability_map.html!\n",
      "Map saved to /home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data/taipei_walkability_map.html!\n",
      "Pipeline completed successfully.\n",
      "   src  dst\n",
      "0    0    1\n",
      "1    0    2\n",
      "2    0    3\n",
      "3    0    4\n",
      "4    0    5\n"
     ]
    }
   ],
   "source": [
    "def main(force_recompute_graph=False):\n",
    "    \"\"\"Main execution pipeline for the analysis.\"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "    logging.info(f\"Ensured subgraph directory exists: {SUBGRAPH_DIR}\")\n",
    "\n",
    "    # Track timing for each step\n",
    "    timings = {}\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load and prepare data\n",
    "        start_time = time.time()\n",
    "        print(\"Starting load_and_prepare_data...\")\n",
    "        data = load_and_prepare_data()\n",
    "        timings['load_and_prepare_data'] = time.time() - start_time\n",
    "\n",
    "        # Step 2: Compute road type accident correlation\n",
    "        start_time = time.time()\n",
    "        print(\"Starting compute_road_type_accident_correlation...\")\n",
    "        road_accident_summary = compute_road_type_accident_correlation(\n",
    "            data['roads'], data['neighborhoods'], data['accidents']\n",
    "        )\n",
    "        timings['compute_road_type_accident_correlation'] = time.time() - start_time\n",
    "\n",
    "        # Step 3: Build graph\n",
    "        start_time = time.time()\n",
    "        print(\"Starting build_graph...\")\n",
    "        G = build_graph(data, force_recompute=force_recompute_graph)\n",
    "        timings['build_graph'] = time.time() - start_time\n",
    "\n",
    "        # Validate edge counts\n",
    "        edge_count = G.edgelist.edgelist_df.shape[0] if G.edgelist else 0\n",
    "        logging.info(f\"Graph edge count: {edge_count}\")\n",
    "        if edge_count == 0:\n",
    "            logging.warning(\"Graph has no edges. GNN will not utilize graph structure.\")\n",
    "\n",
    "        # Step 4: Compute walkability scores\n",
    "        start_time = time.time()\n",
    "        print(\"Starting compute_walkability_scores...\")\n",
    "        G = compute_walkability_scores(G, data)\n",
    "        timings['compute_walkability_scores'] = time.time() - start_time\n",
    "\n",
    "        # Step 5: Prepare GNN data\n",
    "        start_time = time.time()\n",
    "        print(\"Starting prepare_gnn_data...\")\n",
    "        data_gnn = prepare_gnn_data(G)\n",
    "        timings['prepare_gnn_data'] = time.time() - start_time\n",
    "\n",
    "        # Step 6: Train GNN model\n",
    "        start_time = time.time()\n",
    "        print(\"Starting train_gnn_model...\")\n",
    "        model = train_gnn_model(data_gnn)\n",
    "        timings['train_gnn_model'] = time.time() - start_time\n",
    "\n",
    "        # Step 7: Predict walkability\n",
    "        start_time = time.time()\n",
    "        print(\"Starting predict_walkability...\")\n",
    "        G = predict_walkability(G, model)\n",
    "        timings['predict_walkability'] = time.time() - start_time\n",
    "\n",
    "        # Step 8: Create interactive map\n",
    "        start_time = time.time()\n",
    "        print(\"Starting create_interactive_map...\")\n",
    "        create_interactive_map(G, data)\n",
    "        timings['create_interactive_map'] = time.time() - start_time\n",
    "\n",
    "        # Final validation: Check walkability scores\n",
    "        nodes_df = G._nodes.to_pandas()\n",
    "        neighborhood_nodes = nodes_df[nodes_df['type'] == 'neighborhood']\n",
    "        walkability_score_stats = neighborhood_nodes['walkability_score'].describe()\n",
    "        walkability_gnn_stats = neighborhood_nodes['walkability_gnn'].describe()\n",
    "        walkability_category_dist = neighborhood_nodes['walkability_category'].value_counts()\n",
    "        non_zero_walkability = (neighborhood_nodes['walkability_score'] > 0).sum()\n",
    "        non_zero_walkability_gnn = (neighborhood_nodes['walkability_gnn'] > 0).sum()\n",
    "        \n",
    "        logging.info(\"Final validation - Walkability scores in neighborhood nodes:\")\n",
    "        logging.info(f\"Walkability score distribution:\\n{walkability_score_stats}\")\n",
    "        logging.info(f\"Walkability GNN distribution:\\n{walkability_gnn_stats}\")\n",
    "        logging.info(f\"Walkability category distribution:\\n{walkability_category_dist}\")\n",
    "        logging.info(f\"Number of neighborhood nodes with non-zero walkability_score: {non_zero_walkability}/{len(neighborhood_nodes)}\")\n",
    "        logging.info(f\"Number of neighborhood nodes with non-zero walkability_gnn: {non_zero_walkability_gnn}/{len(neighborhood_nodes)}\")\n",
    "\n",
    "        # Check for low variation in walkability scores\n",
    "        if walkability_score_stats['std'] < 0.05:\n",
    "            logging.warning(\"Walkability scores have low variation (std < 0.05). Components may need adjustment.\")\n",
    "        if walkability_gnn_stats['std'] < 0.05:\n",
    "            logging.warning(\"GNN predictions have low variation (std < 0.05). Check edge creation and model training.\")\n",
    "\n",
    "        # Compute correlation between walkability_score and walkability_gnn\n",
    "        corr, p_value = pearsonr(neighborhood_nodes['walkability_score'], neighborhood_nodes['walkability_gnn'])\n",
    "        logging.info(f\"Correlation between walkability_score and walkability_gnn: {corr:.2f} (p-value: {p_value:.2f})\")\n",
    "        if corr < 0.5:\n",
    "            logging.warning(\"Low correlation between walkability_score and walkability_gnn. GNN predictions may not align well with rule-based scores.\")\n",
    "\n",
    "        # Log timing summary\n",
    "        logging.info(\"Processing complete. Timing summary:\")\n",
    "        for step, duration in timings.items():\n",
    "            logging.info(f\"{step}: {duration:.2f} seconds\")\n",
    "        \n",
    "        print(\"Pipeline completed successfully.\")\n",
    "        print(G.edgelist.edgelist_df.to_pandas().head())\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Pipeline failed with error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(force_recompute_graph=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
