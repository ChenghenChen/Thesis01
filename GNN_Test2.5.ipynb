{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you provide solution, you should write the full sections of code, not vague instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:59:54,541 - INFO - Ensured subgraph directory exists: subgraphs\n",
      "2025-04-09 16:59:54,542 - INFO - Stage 1: Loading and preparing data...\n",
      "Loading files:  25%|██▌       | 2/8 [00:01<00:03,  1.60it/s]2025-04-09 16:59:56,609 - INFO - Found 604 roads with missing 'class' values.\n",
      "Loading files: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Plan Categories: ['City_Open_Area', 'Commercial', 'Infrastructure', 'Government', 'Public_Transportation', 'Education', 'Medical', 'Amenity', 'Road', 'Pedestrian', 'Natural', 'Special_Zone', 'River', 'Military', 'Residential', 'Industrial', 'Agriculture']\n",
      "Road Types Categories: [None, 'service', 'track', 'path', 'steps', 'footway', 'residential', 'unclassified', 'secondary', 'tertiary', 'pedestrian', 'living_street', 'primary', 'unknown', 'cycleway', 'motorway', 'trunk', 'bridleway']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:59:58,471 - INFO - Unique categories in urban_masterplan_gdf: ['City_Open_Area' 'Commercial' 'Infrastructure' 'Government'\n",
      " 'Public_Transportation' 'Education' 'Medical' 'Amenity' 'Road'\n",
      " 'Pedestrian' 'Natural' 'Special_Zone' 'River' 'Military' 'Residential'\n",
      " 'Industrial' 'Agriculture']\n",
      "2025-04-09 16:59:58,482 - WARNING - No neighborhoods with zero cityopenarea_count. Check data or computation.\n",
      "2025-04-09 16:59:58,489 - WARNING - No neighborhoods with zero education_count. Check data or computation.\n",
      "2025-04-09 16:59:58,506 - WARNING - No neighborhoods with zero commercial_count. Check data or computation.\n",
      "2025-04-09 16:59:58,555 - INFO - Stage 2: Building graph network...\n",
      "2025-04-09 16:59:58,563 - INFO - Computing accident counts per road...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Structure Overview ---\n",
      "\n",
      "Dataset: neighborhoods\n",
      "Shape: (460, 16)\n",
      "Columns: ['LIE_NAME', 'land_use_commercial_percent', 'land_use_education_percent', 'land_use_residential_percent', 'ndvi_mean', 'geometry', 'total_population', 'elderly_percentage', 'tree_count', 'transit_count', 'accident_count', 'road_length', 'road_density', 'cityopenarea_count', 'education_count', 'commercial_count']\n",
      "Data types:\n",
      "LIE_NAME                          object\n",
      "land_use_commercial_percent      float64\n",
      "land_use_education_percent       float64\n",
      "land_use_residential_percent     float64\n",
      "ndvi_mean                        float64\n",
      "geometry                        geometry\n",
      "total_population                   int64\n",
      "elderly_percentage               float64\n",
      "tree_count                         int64\n",
      "transit_count                      int64\n",
      "accident_count                     int64\n",
      "road_length                      float64\n",
      "road_density                     float64\n",
      "cityopenarea_count                 int64\n",
      "education_count                    int64\n",
      "commercial_count                   int64\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "LIE_NAME                        0\n",
      "land_use_commercial_percent     0\n",
      "land_use_education_percent      0\n",
      "land_use_residential_percent    0\n",
      "ndvi_mean                       0\n",
      "geometry                        0\n",
      "total_population                0\n",
      "elderly_percentage              0\n",
      "tree_count                      0\n",
      "transit_count                   0\n",
      "accident_count                  0\n",
      "road_length                     0\n",
      "road_density                    0\n",
      "cityopenarea_count              0\n",
      "education_count                 0\n",
      "commercial_count                0\n",
      "dtype: int64\n",
      "Summary statistics:\n",
      "       land_use_commercial_percent  land_use_education_percent  \\\n",
      "count                   460.000000                  460.000000   \n",
      "mean                     16.470225                    8.827350   \n",
      "std                      21.541364                   13.535784   \n",
      "min                       0.000000                    0.000000   \n",
      "25%                       0.000000                    0.000000   \n",
      "50%                       8.677236                    0.000000   \n",
      "75%                      22.403101                   14.939929   \n",
      "max                     100.000000                   87.040424   \n",
      "\n",
      "       land_use_residential_percent   ndvi_mean  total_population  \\\n",
      "count                    460.000000  460.000000        460.000000   \n",
      "mean                      51.317706    0.289186       5465.030435   \n",
      "std                       29.359755    0.193803       1975.502593   \n",
      "min                        0.000000   -0.077327        836.000000   \n",
      "25%                       31.019892    0.154659       4173.250000   \n",
      "50%                       54.106301    0.224252       5275.000000   \n",
      "75%                       73.625096    0.365020       6700.750000   \n",
      "max                      100.000000    0.818806      12021.000000   \n",
      "\n",
      "       elderly_percentage  tree_count  transit_count  accident_count  \\\n",
      "count          460.000000  460.000000     460.000000      460.000000   \n",
      "mean            23.302543    7.071739       9.491304      122.817391   \n",
      "std              3.442976   23.498233       9.514004       99.811158   \n",
      "min             13.470000    1.000000       1.000000        1.000000   \n",
      "25%             21.075000    1.000000       4.000000       56.000000   \n",
      "50%             23.350000    1.000000       7.000000       98.500000   \n",
      "75%             25.495000    4.000000      11.000000      157.250000   \n",
      "max             33.630000  211.000000      81.000000      806.000000   \n",
      "\n",
      "         road_length  road_density  cityopenarea_count  education_count  \\\n",
      "count     460.000000    460.000000          460.000000       460.000000   \n",
      "mean    40267.541137      0.158190            2.067391         1.371739   \n",
      "std     35764.862303      0.171275            2.025389         1.227350   \n",
      "min      1527.010658      0.007561            1.000000         1.000000   \n",
      "25%     15352.002537      0.055500            1.000000         1.000000   \n",
      "50%     29982.715544      0.097732            1.000000         1.000000   \n",
      "75%     51252.338138      0.215288            2.000000         1.000000   \n",
      "max    276437.620457      1.657325           18.000000        19.000000   \n",
      "\n",
      "       commercial_count  \n",
      "count        460.000000  \n",
      "mean           6.808696  \n",
      "std            7.931236  \n",
      "min            1.000000  \n",
      "25%            1.000000  \n",
      "50%            4.000000  \n",
      "75%            9.250000  \n",
      "max           49.000000  \n",
      "Sample data (first row):\n",
      "  LIE_NAME  land_use_commercial_percent  land_use_education_percent  \\\n",
      "0      湖田里                          0.0                         0.0   \n",
      "\n",
      "   land_use_residential_percent  ndvi_mean  \\\n",
      "0                           0.0    0.78596   \n",
      "\n",
      "                                            geometry  total_population  \\\n",
      "0  POLYGON ((302666.543 2785226.842, 302675.82 27...               857   \n",
      "\n",
      "   elderly_percentage  tree_count  transit_count  accident_count  \\\n",
      "0               28.24           9             47              70   \n",
      "\n",
      "     road_length  road_density  cityopenarea_count  education_count  \\\n",
      "0  123431.879262      0.007561                   1                1   \n",
      "\n",
      "   commercial_count  \n",
      "0                 1  \n",
      "\n",
      "Dataset: buildings\n",
      "Shape: (74306, 3)\n",
      "Columns: ['building', 'geometry', 'area_m2']\n",
      "Data types:\n",
      "building      object\n",
      "geometry    geometry\n",
      "area_m2      float64\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "building    31\n",
      "geometry     0\n",
      "area_m2      0\n",
      "dtype: int64\n",
      "Summary statistics:\n",
      "            area_m2\n",
      "count  74306.000000\n",
      "mean     326.713464\n",
      "std      783.686503\n",
      "min        0.603543\n",
      "25%       97.315016\n",
      "50%      182.929099\n",
      "75%      304.603966\n",
      "max    62939.914744\n",
      "Sample data (first row):\n",
      "    building                                           geometry      area_m2\n",
      "0  dormitory  POLYGON ((304401.483 2780904.12, 304430.995 27...  2069.043777\n",
      "\n",
      "Dataset: roads\n",
      "Shape: (81444, 3)\n",
      "Columns: ['geometry', 'class', 'length_m']\n",
      "Data types:\n",
      "geometry    geometry\n",
      "class         object\n",
      "length_m     float64\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "geometry      0\n",
      "class       604\n",
      "length_m      0\n",
      "dtype: int64\n",
      "Summary statistics:\n",
      "            length_m\n",
      "count   81444.000000\n",
      "mean      145.622456\n",
      "std      2304.902398\n",
      "min         0.030284\n",
      "25%        28.160770\n",
      "50%        61.698697\n",
      "75%       130.534001\n",
      "max    426414.891763\n",
      "Sample data (first row):\n",
      "                                            geometry class       length_m\n",
      "0  LINESTRING (324778.511 2780945.263, 324826.86 ...  None  426414.891763\n",
      "\n",
      "Dataset: trees\n",
      "Shape: (3399, 3)\n",
      "Columns: ['geometry', 'subtype', 'class']\n",
      "Data types:\n",
      "geometry    geometry\n",
      "subtype       object\n",
      "class         object\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "geometry    0\n",
      "subtype     0\n",
      "class       0\n",
      "dtype: int64\n",
      "Sample data (first row):\n",
      "                         geometry subtype class\n",
      "10  POINT (299214.34 2760358.722)    tree  tree\n",
      "\n",
      "Dataset: transit\n",
      "Shape: (6845, 2)\n",
      "Columns: ['geometry', 'class']\n",
      "Data types:\n",
      "geometry    geometry\n",
      "class         object\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "geometry    0\n",
      "class       0\n",
      "dtype: int64\n",
      "Sample data (first row):\n",
      "                          geometry     class\n",
      "38  POINT (300777.296 2759032.567)  bus_stop\n",
      "\n",
      "Dataset: urban_masterplan\n",
      "Shape: (15521, 2)\n",
      "Columns: ['Category', 'geometry']\n",
      "Data types:\n",
      "Category      object\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "Category    0\n",
      "geometry    0\n",
      "dtype: int64\n",
      "Sample data (first row):\n",
      "         Category                                           geometry\n",
      "0  City_Open_Area  MULTIPOLYGON (((303340.099 2771175.776, 303329...\n",
      "\n",
      "Dataset: accidents\n",
      "Shape: (56133, 1)\n",
      "Columns: ['geometry']\n",
      "Data types:\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "geometry    0\n",
      "dtype: int64\n",
      "Sample data (first row):\n",
      "                        geometry\n",
      "0  POINT (305807.42 2770096.759)\n",
      "\n",
      "Dataset: population\n",
      "Shape: (456, 3)\n",
      "Columns: ['LIE_NAME', 'total_population', 'elderly_percentage']\n",
      "Data types:\n",
      "LIE_NAME               object\n",
      "total_population        int64\n",
      "elderly_percentage    float64\n",
      "dtype: object\n",
      "Missing values per column:\n",
      "LIE_NAME              0\n",
      "total_population      0\n",
      "elderly_percentage    0\n",
      "dtype: int64\n",
      "Summary statistics:\n",
      "       total_population  elderly_percentage\n",
      "count        456.000000          456.000000\n",
      "mean        5471.701754           23.288268\n",
      "std         1972.141786            3.444386\n",
      "min          836.000000           13.470000\n",
      "25%         4175.000000           21.047500\n",
      "50%         5275.000000           23.350000\n",
      "75%         6700.750000           25.495000\n",
      "max        12021.000000           33.630000\n",
      "Sample data (first row):\n",
      "  LIE_NAME  total_population  elderly_percentage\n",
      "0      南福里             12021                16.1\n",
      "--- End of Data Structure Overview ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:59:59,604 - INFO - Loaded existing subgraph for: 湖田里\n",
      "2025-04-09 16:59:59,612 - INFO - Loaded existing subgraph for: 菁山里\n",
      "2025-04-09 16:59:59,614 - INFO - Loaded existing subgraph for: 大屯里\n",
      "2025-04-09 16:59:59,617 - INFO - Loaded existing subgraph for: 平等里\n",
      "2025-04-09 16:59:59,620 - INFO - Loaded existing subgraph for: 泉源里\n",
      "2025-04-09 16:59:59,627 - INFO - Loaded existing subgraph for: 湖山里\n",
      "2025-04-09 16:59:59,629 - INFO - Loaded existing subgraph for: 秀山里\n",
      "2025-04-09 16:59:59,634 - INFO - Loaded existing subgraph for: 陽明里\n",
      "2025-04-09 16:59:59,638 - INFO - Loaded existing subgraph for: 溪山里\n",
      "2025-04-09 16:59:59,641 - INFO - Loaded existing subgraph for: 稻香里\n",
      "2025-04-09 16:59:59,646 - INFO - Loaded existing subgraph for: 開明里\n",
      "2025-04-09 16:59:59,649 - INFO - Loaded existing subgraph for: 中和里\n",
      "2025-04-09 16:59:59,652 - INFO - Loaded existing subgraph for: 中心里\n",
      "2025-04-09 16:59:59,653 - INFO - Loaded existing subgraph for: 桃源里\n",
      "2025-04-09 16:59:59,656 - INFO - Loaded existing subgraph for: 智仁里\n",
      "2025-04-09 16:59:59,659 - INFO - Loaded existing subgraph for: 文化里\n",
      "2025-04-09 16:59:59,662 - INFO - Loaded existing subgraph for: 林泉里\n",
      "2025-04-09 16:59:59,665 - INFO - Loaded existing subgraph for: 永和里\n",
      "2025-04-09 16:59:59,669 - INFO - Loaded existing subgraph for: 天母里\n",
      "2025-04-09 16:59:59,672 - INFO - Loaded existing subgraph for: 公館里\n",
      "2025-04-09 16:59:59,676 - INFO - Loaded existing subgraph for: 一德里\n",
      "2025-04-09 16:59:59,679 - INFO - Loaded existing subgraph for: 中庸里\n",
      "2025-04-09 16:59:59,681 - INFO - Loaded existing subgraph for: 豐年里\n",
      "2025-04-09 16:59:59,682 - INFO - Loaded existing subgraph for: 新安里\n",
      "2025-04-09 16:59:59,684 - INFO - Loaded existing subgraph for: 新安里\n",
      "2025-04-09 16:59:59,686 - INFO - Loaded existing subgraph for: 長安里\n",
      "2025-04-09 16:59:59,689 - INFO - Loaded existing subgraph for: 溫泉里\n",
      "2025-04-09 16:59:59,693 - INFO - Loaded existing subgraph for: 奇岩里\n",
      "2025-04-09 16:59:59,695 - INFO - Loaded existing subgraph for: 大同里\n",
      "2025-04-09 16:59:59,821 - INFO - Loaded existing subgraph for: 東山里\n",
      "2025-04-09 16:59:59,829 - INFO - Loaded existing subgraph for: 中央里\n",
      "2025-04-09 16:59:59,832 - INFO - Loaded existing subgraph for: 中央里\n",
      "2025-04-09 16:59:59,838 - INFO - Loaded existing subgraph for: 清江里\n",
      "2025-04-09 16:59:59,843 - INFO - Loaded existing subgraph for: 永欣里\n",
      "2025-04-09 16:59:59,849 - INFO - Loaded existing subgraph for: 八仙里\n",
      "2025-04-09 16:59:59,853 - INFO - Loaded existing subgraph for: 天和里\n",
      "2025-04-09 16:59:59,857 - INFO - Loaded existing subgraph for: 東華里\n",
      "2025-04-09 16:59:59,860 - INFO - Loaded existing subgraph for: 天山里\n",
      "2025-04-09 16:59:59,862 - INFO - Loaded existing subgraph for: 關渡里\n",
      "2025-04-09 16:59:59,867 - INFO - Loaded existing subgraph for: 天玉里\n",
      "2025-04-09 16:59:59,871 - INFO - Loaded existing subgraph for: 立農里\n",
      "2025-04-09 16:59:59,875 - INFO - Loaded existing subgraph for: 芝山里\n",
      "2025-04-09 16:59:59,878 - INFO - Loaded existing subgraph for: 榮華里\n",
      "2025-04-09 16:59:59,881 - INFO - Loaded existing subgraph for: 永明里\n",
      "2025-04-09 16:59:59,883 - INFO - Loaded existing subgraph for: 振華里\n",
      "2025-04-09 16:59:59,886 - INFO - Loaded existing subgraph for: 吉利里\n",
      "2025-04-09 16:59:59,889 - INFO - Loaded existing subgraph for: 天壽里\n",
      "2025-04-09 16:59:59,890 - INFO - Loaded existing subgraph for: 尊賢里\n",
      "2025-04-09 16:59:59,892 - INFO - Loaded existing subgraph for: 立賢里\n",
      "2025-04-09 16:59:59,896 - INFO - Loaded existing subgraph for: 天福里\n",
      "2025-04-09 16:59:59,903 - INFO - Loaded existing subgraph for: 三玉里\n",
      "2025-04-09 16:59:59,907 - INFO - Loaded existing subgraph for: 天祿里\n",
      "2025-04-09 16:59:59,909 - INFO - Loaded existing subgraph for: 富洲里\n",
      "2025-04-09 16:59:59,912 - INFO - Loaded existing subgraph for: 永福里\n",
      "2025-04-09 16:59:59,915 - INFO - Loaded existing subgraph for: 裕民里\n",
      "2025-04-09 16:59:59,918 - INFO - Loaded existing subgraph for: 福安里\n",
      "2025-04-09 16:59:59,922 - INFO - Loaded existing subgraph for: 碧山里\n",
      "2025-04-09 16:59:59,924 - INFO - Loaded existing subgraph for: 榮光里\n",
      "2025-04-09 17:00:00,040 - INFO - Loaded existing subgraph for: 吉慶里\n",
      "2025-04-09 17:00:00,046 - INFO - Loaded existing subgraph for: 福興里\n",
      "2025-04-09 17:00:00,053 - INFO - Loaded existing subgraph for: 蘭興里\n",
      "2025-04-09 17:00:00,057 - INFO - Loaded existing subgraph for: 洲美里\n",
      "2025-04-09 17:00:00,061 - INFO - Loaded existing subgraph for: 臨溪里\n",
      "2025-04-09 17:00:00,064 - INFO - Loaded existing subgraph for: 翠山里\n",
      "2025-04-09 17:00:00,072 - INFO - Loaded existing subgraph for: 蘭雅里\n",
      "2025-04-09 17:00:00,075 - INFO - Loaded existing subgraph for: 石牌里\n",
      "2025-04-09 17:00:00,079 - INFO - Loaded existing subgraph for: 文林里\n",
      "2025-04-09 17:00:00,084 - INFO - Loaded existing subgraph for: 聖山里\n",
      "2025-04-09 17:00:00,088 - INFO - Loaded existing subgraph for: 建民里\n",
      "2025-04-09 17:00:00,090 - INFO - Loaded existing subgraph for: 內溝里\n",
      "2025-04-09 17:00:00,095 - INFO - Loaded existing subgraph for: 岩山里\n",
      "2025-04-09 17:00:00,098 - INFO - Loaded existing subgraph for: 忠誠里\n",
      "2025-04-09 17:00:00,101 - INFO - Loaded existing subgraph for: 金瑞里\n",
      "2025-04-09 17:00:00,107 - INFO - Loaded existing subgraph for: 德行里\n",
      "2025-04-09 17:00:00,112 - INFO - Loaded existing subgraph for: 名山里\n",
      "2025-04-09 17:00:00,115 - INFO - Loaded existing subgraph for: 大湖里\n",
      "2025-04-09 17:00:00,120 - INFO - Loaded existing subgraph for: 德華里\n",
      "2025-04-09 17:00:00,127 - INFO - Loaded existing subgraph for: 福志里\n",
      "2025-04-09 17:00:00,136 - INFO - Loaded existing subgraph for: 舊佳里\n",
      "2025-04-09 17:00:00,146 - INFO - Loaded existing subgraph for: 福林里\n",
      "2025-04-09 17:00:00,157 - INFO - Loaded existing subgraph for: 福佳里\n",
      "2025-04-09 17:00:00,160 - INFO - Loaded existing subgraph for: 西安里\n",
      "2025-04-09 17:00:00,164 - INFO - Loaded existing subgraph for: 西康里\n",
      "2025-04-09 17:00:00,170 - INFO - Loaded existing subgraph for: 後港里\n",
      "2025-04-09 17:00:00,177 - INFO - Loaded existing subgraph for: 永倫里\n",
      "2025-04-09 17:00:00,184 - INFO - Loaded existing subgraph for: 社園里\n",
      "2025-04-09 17:00:00,190 - INFO - Loaded existing subgraph for: 社子里\n",
      "2025-04-09 17:00:00,286 - INFO - Loaded existing subgraph for: 福德里\n",
      "2025-04-09 17:00:00,290 - INFO - Loaded existing subgraph for: 港華里\n",
      "2025-04-09 17:00:00,294 - INFO - Loaded existing subgraph for: 仁勇里\n",
      "2025-04-09 17:00:00,296 - INFO - Loaded existing subgraph for: 北安里\n",
      "2025-04-09 17:00:00,299 - INFO - Loaded existing subgraph for: 劍潭里\n",
      "2025-04-09 17:00:00,302 - INFO - Loaded existing subgraph for: 大直里\n",
      "2025-04-09 17:00:00,304 - INFO - Loaded existing subgraph for: 安泰里\n",
      "2025-04-09 17:00:00,308 - INFO - Loaded existing subgraph for: 義信里\n",
      "2025-04-09 17:00:00,311 - INFO - Loaded existing subgraph for: 港富里\n",
      "2025-04-09 17:00:00,316 - INFO - Loaded existing subgraph for: 社新里\n",
      "2025-04-09 17:00:00,319 - INFO - Loaded existing subgraph for: 福中里\n",
      "2025-04-09 17:00:00,322 - INFO - Loaded existing subgraph for: 湖濱里\n",
      "2025-04-09 17:00:00,325 - INFO - Loaded existing subgraph for: 葫東里\n",
      "2025-04-09 17:00:00,330 - INFO - Loaded existing subgraph for: 前港里\n",
      "2025-04-09 17:00:00,332 - INFO - Loaded existing subgraph for: 秀湖里\n",
      "2025-04-09 17:00:00,335 - INFO - Loaded existing subgraph for: 金龍里\n",
      "2025-04-09 17:00:00,338 - INFO - Loaded existing subgraph for: 西湖里\n",
      "2025-04-09 17:00:00,340 - INFO - Loaded existing subgraph for: 麗山里\n",
      "2025-04-09 17:00:00,345 - INFO - Loaded existing subgraph for: 葫蘆里\n",
      "2025-04-09 17:00:00,351 - INFO - Loaded existing subgraph for: 成功里\n",
      "2025-04-09 17:00:00,355 - INFO - Loaded existing subgraph for: 內湖里\n",
      "2025-04-09 17:00:00,360 - INFO - Loaded existing subgraph for: 百齡里\n",
      "2025-04-09 17:00:00,364 - INFO - Loaded existing subgraph for: 金泰里\n",
      "2025-04-09 17:00:00,367 - INFO - Loaded existing subgraph for: 清白里\n",
      "2025-04-09 17:00:00,373 - INFO - Loaded existing subgraph for: 承德里\n",
      "2025-04-09 17:00:00,377 - INFO - Loaded existing subgraph for: 福順里\n",
      "2025-04-09 17:00:00,380 - INFO - Loaded existing subgraph for: 港都里\n",
      "2025-04-09 17:00:00,386 - INFO - Loaded existing subgraph for: 福華里\n",
      "2025-04-09 17:00:00,389 - INFO - Loaded existing subgraph for: 富光里\n",
      "2025-04-09 17:00:00,454 - INFO - Loaded existing subgraph for: 紫星里\n",
      "2025-04-09 17:00:00,460 - INFO - Loaded existing subgraph for: 港墘里\n",
      "2025-04-09 17:00:00,464 - INFO - Loaded existing subgraph for: 金湖里\n",
      "2025-04-09 17:00:00,468 - INFO - Loaded existing subgraph for: 明勝里\n",
      "2025-04-09 17:00:00,471 - INFO - Loaded existing subgraph for: 永安里\n",
      "2025-04-09 17:00:00,474 - INFO - Loaded existing subgraph for: 紫陽里\n",
      "2025-04-09 17:00:00,476 - INFO - Loaded existing subgraph for: 重慶里\n",
      "2025-04-09 17:00:00,478 - INFO - Loaded existing subgraph for: 紫雲里\n",
      "2025-04-09 17:00:00,481 - INFO - Loaded existing subgraph for: 老師里\n",
      "2025-04-09 17:00:00,483 - INFO - Loaded existing subgraph for: 瑞陽里\n",
      "2025-04-09 17:00:00,486 - INFO - Loaded existing subgraph for: 康寧里\n",
      "2025-04-09 17:00:00,489 - INFO - Loaded existing subgraph for: 新庄里\n",
      "2025-04-09 17:00:00,493 - INFO - Loaded existing subgraph for: 大佳里\n",
      "2025-04-09 17:00:00,496 - INFO - Loaded existing subgraph for: 寶湖里\n",
      "2025-04-09 17:00:00,499 - INFO - Loaded existing subgraph for: 圓山里\n",
      "2025-04-09 17:00:00,502 - INFO - Loaded existing subgraph for: 瑞光里\n",
      "2025-04-09 17:00:00,505 - INFO - Loaded existing subgraph for: 莊敬里\n",
      "2025-04-09 17:00:00,509 - INFO - Loaded existing subgraph for: 湖興里\n",
      "2025-04-09 17:00:00,512 - INFO - Loaded existing subgraph for: 安湖里\n",
      "2025-04-09 17:00:00,515 - INFO - Loaded existing subgraph for: 東湖里\n",
      "2025-04-09 17:00:00,517 - INFO - Loaded existing subgraph for: 保安里\n",
      "2025-04-09 17:00:00,519 - INFO - Loaded existing subgraph for: 樂康里\n",
      "2025-04-09 17:00:00,523 - INFO - Loaded existing subgraph for: 湖元里\n",
      "2025-04-09 17:00:00,528 - INFO - Loaded existing subgraph for: 葫洲里\n",
      "2025-04-09 17:00:00,532 - INFO - Loaded existing subgraph for: 明湖里\n",
      "2025-04-09 17:00:00,535 - INFO - Loaded existing subgraph for: 鄰江里\n",
      "2025-04-09 17:00:00,538 - INFO - Loaded existing subgraph for: 至聖里\n",
      "2025-04-09 17:00:00,542 - INFO - Loaded existing subgraph for: 精忠里\n",
      "2025-04-09 17:00:00,547 - INFO - Loaded existing subgraph for: 南湖里\n",
      "2025-04-09 17:00:00,615 - INFO - Loaded existing subgraph for: 國慶里\n",
      "2025-04-09 17:00:00,619 - INFO - Loaded existing subgraph for: 五分里\n",
      "2025-04-09 17:00:00,621 - INFO - Loaded existing subgraph for: 國順里\n",
      "2025-04-09 17:00:00,623 - INFO - Loaded existing subgraph for: 揚雅里\n",
      "2025-04-09 17:00:00,625 - INFO - Loaded existing subgraph for: 斯文里\n",
      "2025-04-09 17:00:00,630 - INFO - Loaded existing subgraph for: 集英里\n",
      "2025-04-09 17:00:00,634 - INFO - Loaded existing subgraph for: 新喜里\n",
      "2025-04-09 17:00:00,637 - INFO - Loaded existing subgraph for: 行政里\n",
      "2025-04-09 17:00:00,639 - INFO - Loaded existing subgraph for: 行孝里\n",
      "2025-04-09 17:00:00,642 - INFO - Loaded existing subgraph for: 行仁里\n",
      "2025-04-09 17:00:00,645 - INFO - Loaded existing subgraph for: 下埤里\n",
      "2025-04-09 17:00:00,649 - INFO - Loaded existing subgraph for: 石潭里\n",
      "2025-04-09 17:00:00,652 - INFO - Loaded existing subgraph for: 民福里\n",
      "2025-04-09 17:00:00,655 - INFO - Loaded existing subgraph for: 晴光里\n",
      "2025-04-09 17:00:00,658 - INFO - Loaded existing subgraph for: 蓬萊里\n",
      "2025-04-09 17:00:00,660 - INFO - Loaded existing subgraph for: 隆和里\n",
      "2025-04-09 17:00:00,661 - INFO - Loaded existing subgraph for: 景星里\n",
      "2025-04-09 17:00:00,664 - INFO - Loaded existing subgraph for: 蘆洲里\n",
      "2025-04-09 17:00:00,668 - INFO - Loaded existing subgraph for: 恆安里\n",
      "2025-04-09 17:00:00,670 - INFO - Loaded existing subgraph for: 三重里\n",
      "2025-04-09 17:00:00,674 - INFO - Loaded existing subgraph for: 新福里\n",
      "2025-04-09 17:00:00,677 - INFO - Loaded existing subgraph for: 新東里\n",
      "2025-04-09 17:00:00,680 - INFO - Loaded existing subgraph for: 新益里\n",
      "2025-04-09 17:00:00,682 - INFO - Loaded existing subgraph for: 南芳里\n",
      "2025-04-09 17:00:00,686 - INFO - Loaded existing subgraph for: 富錦里\n",
      "2025-04-09 17:00:00,689 - INFO - Loaded existing subgraph for: 三民里\n",
      "2025-04-09 17:00:00,694 - INFO - Loaded existing subgraph for: 民權里\n",
      "2025-04-09 17:00:00,697 - INFO - Loaded existing subgraph for: 週美里\n",
      "2025-04-09 17:00:00,701 - INFO - Loaded existing subgraph for: 聚葉里\n",
      "2025-04-09 17:00:00,847 - INFO - Loaded existing subgraph for: 新生里\n",
      "2025-04-09 17:00:00,851 - INFO - Loaded existing subgraph for: 東榮里\n",
      "2025-04-09 17:00:00,855 - INFO - Loaded existing subgraph for: 松江里\n",
      "2025-04-09 17:00:00,858 - INFO - Loaded existing subgraph for: 江寧里\n",
      "2025-04-09 17:00:00,862 - INFO - Loaded existing subgraph for: 民有里\n",
      "2025-04-09 17:00:00,864 - INFO - Loaded existing subgraph for: 延平里\n",
      "2025-04-09 17:00:00,867 - INFO - Loaded existing subgraph for: 大有里\n",
      "2025-04-09 17:00:00,872 - INFO - Loaded existing subgraph for: 南港里\n",
      "2025-04-09 17:00:00,877 - INFO - Loaded existing subgraph for: 中庄里\n",
      "2025-04-09 17:00:00,886 - INFO - Loaded existing subgraph for: 雙連里\n",
      "2025-04-09 17:00:00,890 - INFO - Loaded existing subgraph for: 江山里\n",
      "2025-04-09 17:00:00,894 - INFO - Loaded existing subgraph for: 聚盛里\n",
      "2025-04-09 17:00:00,897 - INFO - Loaded existing subgraph for: 重陽里\n",
      "2025-04-09 17:00:00,901 - INFO - Loaded existing subgraph for: 西新里\n",
      "2025-04-09 17:00:00,905 - INFO - Loaded existing subgraph for: 富泰里\n",
      "2025-04-09 17:00:00,909 - INFO - Loaded existing subgraph for: 介壽里\n",
      "2025-04-09 17:00:00,911 - INFO - Loaded existing subgraph for: 東昌里\n",
      "2025-04-09 17:00:00,914 - INFO - Loaded existing subgraph for: 東新里\n",
      "2025-04-09 17:00:00,917 - INFO - Loaded existing subgraph for: 中山里\n",
      "2025-04-09 17:00:00,919 - INFO - Loaded existing subgraph for: 中原里\n",
      "2025-04-09 17:00:00,923 - INFO - Loaded existing subgraph for: 中吉里\n",
      "2025-04-09 17:00:00,925 - INFO - Loaded existing subgraph for: 中央里\n",
      "2025-04-09 17:00:00,927 - INFO - Loaded existing subgraph for: 中央里\n",
      "2025-04-09 17:00:00,935 - INFO - Loaded existing subgraph for: 民安里\n",
      "2025-04-09 17:00:00,938 - INFO - Loaded existing subgraph for: 行善里\n",
      "2025-04-09 17:00:00,940 - INFO - Loaded existing subgraph for: 朱馥里\n",
      "2025-04-09 17:00:00,942 - INFO - Loaded existing subgraph for: 龍洲里\n",
      "2025-04-09 17:00:00,945 - INFO - Loaded existing subgraph for: 松基里\n",
      "2025-04-09 17:00:00,951 - INFO - Loaded existing subgraph for: 光能里\n",
      "2025-04-09 17:00:01,145 - INFO - Loaded existing subgraph for: 鵬程里\n",
      "2025-04-09 17:00:01,153 - INFO - Loaded existing subgraph for: 星明里\n",
      "2025-04-09 17:00:01,156 - INFO - Loaded existing subgraph for: 自強里\n",
      "2025-04-09 17:00:01,158 - INFO - Loaded existing subgraph for: 朝陽里\n",
      "2025-04-09 17:00:01,161 - INFO - Loaded existing subgraph for: 永樂里\n",
      "2025-04-09 17:00:01,164 - INFO - Loaded existing subgraph for: 龍田里\n",
      "2025-04-09 17:00:01,168 - INFO - Loaded existing subgraph for: 中華里\n",
      "2025-04-09 17:00:01,171 - INFO - Loaded existing subgraph for: 東明里\n",
      "2025-04-09 17:00:01,173 - INFO - Loaded existing subgraph for: 中南里\n",
      "2025-04-09 17:00:01,176 - INFO - Loaded existing subgraph for: 新富里\n",
      "2025-04-09 17:00:01,178 - INFO - Loaded existing subgraph for: 玉成里\n",
      "2025-04-09 17:00:01,181 - INFO - Loaded existing subgraph for: 康樂里\n",
      "2025-04-09 17:00:01,185 - INFO - Loaded existing subgraph for: 復華里\n",
      "2025-04-09 17:00:01,189 - INFO - Loaded existing subgraph for: 中正里\n",
      "2025-04-09 17:00:01,191 - INFO - Loaded existing subgraph for: 安平里\n",
      "2025-04-09 17:00:01,193 - INFO - Loaded existing subgraph for: 東光里\n",
      "2025-04-09 17:00:01,195 - INFO - Loaded existing subgraph for: 建功里\n",
      "2025-04-09 17:00:01,197 - INFO - Loaded existing subgraph for: 玉泉里\n",
      "2025-04-09 17:00:01,199 - INFO - Loaded existing subgraph for: 東勢里\n",
      "2025-04-09 17:00:01,204 - INFO - Loaded existing subgraph for: 建泰里\n",
      "2025-04-09 17:00:01,207 - INFO - Loaded existing subgraph for: 慈祐里\n",
      "2025-04-09 17:00:01,210 - INFO - Loaded existing subgraph for: 新光里\n",
      "2025-04-09 17:00:01,215 - INFO - Loaded existing subgraph for: 正得里\n",
      "2025-04-09 17:00:01,218 - INFO - Loaded existing subgraph for: 正義里\n",
      "2025-04-09 17:00:01,223 - INFO - Loaded existing subgraph for: 興亞里\n",
      "2025-04-09 17:00:01,227 - INFO - Loaded existing subgraph for: 朱園里\n",
      "2025-04-09 17:00:01,230 - INFO - Loaded existing subgraph for: 力行里\n",
      "2025-04-09 17:00:01,233 - INFO - Loaded existing subgraph for: 美仁里\n",
      "2025-04-09 17:00:01,236 - INFO - Loaded existing subgraph for: 復勢里\n",
      "2025-04-09 17:00:01,439 - INFO - Loaded existing subgraph for: 吉祥里\n",
      "2025-04-09 17:00:01,445 - INFO - Loaded existing subgraph for: 建明里\n",
      "2025-04-09 17:00:01,447 - INFO - Loaded existing subgraph for: 新聚里\n",
      "2025-04-09 17:00:01,451 - INFO - Loaded existing subgraph for: 合成里\n",
      "2025-04-09 17:00:01,455 - INFO - Loaded existing subgraph for: 光復里\n",
      "2025-04-09 17:00:01,458 - INFO - Loaded existing subgraph for: 聯成里\n",
      "2025-04-09 17:00:01,461 - INFO - Loaded existing subgraph for: 永吉里\n",
      "2025-04-09 17:00:01,464 - INFO - Loaded existing subgraph for: 四育里\n",
      "2025-04-09 17:00:01,467 - INFO - Loaded existing subgraph for: 雅祥里\n",
      "2025-04-09 17:00:01,469 - INFO - Loaded existing subgraph for: 福星里\n",
      "2025-04-09 17:00:01,475 - INFO - Loaded existing subgraph for: 黎明里\n",
      "2025-04-09 17:00:01,478 - INFO - Loaded existing subgraph for: 中研里\n",
      "2025-04-09 17:00:01,481 - INFO - Loaded existing subgraph for: 新仁里\n",
      "2025-04-09 17:00:01,485 - INFO - Loaded existing subgraph for: 正守里\n",
      "2025-04-09 17:00:01,487 - INFO - Loaded existing subgraph for: 復盛里\n",
      "2025-04-09 17:00:01,489 - INFO - Loaded existing subgraph for: 五常里\n",
      "2025-04-09 17:00:01,492 - INFO - Loaded existing subgraph for: 朱崙里\n",
      "2025-04-09 17:00:01,494 - INFO - Loaded existing subgraph for: 復建里\n",
      "2025-04-09 17:00:01,497 - INFO - Loaded existing subgraph for: 敦化里\n",
      "2025-04-09 17:00:01,499 - INFO - Loaded existing subgraph for: 吉仁里\n",
      "2025-04-09 17:00:01,502 - INFO - Loaded existing subgraph for: 復源里\n",
      "2025-04-09 17:00:01,505 - INFO - Loaded existing subgraph for: 中崙里\n",
      "2025-04-09 17:00:01,507 - INFO - Loaded existing subgraph for: 福成里\n",
      "2025-04-09 17:00:01,510 - INFO - Loaded existing subgraph for: 萬福里\n",
      "2025-04-09 17:00:01,517 - INFO - Loaded existing subgraph for: 梅花里\n",
      "2025-04-09 17:00:01,523 - INFO - Loaded existing subgraph for: 埤頭里\n",
      "2025-04-09 17:00:01,526 - INFO - Loaded existing subgraph for: 成福里\n",
      "2025-04-09 17:00:01,530 - INFO - Loaded existing subgraph for: 萬壽里\n",
      "2025-04-09 17:00:01,534 - INFO - Loaded existing subgraph for: 敦厚里\n",
      "2025-04-09 16:59:59,749 - INFO - Loaded existing subgraph for: 六藝里\n",
      "2025-04-09 16:59:59,752 - INFO - Loaded existing subgraph for: 五全里\n",
      "2025-04-09 16:59:59,755 - INFO - Loaded existing subgraph for: 四維里\n",
      "2025-04-09 16:59:59,757 - INFO - Loaded existing subgraph for: 鴻福里\n",
      "2025-04-09 16:59:59,760 - INFO - Loaded existing subgraph for: 民輝里\n",
      "2025-04-09 16:59:59,763 - INFO - Loaded existing subgraph for: 幸福里\n",
      "2025-04-09 16:59:59,766 - INFO - Loaded existing subgraph for: 永春里\n",
      "2025-04-09 16:59:59,769 - INFO - Loaded existing subgraph for: 光武里\n",
      "2025-04-09 16:59:59,772 - INFO - Loaded existing subgraph for: 華聲里\n",
      "2025-04-09 16:59:59,774 - INFO - Loaded existing subgraph for: 誠安里\n",
      "2025-04-09 16:59:59,777 - INFO - Loaded existing subgraph for: 建安里\n",
      "2025-04-09 16:59:59,779 - INFO - Loaded existing subgraph for: 菜園里\n",
      "2025-04-09 16:59:59,781 - INFO - Loaded existing subgraph for: 昌隆里\n",
      "2025-04-09 16:59:59,784 - INFO - Loaded existing subgraph for: 車層里\n",
      "2025-04-09 16:59:59,786 - INFO - Loaded existing subgraph for: 西門里\n",
      "2025-04-09 16:59:59,789 - INFO - Loaded existing subgraph for: 大道里\n",
      "2025-04-09 16:59:59,791 - INFO - Loaded existing subgraph for: 興雅里\n",
      "2025-04-09 16:59:59,793 - INFO - Loaded existing subgraph for: 舊莊里\n",
      "2025-04-09 16:59:59,796 - INFO - Loaded existing subgraph for: 長春里\n",
      "2025-04-09 16:59:59,800 - INFO - Loaded existing subgraph for: 東門里\n",
      "2025-04-09 16:59:59,803 - INFO - Loaded existing subgraph for: 松光里\n",
      "2025-04-09 16:59:59,806 - INFO - Loaded existing subgraph for: 幸市里\n",
      "2025-04-09 16:59:59,809 - INFO - Loaded existing subgraph for: 富台里\n",
      "2025-04-09 16:59:59,812 - INFO - Loaded existing subgraph for: 青山里\n",
      "2025-04-09 16:59:59,816 - INFO - Loaded existing subgraph for: 建國里\n",
      "2025-04-09 16:59:59,818 - INFO - Loaded existing subgraph for: 新起里\n",
      "2025-04-09 16:59:59,821 - INFO - Loaded existing subgraph for: 柳鄉里\n",
      "2025-04-09 16:59:59,825 - INFO - Loaded existing subgraph for: 中行里\n",
      "2025-04-09 16:59:59,827 - INFO - Loaded existing subgraph for: 百福里\n",
      "2025-04-09 17:00:00,033 - INFO - Loaded existing subgraph for: 義村里\n",
      "2025-04-09 17:00:00,036 - INFO - Loaded existing subgraph for: 仁愛里\n",
      "2025-04-09 17:00:00,038 - INFO - Loaded existing subgraph for: 建倫里\n",
      "2025-04-09 17:00:00,042 - INFO - Loaded existing subgraph for: 文北里\n",
      "2025-04-09 17:00:00,044 - INFO - Loaded existing subgraph for: 仁福里\n",
      "2025-04-09 17:00:00,046 - INFO - Loaded existing subgraph for: 正聲里\n",
      "2025-04-09 17:00:00,048 - INFO - Loaded existing subgraph for: 興隆里\n",
      "2025-04-09 17:00:00,051 - INFO - Loaded existing subgraph for: 廣居里\n",
      "2025-04-09 17:00:00,055 - INFO - Loaded existing subgraph for: 中坡里\n",
      "2025-04-09 17:00:00,057 - INFO - Loaded existing subgraph for: 大仁里\n",
      "2025-04-09 17:00:00,060 - INFO - Loaded existing subgraph for: 富民里\n",
      "2025-04-09 17:00:00,061 - INFO - Loaded existing subgraph for: 福音里\n",
      "2025-04-09 17:00:00,063 - INFO - Loaded existing subgraph for: 國業里\n",
      "2025-04-09 17:00:00,065 - INFO - Loaded existing subgraph for: 仁德里\n",
      "2025-04-09 17:00:00,068 - INFO - Loaded existing subgraph for: 安康里\n",
      "2025-04-09 17:00:00,072 - INFO - Loaded existing subgraph for: 西村里\n",
      "2025-04-09 17:00:00,074 - INFO - Loaded existing subgraph for: 九如里\n",
      "2025-04-09 17:00:00,078 - INFO - Loaded existing subgraph for: 三愛里\n",
      "2025-04-09 17:00:00,081 - INFO - Loaded existing subgraph for: 民炤里\n",
      "2025-04-09 17:00:00,083 - INFO - Loaded existing subgraph for: 和安里\n",
      "2025-04-09 17:00:00,086 - INFO - Loaded existing subgraph for: 仁慈里\n",
      "2025-04-09 17:00:00,088 - INFO - Loaded existing subgraph for: 德安里\n",
      "2025-04-09 17:00:00,091 - INFO - Loaded existing subgraph for: 敦安里\n",
      "2025-04-09 17:00:00,094 - INFO - Loaded existing subgraph for: 文祥里\n",
      "2025-04-09 17:00:00,096 - INFO - Loaded existing subgraph for: 敦煌里\n",
      "2025-04-09 17:00:00,098 - INFO - Loaded existing subgraph for: 光信里\n",
      "2025-04-09 17:00:00,100 - INFO - Loaded existing subgraph for: 正和里\n",
      "2025-04-09 17:00:00,102 - INFO - Loaded existing subgraph for: 愛國里\n",
      "2025-04-09 17:00:00,105 - INFO - Loaded existing subgraph for: 松隆里\n",
      "2025-04-09 17:00:00,337 - INFO - Loaded existing subgraph for: 南門里\n",
      "2025-04-09 17:00:00,341 - INFO - Loaded existing subgraph for: 富福里\n",
      "2025-04-09 17:00:00,344 - INFO - Loaded existing subgraph for: 松友里\n",
      "2025-04-09 17:00:00,346 - INFO - Loaded existing subgraph for: 光明里\n",
      "2025-04-09 17:00:00,348 - INFO - Loaded existing subgraph for: 華江里\n",
      "2025-04-09 17:00:00,351 - INFO - Loaded existing subgraph for: 糖廍里\n",
      "2025-04-09 17:00:00,354 - INFO - Loaded existing subgraph for: 龍福里\n",
      "2025-04-09 17:00:00,357 - INFO - Loaded existing subgraph for: 新營里\n",
      "2025-04-09 17:00:00,359 - INFO - Loaded existing subgraph for: 中興里\n",
      "2025-04-09 17:00:00,362 - INFO - Loaded existing subgraph for: 永康里\n",
      "2025-04-09 17:00:00,364 - INFO - Loaded existing subgraph for: 頂碩里\n",
      "2025-04-09 17:00:00,366 - INFO - Loaded existing subgraph for: 綠堤里\n",
      "2025-04-09 17:00:00,369 - INFO - Loaded existing subgraph for: 三犁里\n",
      "2025-04-09 17:00:00,373 - INFO - Loaded existing subgraph for: 福住里\n",
      "2025-04-09 17:00:00,377 - INFO - Loaded existing subgraph for: 龍門里\n",
      "2025-04-09 17:00:00,380 - INFO - Loaded existing subgraph for: 龍圖里\n",
      "2025-04-09 17:00:00,382 - INFO - Loaded existing subgraph for: 住安里\n",
      "2025-04-09 17:00:00,384 - INFO - Loaded existing subgraph for: 廈安里\n",
      "2025-04-09 17:00:00,386 - INFO - Loaded existing subgraph for: 義安里\n",
      "2025-04-09 17:00:00,388 - INFO - Loaded existing subgraph for: 通安里\n",
      "2025-04-09 17:00:00,390 - INFO - Loaded existing subgraph for: 通化里\n",
      "2025-04-09 17:00:00,392 - INFO - Loaded existing subgraph for: 景聯里\n",
      "2025-04-09 17:00:00,395 - INFO - Loaded existing subgraph for: 景新里\n",
      "2025-04-09 17:00:00,399 - INFO - Loaded existing subgraph for: 三張里\n",
      "2025-04-09 17:00:00,401 - INFO - Loaded existing subgraph for: 和平里\n",
      "2025-04-09 17:00:00,404 - INFO - Loaded existing subgraph for: 雙園里\n",
      "2025-04-09 17:00:00,407 - INFO - Loaded existing subgraph for: 錦泰里\n",
      "2025-04-09 17:00:00,409 - INFO - Loaded existing subgraph for: 龍光里\n",
      "2025-04-09 17:00:00,413 - INFO - Loaded existing subgraph for: 南福里\n",
      "2025-04-09 17:00:00,641 - INFO - Loaded existing subgraph for: 新龍里\n",
      "2025-04-09 17:00:00,645 - INFO - Loaded existing subgraph for: 龍雲里\n",
      "2025-04-09 17:00:00,647 - INFO - Loaded existing subgraph for: 龍興里\n",
      "2025-04-09 17:00:00,650 - INFO - Loaded existing subgraph for: 龍安里\n",
      "2025-04-09 17:00:00,652 - INFO - Loaded existing subgraph for: 忠勤里\n",
      "2025-04-09 17:00:00,656 - INFO - Loaded existing subgraph for: 龍陣里\n",
      "2025-04-09 17:00:00,659 - INFO - Loaded existing subgraph for: 臨江里\n",
      "2025-04-09 17:00:00,662 - INFO - Loaded existing subgraph for: 錦安里\n",
      "2025-04-09 17:00:00,664 - INFO - Loaded existing subgraph for: 嘉興里\n",
      "2025-04-09 17:00:00,666 - INFO - Loaded existing subgraph for: 新忠里\n",
      "2025-04-09 17:00:00,668 - INFO - Loaded existing subgraph for: 景勤里\n",
      "2025-04-09 17:00:00,671 - INFO - Loaded existing subgraph for: 錦華里\n",
      "2025-04-09 17:00:00,672 - INFO - Loaded existing subgraph for: 新安里\n",
      "2025-04-09 17:00:00,674 - INFO - Loaded existing subgraph for: 新安里\n",
      "2025-04-09 17:00:00,678 - INFO - Loaded existing subgraph for: 日善里\n",
      "2025-04-09 17:00:00,680 - INFO - Loaded existing subgraph for: 新和里\n",
      "2025-04-09 17:00:00,682 - INFO - Loaded existing subgraph for: 全安里\n",
      "2025-04-09 17:00:00,684 - INFO - Loaded existing subgraph for: 永功里\n",
      "2025-04-09 17:00:00,685 - INFO - Loaded existing subgraph for: 永昌里\n",
      "2025-04-09 17:00:00,687 - INFO - Loaded existing subgraph for: 和德里\n",
      "2025-04-09 17:00:00,690 - INFO - Loaded existing subgraph for: 龍生里\n",
      "2025-04-09 17:00:00,692 - INFO - Loaded existing subgraph for: 法治里\n",
      "2025-04-09 17:00:00,695 - INFO - Loaded existing subgraph for: 群賢里\n",
      "2025-04-09 17:00:00,697 - INFO - Loaded existing subgraph for: 群英里\n",
      "2025-04-09 17:00:00,700 - INFO - Loaded existing subgraph for: 忠德里\n",
      "2025-04-09 17:00:00,703 - INFO - Loaded existing subgraph for: 雙和里\n",
      "2025-04-09 17:00:00,710 - INFO - Loaded existing subgraph for: 螢雪里\n",
      "2025-04-09 17:00:00,713 - INFO - Loaded existing subgraph for: 黎順里\n",
      "2025-04-09 17:00:00,715 - INFO - Loaded existing subgraph for: 螢圃里\n",
      "2025-04-09 17:00:00,963 - INFO - Loaded existing subgraph for: 板溪里\n",
      "2025-04-09 17:00:00,968 - INFO - Loaded existing subgraph for: 古莊里\n",
      "2025-04-09 17:00:00,974 - INFO - Loaded existing subgraph for: 六合里\n",
      "2025-04-09 17:00:00,980 - INFO - Loaded existing subgraph for: 惠安里\n",
      "2025-04-09 17:00:00,982 - INFO - Loaded existing subgraph for: 錦德里\n",
      "2025-04-09 17:00:00,984 - INFO - Loaded existing subgraph for: 凌霄里\n",
      "2025-04-09 17:00:00,986 - INFO - Loaded existing subgraph for: 龍泉里\n",
      "2025-04-09 17:00:00,989 - INFO - Loaded existing subgraph for: 龍坡里\n",
      "2025-04-09 17:00:00,993 - INFO - Loaded existing subgraph for: 全德里\n",
      "2025-04-09 17:00:00,996 - INFO - Loaded existing subgraph for: 騰雲里\n",
      "2025-04-09 17:00:01,000 - INFO - Loaded existing subgraph for: 頂東里\n",
      "2025-04-09 17:00:01,002 - INFO - Loaded existing subgraph for: 忠貞里\n",
      "2025-04-09 17:00:01,005 - INFO - Loaded existing subgraph for: 龍淵里\n",
      "2025-04-09 17:00:01,009 - INFO - Loaded existing subgraph for: 壽德里\n",
      "2025-04-09 17:00:01,012 - INFO - Loaded existing subgraph for: 臥龍里\n",
      "2025-04-09 17:00:01,014 - INFO - Loaded existing subgraph for: 虎嘯里\n",
      "2025-04-09 17:00:01,015 - INFO - Loaded existing subgraph for: 孝德里\n",
      "2025-04-09 17:00:01,018 - INFO - Loaded existing subgraph for: 黎平里\n",
      "2025-04-09 17:00:01,021 - INFO - Loaded existing subgraph for: 芳和里\n",
      "2025-04-09 17:00:01,024 - INFO - Loaded existing subgraph for: 保德里\n",
      "2025-04-09 17:00:01,026 - INFO - Loaded existing subgraph for: 河堤里\n",
      "2025-04-09 17:00:01,031 - INFO - Loaded existing subgraph for: 泰和里\n",
      "2025-04-09 17:00:01,033 - INFO - Loaded existing subgraph for: 網溪里\n",
      "2025-04-09 17:00:01,036 - INFO - Loaded existing subgraph for: 古風里\n",
      "2025-04-09 17:00:01,040 - INFO - Loaded existing subgraph for: 黎忠里\n",
      "2025-04-09 17:00:01,042 - INFO - Loaded existing subgraph for: 銘德里\n",
      "2025-04-09 17:00:01,058 - INFO - Loaded existing subgraph for: 學府里\n",
      "2025-04-09 17:00:01,063 - INFO - Loaded existing subgraph for: 黎孝里\n",
      "2025-04-09 17:00:01,069 - INFO - Loaded existing subgraph for: 大學里\n",
      "2025-04-09 17:00:01,271 - INFO - Loaded existing subgraph for: 日祥里\n",
      "2025-04-09 17:00:01,275 - INFO - Loaded existing subgraph for: 興德里\n",
      "2025-04-09 17:00:01,277 - INFO - Loaded existing subgraph for: 榮德里\n",
      "2025-04-09 17:00:01,280 - INFO - Loaded existing subgraph for: 華中里\n",
      "2025-04-09 17:00:01,282 - INFO - Loaded existing subgraph for: 林興里\n",
      "2025-04-09 17:00:01,285 - INFO - Loaded existing subgraph for: 黎和里\n",
      "2025-04-09 17:00:01,287 - INFO - Loaded existing subgraph for: 黎元里\n",
      "2025-04-09 17:00:01,289 - INFO - Loaded existing subgraph for: 黎安里\n",
      "2025-04-09 17:00:01,291 - INFO - Loaded existing subgraph for: 文盛里\n",
      "2025-04-09 17:00:01,294 - INFO - Loaded existing subgraph for: 富水里\n",
      "2025-04-09 17:00:01,296 - INFO - Loaded existing subgraph for: 博嘉里\n",
      "2025-04-09 17:00:01,299 - INFO - Loaded existing subgraph for: 水源里\n",
      "2025-04-09 17:00:01,302 - INFO - Loaded existing subgraph for: 興昌里\n",
      "2025-04-09 17:00:01,306 - INFO - Loaded existing subgraph for: 興泰里\n",
      "2025-04-09 17:00:01,309 - INFO - Loaded existing subgraph for: 萬年里\n",
      "2025-04-09 17:00:01,312 - INFO - Loaded existing subgraph for: 興旺里\n",
      "2025-04-09 17:00:01,315 - INFO - Loaded existing subgraph for: 萬盛里\n",
      "2025-04-09 17:00:01,318 - INFO - Loaded existing subgraph for: 萬美里\n",
      "2025-04-09 17:00:01,320 - INFO - Loaded existing subgraph for: 萬和里\n",
      "2025-04-09 17:00:01,323 - INFO - Loaded existing subgraph for: 興邦里\n",
      "2025-04-09 17:00:01,326 - INFO - Loaded existing subgraph for: 萬興里\n",
      "2025-04-09 17:00:01,329 - INFO - Loaded existing subgraph for: 萬祥里\n",
      "2025-04-09 17:00:01,332 - INFO - Loaded existing subgraph for: 興豐里\n",
      "2025-04-09 17:00:01,335 - INFO - Loaded existing subgraph for: 萬芳里\n",
      "2025-04-09 17:00:01,338 - INFO - Loaded existing subgraph for: 萬隆里\n",
      "2025-04-09 17:00:01,341 - INFO - Loaded existing subgraph for: 興光里\n",
      "2025-04-09 17:00:01,351 - INFO - Loaded existing subgraph for: 萬有里\n",
      "2025-04-09 17:00:01,355 - INFO - Loaded existing subgraph for: 興業里\n",
      "2025-04-09 17:00:01,360 - INFO - Loaded existing subgraph for: 興安里\n",
      "2025-04-09 17:00:01,563 - INFO - Loaded existing subgraph for: 興得里\n",
      "2025-04-09 17:00:01,567 - INFO - Loaded existing subgraph for: 景仁里\n",
      "2025-04-09 17:00:01,571 - INFO - Loaded existing subgraph for: 興福里\n",
      "2025-04-09 17:00:01,576 - INFO - Loaded existing subgraph for: 景華里\n",
      "2025-04-09 17:00:01,580 - INFO - Loaded existing subgraph for: 景慶里\n",
      "2025-04-09 17:00:01,583 - INFO - Loaded existing subgraph for: 政大里\n",
      "2025-04-09 17:00:01,585 - INFO - Loaded existing subgraph for: 興家里\n",
      "2025-04-09 17:00:01,588 - INFO - Loaded existing subgraph for: 景東里\n",
      "2025-04-09 17:00:01,590 - INFO - Loaded existing subgraph for: 木柵里\n",
      "2025-04-09 17:00:01,593 - INFO - Loaded existing subgraph for: 景美里\n",
      "2025-04-09 17:00:01,596 - INFO - Loaded existing subgraph for: 明興里\n",
      "2025-04-09 17:00:01,598 - INFO - Loaded existing subgraph for: 華興里\n",
      "2025-04-09 17:00:01,601 - INFO - Loaded existing subgraph for: 景行里\n",
      "2025-04-09 17:00:01,604 - INFO - Loaded existing subgraph for: 明義里\n",
      "2025-04-09 17:00:01,607 - INFO - Loaded existing subgraph for: 木新里\n",
      "2025-04-09 17:00:01,610 - INFO - Loaded existing subgraph for: 試院里\n",
      "2025-04-09 17:00:01,612 - INFO - Loaded existing subgraph for: 忠順里\n",
      "2025-04-09 17:00:01,614 - INFO - Loaded existing subgraph for: 樟林里\n",
      "2025-04-09 17:00:01,617 - INFO - Loaded existing subgraph for: 指南里\n",
      "2025-04-09 17:00:01,620 - INFO - Loaded existing subgraph for: 順興里\n",
      "2025-04-09 17:00:01,622 - INFO - Loaded existing subgraph for: 樟樹里\n",
      "2025-04-09 17:00:01,624 - INFO - Loaded existing subgraph for: 樟文里\n",
      "2025-04-09 17:00:01,626 - INFO - Loaded existing subgraph for: 樟腳里\n",
      "2025-04-09 17:00:01,628 - INFO - Loaded existing subgraph for: 老泉里\n",
      "2025-04-09 17:00:01,632 - INFO - Loaded existing subgraph for: 樟新里\n",
      "Collecting subgraphs: 100%|██████████| 460/460 [00:18<00:00, 25.32it/s]\n",
      "2025-04-09 17:00:20,282 - INFO - Finished building/loading 454 subgraphs.\n",
      "2025-04-09 17:00:20,369 - INFO - Stage 3: Calculating rule-based walkability scores...\n",
      "Calculating walkability:   0%|          | 0/454 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'road_density'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids_wsl/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'road_density'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 617\u001b[39m\n\u001b[32m    614\u001b[39m     logging.info(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete. Check walkability_scores.geojson for results.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 612\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    609\u001b[39m subgraphs, _ = build_graph(data)\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# Calculate walkability\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m subgraphs = \u001b[43mcalculate_walkability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneighborhoods\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete. Check walkability_scores.geojson for results.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 447\u001b[39m, in \u001b[36mcalculate_walkability\u001b[39m\u001b[34m(subgraphs, neighborhoods_gdf)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lie_name, subgraph_data \u001b[38;5;129;01min\u001b[39;00m tqdm(subgraphs.items(), desc=\u001b[33m\"\u001b[39m\u001b[33mCalculating walkability\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    446\u001b[39m     nodes_df = subgraph_data[\u001b[33m'\u001b[39m\u001b[33mnodes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     nodes_df = \u001b[43mcompute_walkability_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m     subgraph_data[\u001b[33m'\u001b[39m\u001b[33mnodes\u001b[39m\u001b[33m'\u001b[39m] = nodes_df\n\u001b[32m    450\u001b[39m     neighborhood_node = nodes_df[nodes_df[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mneighborhood\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 429\u001b[39m, in \u001b[36mcompute_walkability_scores\u001b[39m\u001b[34m(nodes_df)\u001b[39m\n\u001b[32m    423\u001b[39m amenity_score = \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    424\u001b[39m     (neighborhood_df[col] / (neighborhood_df[col].max() + \u001b[32m1e-6\u001b[39m)) * \u001b[32m0.05\u001b[39m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m amenity_cols \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m neighborhood_df.columns \u001b[38;5;129;01mand\u001b[39;00m neighborhood_df[col].max() > \u001b[32m0\u001b[39m\n\u001b[32m    426\u001b[39m )\n\u001b[32m    428\u001b[39m \u001b[38;5;66;03m# Road density score\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m road_density_score = ((\u001b[43mneighborhood_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroad_density\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m - neighborhood_df[\u001b[33m'\u001b[39m\u001b[33mroad_density\u001b[39m\u001b[33m'\u001b[39m].min()) /\n\u001b[32m    430\u001b[39m                       (neighborhood_df[\u001b[33m'\u001b[39m\u001b[33mroad_density\u001b[39m\u001b[33m'\u001b[39m].max() - neighborhood_df[\u001b[33m'\u001b[39m\u001b[33mroad_density\u001b[39m\u001b[33m'\u001b[39m].min() + \u001b[32m1e-6\u001b[39m)) * \u001b[32m0.1\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# Final walkability score\u001b[39;00m\n\u001b[32m    433\u001b[39m walkability = (land_use_score + ndvi_score + tree_score + transit_score +\n\u001b[32m    434\u001b[39m                amenity_score + road_density_score - elderly_factor - accident_factor).clip(lower=\u001b[32m0.0\u001b[39m, upper=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids_wsl/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids_wsl/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'road_density'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import cudf\n",
    "import cuspatial\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Show info messages and above (e.g., warnings, errors)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Include timestamp and level\n",
    ")\n",
    "\n",
    "# Define file paths (customize these based on your system)\n",
    "BASE_DIR = \"/home/johnny/Iaacthesis/projects/Geojson/GNN_Read_data\"\n",
    "LANDUSE_NDVI_PATH = os.path.join(BASE_DIR, \"neighborhoods_with_ndvi_numerical.geojson\")\n",
    "OSM_BUILDINGS_PATH = os.path.join(BASE_DIR, \"Taipei_Buildings_fulldata.geojson\")\n",
    "OSM_ROADS_PATH = os.path.join(BASE_DIR, \"taipei_segments_cleaned_verified.geoparquet\")\n",
    "OSM_TREES_PATH = os.path.join(BASE_DIR, \"taipei_land.geoparquet\")\n",
    "OSM_TRANSIT_PATH = os.path.join(BASE_DIR, \"taipei_infrastructure.geoparquet\")\n",
    "URBAN_MASTERPLAN_PATH = os.path.join(BASE_DIR, \"Taipei_urban_masterplan.geojson\")\n",
    "ACCIDENTS_PATH = os.path.join(BASE_DIR, \"2023_accidents.geojson\")\n",
    "POPULATION_PATH = os.path.join(BASE_DIR, \"population.json\")\n",
    "SUBGRAPH_DIR = os.path.join(BASE_DIR, \"subgraphs\")\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Helper Functions\n",
    "def check_geometries(gdf, name):\n",
    "    \"\"\"Check for invalid geometries in a GeoDataFrame.\"\"\"\n",
    "    # It's good practice to fix or remove invalid geometries before spatial operations\n",
    "    # gdf.geometry = gdf.geometry.buffer(0) # A common trick to try and fix invalid geoms\n",
    "    invalid_geoms = gdf[~gdf.geometry.is_valid]\n",
    "    if not invalid_geoms.empty:\n",
    "        print(f\"Warning: {len(invalid_geoms)} invalid geometries found in {name}. Consider cleaning them.\")\n",
    "        # Optionally remove or fix them here\n",
    "        # gdf = gdf[gdf.geometry.is_valid]\n",
    "    return gdf\n",
    "\n",
    "def print_data_structure(data_dict):\n",
    "    \"\"\"Print the structure and summary of datasets in a dictionary.\"\"\"\n",
    "    print(\"\\n--- Data Structure Overview ---\")\n",
    "    for key, df in data_dict.items():\n",
    "        if isinstance(df, (gpd.GeoDataFrame, pd.DataFrame)):\n",
    "            print(f\"\\nDataset: {key}\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            print(f\"Data types:\\n{df.dtypes}\")\n",
    "            print(f\"Missing values per column:\\n{df.isnull().sum()}\")\n",
    "            if not df.select_dtypes(include=['float64', 'int64']).empty:\n",
    "                print(f\"Summary statistics:\\n{df.describe()}\")\n",
    "            print(\"Sample data (first row):\")\n",
    "            print(df.head(1))\n",
    "        else:\n",
    "            print(f\"\\nDataset: {key} - Not a DataFrame or GeoDataFrame\")\n",
    "    print(\"--- End of Data Structure Overview ---\\n\")\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load and prepare geospatial datasets with optimized memory usage.\"\"\"\n",
    "    logging.info(\"Stage 1: Loading and preparing data...\")\n",
    "    with tqdm(total=8, desc=\"Loading files\") as pbar:\n",
    "        # Load datasets\n",
    "        neighborhoods_gdf = gpd.read_file(\n",
    "            LANDUSE_NDVI_PATH,\n",
    "            encoding='utf-8-sig',\n",
    "            columns=['LIE_NAME', 'geometry', 'land_use_residential_percent', 'land_use_commercial_percent',\n",
    "                     'land_use_education_percent', 'ndvi_mean']\n",
    "        ).to_crs('EPSG:3826')\n",
    "        pbar.update(1)\n",
    "\n",
    "        buildings_gdf = gpd.read_file(OSM_BUILDINGS_PATH, columns=['geometry', 'building']).to_crs('EPSG:3826')\n",
    "        buildings_gdf['area_m2'] = buildings_gdf.geometry.area\n",
    "        pbar.update(1)\n",
    "\n",
    "        roads_gdf = gpd.read_parquet(OSM_ROADS_PATH, columns=['geometry', 'class']).to_crs('EPSG:3826')\n",
    "        roads_gdf['length_m'] = roads_gdf.geometry.length\n",
    "        missing_road_types = roads_gdf['class'].isnull().sum()\n",
    "        if missing_road_types > 0:\n",
    "            logging.info(f\"Found {missing_road_types} roads with missing 'class' values.\")\n",
    "        pbar.update(1)\n",
    "\n",
    "        trees_gdf = gpd.read_parquet(OSM_TREES_PATH, columns=['geometry', 'subtype', 'class']).to_crs('EPSG:3826')\n",
    "        trees_gdf = trees_gdf[trees_gdf['subtype'] == 'tree']\n",
    "        pbar.update(1)\n",
    "\n",
    "        transit_gdf = gpd.read_parquet(OSM_TRANSIT_PATH, columns=['geometry', 'class']).to_crs('EPSG:3826')\n",
    "        transit_gdf = transit_gdf[transit_gdf['class'].isin(['stop_position', 'bus_stop'])]\n",
    "        pbar.update(1)\n",
    "\n",
    "        urban_masterplan_gdf = gpd.read_file(URBAN_MASTERPLAN_PATH, columns=['geometry', 'Category']).to_crs('EPSG:3826')\n",
    "        pbar.update(1)\n",
    "\n",
    "        accidents_gdf = gpd.read_file(ACCIDENTS_PATH, columns=['geometry']).to_crs('EPSG:3826')\n",
    "        pbar.update(1)\n",
    "\n",
    "        population_df = pd.read_json(POPULATION_PATH)\n",
    "        population_df.rename(columns={'District': 'LIE_NAME', 'Total_Population': 'total_population',\n",
    "                                      'Elderly_Percentage': 'elderly_percentage'}, inplace=True)\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Print master plan categories and road types categories\n",
    "    print(\"Master Plan Categories:\", urban_masterplan_gdf['Category'].unique().tolist())\n",
    "    print(\"Road Types Categories:\", roads_gdf['class'].unique().tolist())\n",
    "\n",
    "    # Merge population data\n",
    "    neighborhoods_gdf['LIE_NAME'] = neighborhoods_gdf['LIE_NAME'].str.strip().str.lower()\n",
    "    population_df['LIE_NAME'] = population_df['LIE_NAME'].str.strip().str.lower()\n",
    "    neighborhoods_gdf = neighborhoods_gdf.merge(\n",
    "        population_df[['LIE_NAME', 'total_population', 'elderly_percentage']], on='LIE_NAME', how='left'\n",
    "    )\n",
    "\n",
    "    # Compute tree and transit counts\n",
    "    tree_counts = gpd.sjoin(neighborhoods_gdf, trees_gdf, how='left', predicate='contains')\n",
    "    neighborhoods_gdf['tree_count'] = tree_counts.groupby(tree_counts.index).size().reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "    transit_counts = gpd.sjoin(neighborhoods_gdf, transit_gdf, how='left', predicate='contains')\n",
    "    neighborhoods_gdf['transit_count'] = transit_counts.groupby(transit_counts.index).size().reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "\n",
    "    # Compute accident counts per neighborhood\n",
    "    accident_counts = gpd.sjoin(neighborhoods_gdf, accidents_gdf, how='left', predicate='contains')\n",
    "    neighborhoods_gdf['accident_count'] = accident_counts.groupby(accident_counts.index).size().reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "\n",
    "    # Compute road density\n",
    "    road_lengths = gpd.sjoin(roads_gdf, neighborhoods_gdf, how='inner', predicate='intersects')\n",
    "    road_lengths_grouped = road_lengths.groupby('index_right')['length_m'].sum()\n",
    "    neighborhoods_gdf['road_length'] = road_lengths_grouped.reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "    neighborhoods_gdf['road_density'] = neighborhoods_gdf['road_length'] / neighborhoods_gdf.geometry.area\n",
    "\n",
    "    # Inspect unique categories in urban_masterplan_gdf\n",
    "    unique_categories = urban_masterplan_gdf['Category'].unique()\n",
    "    logging.info(f\"Unique categories in urban_masterplan_gdf: {unique_categories}\")\n",
    "\n",
    "    # Use actual categories from the data\n",
    "    amenity_categories = ['City_Open_Area', 'Education', 'Commercial']\n",
    "    for category in amenity_categories:\n",
    "        amenity_gdf = urban_masterplan_gdf[urban_masterplan_gdf['Category'] == category]\n",
    "        amenity_counts = gpd.sjoin(neighborhoods_gdf, amenity_gdf, how='left', predicate='contains')\n",
    "        column_name = f\"{category.lower().replace('_', '')}_count\"\n",
    "        neighborhoods_gdf[column_name] = amenity_counts.groupby(amenity_counts.index).size().reindex(neighborhoods_gdf.index, fill_value=0)\n",
    "        if neighborhoods_gdf[column_name].min() > 0:\n",
    "            logging.warning(f\"No neighborhoods with zero {column_name}. Check data or computation.\")\n",
    "\n",
    "    data_dict = {\n",
    "        'neighborhoods': neighborhoods_gdf,\n",
    "        'buildings': buildings_gdf,\n",
    "        'roads': roads_gdf,\n",
    "        'trees': trees_gdf,\n",
    "        'transit': transit_gdf,\n",
    "        'urban_masterplan': urban_masterplan_gdf,\n",
    "        'accidents': accidents_gdf,\n",
    "        'population': population_df\n",
    "    }\n",
    "    print_data_structure(data_dict)\n",
    "    return data_dict\n",
    "\n",
    "# Stage 2: Graph Construction\n",
    "import geopandas as gpd\n",
    "import cudf\n",
    "import cuspatial\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory for storing subgraphs globally\n",
    "SUBGRAPH_DIR = \"subgraphs\"\n",
    "\n",
    "import geopandas as gpd\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "SUBGRAPH_DIR = \"subgraphs\"\n",
    "\n",
    "def build_subgraph_for_neighborhood(args):\n",
    "    \"\"\"Helper function to build or load a subgraph for a single neighborhood using pandas.\"\"\"\n",
    "    (idx, neighborhoods_gdf, buildings_gdf, roads_gdf, trees_gdf, transit_gdf, feature_cols, all_columns, SUBGRAPH_DIR) = args\n",
    "    lie_name = neighborhoods_gdf['LIE_NAME'].iloc[idx]\n",
    "    subgraph_path = os.path.join(SUBGRAPH_DIR, f\"subgraph_{lie_name}.pkl\")\n",
    "\n",
    "# Check if subgraph exists and is loadable\n",
    "    if os.path.exists(subgraph_path):\n",
    "        try:\n",
    "            with open(subgraph_path, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "                logging.info(f\"Loaded existing subgraph for: {lie_name}\")\n",
    "                return lie_name, loaded_data  # Return pandas DataFrames\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load subgraph {subgraph_path}. Regenerating. Error: {e}\")\n",
    "\n",
    "    # If subgraph doesn’t exist or loading failed, compute it\n",
    "    logging.info(f\"Computing subgraph for: {lie_name}\")\n",
    "    try:\n",
    "        all_nodes = []\n",
    "        all_edges = []\n",
    "\n",
    "        # Neighborhood node\n",
    "        neighborhood_node_id = f\"neighborhood_{lie_name}\"\n",
    "        neighborhood_data = neighborhoods_gdf.loc[idx]\n",
    "        node_data = {\n",
    "            'vertex': neighborhood_node_id, 'type': 'neighborhood', 'lie_name': lie_name,\n",
    "            **{col: float(neighborhood_data.get(col, 0.0)) for col in feature_cols if col not in ['tree_count', 'transit_count', 'accident_count']},\n",
    "            'tree_count': int(neighborhood_data.get('tree_count', 0)),\n",
    "            'transit_count': int(neighborhood_data.get('transit_count', 0)),\n",
    "            'accident_count': int(neighborhood_data.get('accident_count', 0)),\n",
    "            'building_type': None, 'road_class': None, 'class': None\n",
    "        }\n",
    "        all_nodes.append(node_data)\n",
    "\n",
    "        # Buffer and filter\n",
    "        buffer_distance_meters = 200\n",
    "        neigh_geom_proj = neighborhoods_gdf.geometry.iloc[idx]\n",
    "        neigh_buffer_proj = neigh_geom_proj.buffer(buffer_distance_meters) if neigh_geom_proj.is_valid else None\n",
    "\n",
    "        if neigh_buffer_proj:\n",
    "            relevant_buildings = buildings_gdf[buildings_gdf.geometry.within(neigh_buffer_proj)]\n",
    "            relevant_roads = roads_gdf[roads_gdf.geometry.intersects(neigh_buffer_proj)]\n",
    "            relevant_trees = trees_gdf[trees_gdf.geometry.within(neigh_buffer_proj)]\n",
    "            relevant_transit = transit_gdf[transit_gdf.geometry.within(neigh_buffer_proj)]\n",
    "        else:\n",
    "            relevant_buildings = gpd.GeoDataFrame(geometry=[])\n",
    "            relevant_roads = gpd.GeoDataFrame(geometry=[])\n",
    "            relevant_trees = gpd.GeoDataFrame(geometry=[])\n",
    "            relevant_transit = gpd.GeoDataFrame(geometry=[])\n",
    "\n",
    "        # Building nodes\n",
    "        for b_idx, building in relevant_buildings.iterrows():\n",
    "            node_id = f\"building_{b_idx}\"\n",
    "            node_data = {\n",
    "                'vertex': node_id, 'type': 'building', 'lie_name': lie_name,\n",
    "                'area_m2': float(building.get('area_m2', 0.0)), 'building_type': building.get('building', None),\n",
    "                **{col: 0.0 for col in feature_cols if col != 'area_m2'},\n",
    "                'road_class': None, 'class': None\n",
    "            }\n",
    "            all_nodes.append(node_data)\n",
    "\n",
    "        # Road nodes\n",
    "        for r_idx, road in relevant_roads.iterrows():\n",
    "            geom = road.geometry\n",
    "            if geom and not geom.is_empty and geom.geom_type in ['LineString', 'MultiLineString']:\n",
    "                start_id = f\"road_start_{r_idx}\"\n",
    "                end_id = f\"road_end_{r_idx}\"\n",
    "                node_data_start = {\n",
    "                    'vertex': start_id, 'type': 'road', 'lie_name': lie_name,\n",
    "                    'length_m': float(road.get('length_m', 0.0)), 'accident_count': int(road.get('accident_count', 0)),\n",
    "                    'road_class': road.get('class', None),\n",
    "                    **{col: 0.0 for col in feature_cols if col not in ['length_m', 'accident_count']},\n",
    "                    'building_type': None, 'class': None\n",
    "                }\n",
    "                node_data_end = node_data_start.copy()\n",
    "                node_data_end['vertex'] = end_id\n",
    "                all_nodes.extend([node_data_start, node_data_end])\n",
    "\n",
    "        # Tree nodes\n",
    "        for t_idx, tree in relevant_trees.iterrows():\n",
    "            node_id = f\"tree_{t_idx}\"\n",
    "            node_data = {\n",
    "                'vertex': node_id, 'type': 'tree', 'lie_name': lie_name,\n",
    "                **{col: 0.0 for col in feature_cols},\n",
    "                'building_type': None, 'road_class': None, 'class': tree.get('class', None)\n",
    "            }\n",
    "            all_nodes.append(node_data)\n",
    "\n",
    "        # Transit nodes\n",
    "        for tr_idx, transit in relevant_transit.iterrows():\n",
    "            node_id = f\"transit_{tr_idx}\"\n",
    "            node_data = {\n",
    "                'vertex': node_id, 'type': 'transit', 'lie_name': lie_name,\n",
    "                **{col: 0.0 for col in feature_cols},\n",
    "                'building_type': None, 'road_class': None, 'class': transit.get('class', None)\n",
    "            }\n",
    "            all_nodes.append(node_data)\n",
    "\n",
    "        # Create edges based on spatial proximity\n",
    "        if neigh_buffer_proj:\n",
    "            # Neighborhood to buildings\n",
    "            for b_idx, building in relevant_buildings.iterrows():\n",
    "                building_geom = building.geometry\n",
    "                if building_geom and building_geom.is_valid:\n",
    "                    distance = neigh_geom_proj.distance(building_geom)\n",
    "                    if distance < 100:\n",
    "                        all_edges.append({'src': neighborhood_node_id, 'dst': f\"building_{b_idx}\", 'weight': float(distance)})\n",
    "\n",
    "            # Buildings to roads\n",
    "            for b_idx, building in relevant_buildings.iterrows():\n",
    "                building_geom = building.geometry\n",
    "                if not (building_geom and building_geom.is_valid):\n",
    "                    continue\n",
    "                for r_idx, road in relevant_roads.iterrows():\n",
    "                    road_geom = road.geometry\n",
    "                    if not (road_geom and road_geom.is_valid):\n",
    "                        continue\n",
    "                    distance = building_geom.distance(road_geom)\n",
    "                    if distance < 50:\n",
    "                        all_edges.append({'src': f\"building_{b_idx}\", 'dst': f\"road_start_{r_idx}\", 'weight': float(distance)})\n",
    "                        all_edges.append({'src': f\"building_{b_idx}\", 'dst': f\"road_end_{r_idx}\", 'weight': float(distance)})\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        nodes_pd_df = pd.DataFrame(all_nodes)\n",
    "        edges_pd_df = pd.DataFrame(all_edges, columns=['src', 'dst', 'weight']) if all_edges else pd.DataFrame(columns=['src', 'dst', 'weight'])\n",
    "        for col in all_columns:\n",
    "            if col not in nodes_pd_df.columns:\n",
    "                nodes_pd_df[col] = 0.0 if col in feature_cols else None\n",
    "\n",
    "        # Save to disk\n",
    "        with open(subgraph_path, 'wb') as f:\n",
    "            pickle.dump({'nodes': nodes_pd_df, 'edges': edges_pd_df}, f)\n",
    "        logging.info(f\"Saved subgraph for: {lie_name}\")\n",
    "        return lie_name, {'nodes': nodes_pd_df, 'edges': edges_pd_df}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error building subgraph for {lie_name}: {e}\")\n",
    "        return lie_name, None\n",
    "\n",
    "def build_graph(data):\n",
    "    \"\"\"Build subgraphs for each neighborhood with accident counts using parallel processing.\"\"\"\n",
    "    logging.info(\"Stage 2: Building graph network...\")\n",
    "    subgraphs = {}\n",
    "    target_crs = 'EPSG:3826'\n",
    "\n",
    "    # Extract GeoDataFrames\n",
    "    neighborhoods_gdf = data['neighborhoods'].to_crs(target_crs)\n",
    "    buildings_gdf = data['buildings'].to_crs(target_crs)\n",
    "    roads_gdf = data['roads'].to_crs(target_crs)\n",
    "    trees_gdf = data['trees'].to_crs(target_crs)\n",
    "    transit_gdf = data['transit'].to_crs(target_crs)\n",
    "    accidents_gdf = data['accidents'].to_crs(target_crs)\n",
    "\n",
    "    # Calculate accident counts per road\n",
    "    logging.info(\"Computing accident counts per road...\")\n",
    "    road_accidents = gpd.sjoin(roads_gdf, accidents_gdf, how='left', predicate='intersects')\n",
    "    roads_gdf['accident_count'] = road_accidents.groupby(road_accidents.index).size().reindex(roads_gdf.index, fill_value=0)\n",
    "\n",
    "    feature_cols = [\n",
    "        'land_use_residential_percent', 'land_use_commercial_percent',\n",
    "        'land_use_education_percent', 'ndvi_mean', 'tree_count', 'transit_count',\n",
    "        'area_m2', 'length_m', 'total_population', 'elderly_percentage', 'accident_count'\n",
    "    ]\n",
    "    all_columns = ['vertex', 'type', 'lie_name'] + feature_cols + ['building_type', 'road_class', 'class']\n",
    "\n",
    "    os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "\n",
    "    # Prepare arguments for multiprocessing\n",
    "    args_list = [(idx, neighborhoods_gdf, buildings_gdf, roads_gdf, trees_gdf, transit_gdf, feature_cols, all_columns, SUBGRAPH_DIR) for idx in range(len(neighborhoods_gdf))]\n",
    "\n",
    "    # Use a pool of workers to build subgraphs in parallel\n",
    "    with Pool(processes=4) as pool:  # Adjust 'processes' based on your CPU cores\n",
    "        results = pool.map(build_subgraph_for_neighborhood, args_list)\n",
    "\n",
    "    # Collect results into subgraphs dictionary\n",
    "    for lie_name, subgraph_data in tqdm(results, desc=\"Collecting subgraphs\"):\n",
    "        if subgraph_data is not None:\n",
    "            # Convert to cudf in the main process\n",
    "            nodes_df = cudf.from_pandas(subgraph_data['nodes'])\n",
    "            edges_df = cudf.from_pandas(subgraph_data['edges']) if not subgraph_data['edges'].empty else cudf.DataFrame(columns=['src', 'dst', 'weight'])\n",
    "            subgraphs[lie_name] = {'nodes': nodes_df, 'edges': edges_df}\n",
    "        else:\n",
    "            logging.warning(f\"Skipping subgraph for {lie_name} due to error.\")\n",
    "\n",
    "    logging.info(f\"Finished building/loading {len(subgraphs)} subgraphs.\")\n",
    "    return subgraphs, []\n",
    "\n",
    "# Stage 3: Rule-Based Walkability Calculation\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def compute_walkability_scores(nodes_df):\n",
    "    \"\"\"Compute enhanced rule-based walkability scores for neighborhood nodes.\"\"\"\n",
    "    if not isinstance(nodes_df, pd.DataFrame):\n",
    "        nodes_df = nodes_df.to_pandas()\n",
    "\n",
    "    neighborhood_mask = nodes_df['type'] == 'neighborhood'\n",
    "    neighborhood_df = nodes_df[neighborhood_mask].copy()\n",
    "\n",
    "    if len(neighborhood_df) == 0:\n",
    "        logging.warning(\"No neighborhood nodes found.\")\n",
    "        nodes_df['walkability_rule'] = 0.0\n",
    "        return nodes_df\n",
    "\n",
    "    # Land use score\n",
    "    land_use_cols = [col for col in neighborhood_df.columns if 'land_use' in col.lower()]\n",
    "    land_use_weights = {\n",
    "        'land_use_residential_percent': 0.25,\n",
    "        'land_use_commercial_percent': 0.20,\n",
    "        'land_use_education_percent': 0.15\n",
    "    }\n",
    "    land_use_score = sum(\n",
    "        (neighborhood_df[col].fillna(0.0) * land_use_weights.get(col, 0.1)) / 100\n",
    "        for col in land_use_cols\n",
    "    )\n",
    "\n",
    "    # Normalized feature scores\n",
    "    ndvi_score = ((neighborhood_df['ndvi_mean'] - neighborhood_df['ndvi_mean'].min()) /\n",
    "                  (neighborhood_df['ndvi_mean'].max() - neighborhood_df['ndvi_mean'].min() + 1e-6)) * 0.3\n",
    "    tree_score = ((neighborhood_df['tree_count'] - neighborhood_df['tree_count'].min()) /\n",
    "                  (neighborhood_df['tree_count'].max() - neighborhood_df['tree_count'].min() + 1e-6)) * 0.2\n",
    "    transit_score = ((neighborhood_df['transit_count'] - neighborhood_df['transit_count'].min()) /\n",
    "                     (neighborhood_df['transit_count'].max() - neighborhood_df['transit_count'].min() + 1e-6)) * 0.2\n",
    "\n",
    "    # Penalty factors\n",
    "    elderly_factor = (neighborhood_df['elderly_percentage'].fillna(0.0) / 100) * 0.1\n",
    "    accident_factor = ((neighborhood_df['accident_count'] - neighborhood_df['accident_count'].min()) /\n",
    "                       (neighborhood_df['accident_count'].max() - neighborhood_df['accident_count'].min() + 1e-6)) * 0.1\n",
    "\n",
    "    # Amenity score (using updated columns)\n",
    "    amenity_cols = ['cityopenarea_count', 'education_count', 'commercial_count']\n",
    "    amenity_score = sum(\n",
    "        (neighborhood_df[col] / (neighborhood_df[col].max() + 1e-6)) * 0.05\n",
    "        for col in amenity_cols if col in neighborhood_df.columns and neighborhood_df[col].max() > 0\n",
    "    )\n",
    "\n",
    "    # Road density score\n",
    "    road_density_score = ((neighborhood_df['road_density'] - neighborhood_df['road_density'].min()) /\n",
    "                          (neighborhood_df['road_density'].max() - neighborhood_df['road_density'].min() + 1e-6)) * 0.1\n",
    "\n",
    "    # Final walkability score\n",
    "    walkability = (land_use_score + ndvi_score + tree_score + transit_score +\n",
    "                   amenity_score + road_density_score - elderly_factor - accident_factor).clip(lower=0.0, upper=1.0)\n",
    "    nodes_df['walkability_rule'] = 0.0\n",
    "    nodes_df.loc[neighborhood_mask, 'walkability_rule'] = walkability\n",
    "\n",
    "    return nodes_df\n",
    "\n",
    "def calculate_walkability(subgraphs, neighborhoods_gdf):\n",
    "    \"\"\"Calculate walkability scores for all subgraphs and prepare for visualization.\"\"\"\n",
    "    logging.info(\"Stage 3: Calculating rule-based walkability scores...\")\n",
    "    walkability_scores = {}\n",
    "\n",
    "    for lie_name, subgraph_data in tqdm(subgraphs.items(), desc=\"Calculating walkability\"):\n",
    "        nodes_df = subgraph_data['nodes']\n",
    "        nodes_df = compute_walkability_scores(nodes_df)\n",
    "        subgraph_data['nodes'] = nodes_df\n",
    "\n",
    "        neighborhood_node = nodes_df[nodes_df['type'] == 'neighborhood']\n",
    "        if not neighborhood_node.empty:\n",
    "            walkability_scores[lie_name] = neighborhood_node['walkability_rule'].iloc[0]\n",
    "\n",
    "    neighborhoods_gdf['walkability_rule'] = neighborhoods_gdf['LIE_NAME'].map(walkability_scores).fillna(0.0)\n",
    "    neighborhoods_gdf.to_file(\"walkability_scores.geojson\", driver=\"GeoJSON\")\n",
    "    logging.info(\"Walkability scores saved to walkability_scores.geojson\")\n",
    "    return subgraphs\n",
    "\n",
    "# Stage 4: GNN Model with GAT and Validation\n",
    "class GATWalkability(torch.nn.Module):\n",
    "    \"\"\"Graph Attention Network (GAT) model for walkability prediction.\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GATWalkability, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=4, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_channels * 4, out_channels, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def prepare_gnn_data(subgraphs, train_indices, val_indices):\n",
    "    \"\"\"Prepare data for GNN training.\"\"\"\n",
    "    feature_cols = [\n",
    "        'land_use_residential_percent', 'land_use_commercial_percent', 'land_use_education_percent',\n",
    "        'ndvi_mean', 'tree_count', 'transit_count', 'area_m2', 'length_m', 'total_population',\n",
    "        'elderly_percentage', 'accident_count'\n",
    "    ]\n",
    "\n",
    "    train_nodes = cudf.concat([subgraphs[lie_name]['nodes'] for lie_name in train_indices])\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col not in train_nodes.columns:\n",
    "            train_nodes[col] = 0.0\n",
    "\n",
    "    min_values = train_nodes[feature_cols].min()\n",
    "    max_values = train_nodes[feature_cols].max()\n",
    "\n",
    "    data_list = []\n",
    "    for lie_name in subgraphs.keys():\n",
    "        nodes_df = subgraphs[lie_name]['nodes']\n",
    "        edges_df = subgraphs[lie_name]['edges']\n",
    "\n",
    "        if edges_df is None or not isinstance(edges_df, cudf.DataFrame):\n",
    "            edges_df = cudf.DataFrame(columns=['src', 'dst', 'weight'])\n",
    "\n",
    "        vertex_list = nodes_df['vertex'].to_arrow().to_pylist()\n",
    "        node_mapping = {vertex: idx for idx, vertex in enumerate(vertex_list)}\n",
    "\n",
    "        for col in feature_cols:\n",
    "            if col not in nodes_df.columns:\n",
    "                nodes_df[col] = 0.0\n",
    "\n",
    "        scaled_nodes_df = nodes_df[feature_cols].copy()\n",
    "        for col in feature_cols:\n",
    "            if max_values[col] > min_values[col]:\n",
    "                scaled_nodes_df[col] = (scaled_nodes_df[col] - min_values[col]) / (max_values[col] - min_values[col])\n",
    "            else:\n",
    "                scaled_nodes_df[col] = 0\n",
    "\n",
    "        x = torch.tensor(scaled_nodes_df.to_pandas().values, dtype=torch.float)\n",
    "\n",
    "        if len(edges_df) > 0:\n",
    "            src_list = edges_df['src'].to_arrow().to_pylist()\n",
    "            dst_list = edges_df['dst'].to_arrow().to_pylist()\n",
    "            src_idx = [node_mapping[src] for src in src_list]\n",
    "            dst_idx = [node_mapping[dst] for dst in dst_list]\n",
    "            edge_index = torch.tensor([src_idx, dst_idx], dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.tensor([[], []], dtype=torch.long)\n",
    "\n",
    "        y = torch.tensor(nodes_df['walkability_rule'].to_pandas().values, dtype=torch.float)\n",
    "        data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def train_gnn_model(data_list):\n",
    "    \"\"\"Train the GNN model with validation, early stopping, and LR scheduling.\"\"\"\n",
    "    logging.info(\"Stage 4: Training GNN model...\")\n",
    "    model = GATWalkability(in_channels=11, hidden_channels=64, out_channels=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "    indices = list(range(len(data_list)))\n",
    "    shuffle(indices)\n",
    "    train_data = [data_list[i] for i in indices[:int(0.8 * len(data_list))]]\n",
    "    val_data = [data_list[i] for i in indices[int(0.8 * len(data_list)):]]\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_data)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_data:\n",
    "                out = model(data.x, data.edge_index)\n",
    "                val_loss += criterion(out, data.y.view(-1, 1)).item()\n",
    "        val_loss /= len(val_data)\n",
    "\n",
    "        logging.info(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "            logging.info(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= patience:\n",
    "            logging.info(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth')))\n",
    "    logging.info(f\"Training completed. Best validation loss: {best_val_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "def predict_walkability(subgraphs, model):\n",
    "    \"\"\"Predict walkability scores using the trained GNN model.\"\"\"\n",
    "    for lie_name, subgraph_data in subgraphs.items():\n",
    "        nodes_df = subgraph_data['nodes'].to_pandas()\n",
    "        data = prepare_gnn_data({lie_name: subgraph_data}, [lie_name], [])[0]\n",
    "        with torch.no_grad():\n",
    "            pred = model(data.x, data.edge_index)\n",
    "        nodes_df['walkability_gnn'] = pred.numpy().flatten()\n",
    "        subgraph_data['nodes'] = cudf.from_pandas(nodes_df)\n",
    "    return subgraphs\n",
    "\n",
    "# Main Execution Flow\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    SUBGRAPH_DIR = \"subgraphs\"\n",
    "    os.makedirs(SUBGRAPH_DIR, exist_ok=True)\n",
    "    logging.info(f\"Ensured subgraph directory exists: {SUBGRAPH_DIR}\")\n",
    "\n",
    "    # Load and prepare data\n",
    "    data = load_and_prepare_data()\n",
    "\n",
    "    # Build graph (use your existing function)\n",
    "    subgraphs, _ = build_graph(data)\n",
    "\n",
    "    # Calculate walkability\n",
    "    subgraphs = calculate_walkability(subgraphs, data['neighborhoods'])\n",
    "\n",
    "    logging.info(\"Processing complete. Check walkability_scores.geojson for results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import React, { useState, useEffect } from 'react';\n",
    "import KeplerGl from 'kepler.gl';\n",
    "\n",
    "const MapWithWalkability = () => {\n",
    "  const [mapData, setMapData] = useState(null);\n",
    "\n",
    "  useEffect(() => {\n",
    "    fetch('/walkability_scores.geojson')\n",
    "      .then(response => response.json())\n",
    "      .then(data => {\n",
    "        setMapData({\n",
    "          data: data,\n",
    "          config: {\n",
    "            version: 'v1',\n",
    "            config: {\n",
    "              visState: {\n",
    "                layers: [\n",
    "                  {\n",
    "                    type: 'geojson',\n",
    "                    config: {\n",
    "                      dataId: 'walkability_data',\n",
    "                      label: 'Walkability Scores',\n",
    "                      columns: { geojson: 'geometry' },\n",
    "                      isVisible: true,\n",
    "                      visConfig: {\n",
    "                        opacity: 0.8,\n",
    "                        colorRange: {\n",
    "                          name: 'Global Warming',\n",
    "                          type: 'sequential',\n",
    "                          category: 'Uber',\n",
    "                          colors: ['#5A1846', '#900C3F', '#C70039', '#E3611C', '#F1920E', '#FFC300']\n",
    "                        },\n",
    "                        filled: true,\n",
    "                        colorField: {\n",
    "                          name: 'walkability_rule',\n",
    "                          type: 'real'\n",
    "                        },\n",
    "                        colorScale: 'quantile'\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        });\n",
    "      })\n",
    "      .catch(error => console.error('Error loading walkability scores:', error));\n",
    "  }, []);\n",
    "\n",
    "  return (\n",
    "    <div>\n",
    "      <KeplerGl\n",
    "        id=\"map\"\n",
    "        mapboxApiAccessToken=\"YOUR_MAPBOX_TOKEN\"  // Replace with your actual Mapbox token\n",
    "        width={800}\n",
    "        height={600}\n",
    "        mapData={mapData ? mapData.data : null}\n",
    "        config={mapData ? mapData.config : {}}\n",
    "      />\n",
    "    </div>\n",
    "  );\n",
    "};\n",
    "\n",
    "export default MapWithWalkability;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
