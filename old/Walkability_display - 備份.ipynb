{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成功！預留"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kepler.gl 延伸範圍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import os\n",
    "from shapely.geometry import Point, LineString\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyproj\n",
    "from keplergl import KeplerGl\n",
    "from shapely.ops import unary_union, linemerge\n",
    "\n",
    "# Define checkpoint directory\n",
    "CHECKPOINT_DIR = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\checkpoints\"\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "# Mapbox Access Token (Replace with your valid token)\n",
    "MAPBOX_ACCESS_TOKEN = \"your_valid_mapbox_access_token_here\"  # Replace with your token\n",
    "\n",
    "# Helper function to convert TWD97 (EPSG:3826) to WGS84 (EPSG:4326)\n",
    "def twd97_to_wgs84(x, y):\n",
    "    transformer = pyproj.Transformer.from_crs(\"EPSG:3826\", \"EPSG:4326\", always_xy=True)\n",
    "    lon, lat = transformer.transform(x, y)\n",
    "    return lat, lon\n",
    "\n",
    "# Helper function to convert a polyline into a series of points\n",
    "def polyline_to_points(linestring, spacing=7):\n",
    "    \"\"\"\n",
    "    Convert a LineString to a list of Points spaced at a given interval (in meters).\n",
    "    \n",
    "    Parameters:\n",
    "    - linestring: shapely LineString object\n",
    "    - spacing: distance between points in meters (default: 7m, based on Taiwan's minimum tree interval)\n",
    "    \n",
    "    Returns:\n",
    "    - List of shapely Point objects\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    # Ensure the linestring is a single LineString (merge if MultiLineString)\n",
    "    if linestring.geom_type == 'MultiLineString':\n",
    "        linestring = linemerge(linestring)\n",
    "    if linestring.geom_type != 'LineString':\n",
    "        return points  # Return empty list if not a valid LineString\n",
    "\n",
    "    total_length = linestring.length\n",
    "    if total_length <= 0:\n",
    "        return points\n",
    "\n",
    "    # Generate points along the line at regular intervals\n",
    "    distance = 0\n",
    "    while distance <= total_length:\n",
    "        point = linestring.interpolate(distance)\n",
    "        points.append(point)\n",
    "        distance += spacing\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data with Checkpoints and Progress Bar\n",
    "def load_data():\n",
    "    print(\"Checkpoint 1: Loading data for 和安里 and all neighborhoods within the covering radius...\")\n",
    "    landuse_ndvi_path = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\neighborhoods_with_ndvi_numerical.geojson\"\n",
    "    osm_buildings_path = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\Taipei_Buildings_fulldata.geojson\"\n",
    "    osm_roads_path = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\taipei_segments_cleaned_verified.geoparquet\"\n",
    "    osm_trees_path = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\taipei_land.geoparquet\"\n",
    "    osm_transit_path = r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\taipei_infrastructure.geoparquet\"\n",
    "\n",
    "    for path in [landuse_ndvi_path, osm_buildings_path, osm_roads_path, osm_trees_path, osm_transit_path]:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    # Try loading with utf-8-sig to handle BOM, fall back to ignoring errors if needed\n",
    "    try:\n",
    "        with tqdm(total=5, desc=\"Loading files\") as pbar:\n",
    "            neighborhoods = gpd.read_file(landuse_ndvi_path, encoding='utf-8-sig')\n",
    "            print(\"Columns in neighborhoods after loading:\", neighborhoods.columns.tolist())\n",
    "            pbar.update(1)\n",
    "            buildings = gpd.read_file(osm_buildings_path, encoding='utf-8-sig')\n",
    "            pbar.update(1)\n",
    "            roads = gpd.read_parquet(osm_roads_path)\n",
    "            pbar.update(1)\n",
    "            # Load tree data and filter for subtype=\"tree\"\n",
    "            trees = gpd.read_parquet(osm_trees_path)\n",
    "            trees = trees[trees['subtype'] == 'tree']\n",
    "            pbar.update(1)\n",
    "            # Load transit data and filter for class=\"stop_position\" and \"bus_stop\"\n",
    "            transit = gpd.read_parquet(osm_transit_path)\n",
    "            transit = transit[transit['class'].isin(['stop_position', 'bus_stop'])]\n",
    "            pbar.update(1)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UTF-8-SIG decoding failed: {e}. Attempting with errors='ignore'...\")\n",
    "        try:\n",
    "            with tqdm(total=5, desc=\"Loading files (fallback)\") as pbar:\n",
    "                neighborhoods = gpd.read_file(landuse_ndvi_path, encoding='utf-8-sig', errors='ignore')\n",
    "                print(\"Columns in neighborhoods after loading (fallback):\", neighborhoods.columns.tolist())\n",
    "                pbar.update(1)\n",
    "                buildings = gpd.read_file(osm_buildings_path, encoding='utf-8-sig', errors='ignore')\n",
    "                pbar.update(1)\n",
    "                roads = gpd.read_parquet(osm_roads_path)\n",
    "                pbar.update(1)\n",
    "                trees = gpd.read_parquet(osm_trees_path)\n",
    "                trees = trees[trees['subtype'] == 'tree']\n",
    "                pbar.update(1)\n",
    "                transit = gpd.read_parquet(osm_transit_path)\n",
    "                transit = transit[transit['class'].isin(['stop_position', 'bus_stop'])]\n",
    "                pbar.update(1)\n",
    "            print(\"Loaded with errors ignored. Some data may be incomplete.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Final loading attempt failed: {e2}. Please check file encoding or integrity.\")\n",
    "            raise\n",
    "\n",
    "    # Ensure all data is in EPSG:3826 (TWD97)\n",
    "    neighborhoods = neighborhoods.to_crs('EPSG:3826')\n",
    "    buildings = buildings.to_crs('EPSG:3826')\n",
    "    roads = roads.to_crs('EPSG:3826')\n",
    "    trees = trees.to_crs('EPSG:3826')\n",
    "    transit = transit.to_crs('EPSG:3826')\n",
    "\n",
    "    # Filter invalid geometries and calculate areas for buildings\n",
    "    neighborhoods = neighborhoods[neighborhoods.geometry.is_valid]\n",
    "    buildings = buildings[buildings.geometry.is_valid].copy()\n",
    "    roads = roads[roads.geometry.is_valid]\n",
    "    trees = trees[trees.geometry.is_valid]\n",
    "    transit = transit[transit.geometry.is_valid]\n",
    "\n",
    "    # Calculate building areas with 1 decimal place precision\n",
    "    buildings['area_m2'] = buildings.geometry.area.round(1)\n",
    "\n",
    "    # Clean the 'building' column: only replace 'yes' and NaN with 'unknown'\n",
    "    buildings['building'] = buildings['building'].fillna('unknown').replace('yes', 'unknown')\n",
    "\n",
    "    # Separate tree points and polylines\n",
    "    tree_points = trees[trees.geometry.geom_type == 'Point']\n",
    "    tree_polylines = trees[trees.geometry.geom_type.isin(['LineString', 'MultiLineString'])]\n",
    "\n",
    "    # Convert polylines to points (approximate trees every 7 meters)\n",
    "    converted_points = []\n",
    "    for _, row in tree_polylines.iterrows():\n",
    "        geom = row.geometry\n",
    "        points = polyline_to_points(geom, spacing=7)  # One tree every 7 meters based on Taiwan's minimum interval\n",
    "        for point in points:\n",
    "            converted_points.append({'geometry': point})\n",
    "\n",
    "    # Create a GeoDataFrame for converted points\n",
    "    if converted_points:\n",
    "        converted_points_gdf = gpd.GeoDataFrame(converted_points, crs='EPSG:3826')\n",
    "        # Combine with original tree points\n",
    "        all_trees = pd.concat([tree_points[['geometry']], converted_points_gdf], ignore_index=True)\n",
    "        all_trees = gpd.GeoDataFrame(all_trees, crs='EPSG:3826')\n",
    "    else:\n",
    "        all_trees = tree_points[['geometry']].copy()\n",
    "        all_trees = gpd.GeoDataFrame(all_trees, crs='EPSG:3826')\n",
    "\n",
    "    # Debug: Print distribution of building types, total neighborhoods, tree counts, and transit counts\n",
    "    print(\"Building type distribution after cleaning:\")\n",
    "    print(buildings['building'].value_counts())\n",
    "    print(f\"Warren: Total number of neighborhoods in dataset: {len(neighborhoods)}\")\n",
    "    print(f\"Total number of tree points loaded: {len(tree_points)}\")\n",
    "    print(f\"Total number of tree polylines loaded: {len(tree_polylines)}\")\n",
    "    print(f\"Total number of trees after converting polylines: {len(all_trees)}\")\n",
    "    print(f\"Total number of transit points loaded: {len(transit)}\")\n",
    "\n",
    "    # Find 和安里 and select all neighborhoods within a covering radius\n",
    "    central_neigh = neighborhoods[neighborhoods['LIE_NAME'] == '和安里']\n",
    "    if central_neigh.empty:\n",
    "        raise ValueError(\"Neighborhood '和安里' not found in the data.\")\n",
    "    \n",
    "    central_neigh = central_neigh.iloc[0]\n",
    "    central_centroid = central_neigh['geometry'].centroid\n",
    "    \n",
    "    # Calculate distances from 和安里's centroid to all neighborhoods' centroids (including 和安里)\n",
    "    neighborhoods['distance_to_central'] = neighborhoods.geometry.centroid.apply(lambda x: x.distance(central_centroid))\n",
    "    # Set 和安里's distance to 0.0 explicitly\n",
    "    neighborhoods.loc[neighborhoods['LIE_NAME'] == '和安里', 'distance_to_central'] = 0.0\n",
    "    \n",
    "    # Define the covering radius (in meters, since TWD97 is in meters)\n",
    "    covering_radius = 1000  # Increased from 500m to include more neighborhoods\n",
    "    \n",
    "    # Select all neighborhoods within the covering radius, sorted by distance\n",
    "    within_radius = neighborhoods[neighborhoods['distance_to_central'] <= covering_radius]\n",
    "    if len(within_radius) == 0:\n",
    "        raise ValueError(f\"No neighborhoods found within {covering_radius}m radius of 和安里.\")\n",
    "    print(f\"Found {len(within_radius)} neighborhoods within {covering_radius}m radius.\")\n",
    "    \n",
    "    # Sort by distance and take all within the radius\n",
    "    selected_neighborhoods = within_radius.sort_values(by='distance_to_central').reset_index(drop=True)\n",
    "\n",
    "    # Warn if the dataset might be too large\n",
    "    if len(selected_neighborhoods) > 100:\n",
    "        print(f\"Warning: Large number of neighborhoods ({len(selected_neighborhoods)}) selected. This may impact performance during graph construction and map rendering.\")\n",
    "\n",
    "    # Debug: Print selected neighborhood names and their distances\n",
    "    print(\"Selected neighborhoods and distances from 和安里 (in meters):\")\n",
    "    for idx, row in selected_neighborhoods.iterrows():\n",
    "        distance = row['distance_to_central']\n",
    "        print(f\"- {row['LIE_NAME']}: {distance:.1f}m\")\n",
    "\n",
    "    # Integrate tree data: Count trees per neighborhood\n",
    "    print(\"Integrating tree data with neighborhoods...\")\n",
    "    selected_neighborhoods['tree_count'] = 0\n",
    "\n",
    "    for idx, neighborhood in selected_neighborhoods.iterrows():\n",
    "        # Filter trees within the neighborhood boundary\n",
    "        neighborhood_geom = neighborhood.geometry\n",
    "        trees_in_neighborhood = all_trees[all_trees.intersects(neighborhood_geom)]\n",
    "        selected_neighborhoods.at[idx, 'tree_count'] = len(trees_in_neighborhood)\n",
    "\n",
    "    # Integrate transit data: Count transit points per neighborhood\n",
    "    print(\"Integrating transit data with neighborhoods...\")\n",
    "    selected_neighborhoods['transit_count'] = 0\n",
    "\n",
    "    for idx, neighborhood in selected_neighborhoods.iterrows():\n",
    "        # Filter transit points within the neighborhood boundary\n",
    "        neighborhood_geom = neighborhood.geometry\n",
    "        transit_in_neighborhood = transit[transit.intersects(neighborhood_geom)]\n",
    "        selected_neighborhoods.at[idx, 'transit_count'] = len(transit_in_neighborhood)\n",
    "\n",
    "    # Debug: Print tree and transit counts per neighborhood\n",
    "    print(\"Tree and transit counts per neighborhood:\")\n",
    "    for idx, row in selected_neighborhoods.iterrows():\n",
    "        print(f\"- {row['LIE_NAME']}: {row['tree_count']} trees, {row['transit_count']} transit points\")\n",
    "\n",
    "    # Combine boundaries of selected neighborhoods\n",
    "    city_center_boundary = unary_union(selected_neighborhoods['geometry'])\n",
    "    buffer_distance = 50\n",
    "    buffered_geom = city_center_boundary.buffer(buffer_distance)\n",
    "\n",
    "    # Filter buildings, roads, trees, and transit\n",
    "    filtered_buildings = buildings[buildings.intersects(buffered_geom)]\n",
    "    filtered_roads = roads[roads.intersects(buffered_geom)].copy()\n",
    "    filtered_trees = all_trees[all_trees.intersects(buffered_geom)]\n",
    "    filtered_transit = transit[transit.intersects(buffered_geom)]\n",
    "\n",
    "    # Calculate road segment lengths\n",
    "    filtered_roads['length_m'] = filtered_roads.geometry.length.round(1)\n",
    "    # Debug: Print road length distribution\n",
    "    print(\"Road length distribution (in meters):\")\n",
    "    print(filtered_roads['length_m'].describe())\n",
    "    \n",
    "    road_points = []\n",
    "    for idx, row in tqdm(filtered_roads.iterrows(), total=len(filtered_roads), desc=\"Extracting road endpoints\"):\n",
    "        geom = row['geometry']\n",
    "        if geom.geom_type == 'LineString':\n",
    "            start_point = Point(geom.coords[0])\n",
    "            end_point = Point(geom.coords[-1])\n",
    "            road_points.extend([(f\"road_start_{idx}\", start_point), (f\"road_end_{idx}\", end_point)])\n",
    "        elif geom.geom_type == 'MultiLineString':\n",
    "            for i, line in enumerate(geom.geoms):\n",
    "                start_point = Point(line.coords[0])\n",
    "                end_point = Point(line.coords[-1])\n",
    "                road_points.extend([(f\"road_start_{idx}_{i}\", start_point), (f\"road_end_{idx}_{i}\", end_point)])\n",
    "\n",
    "    # Ensure filtered data has valid geometries\n",
    "    filtered_buildings = filtered_buildings[filtered_buildings.geometry.is_valid]\n",
    "    filtered_roads = filtered_roads[filtered_roads.geometry.is_valid]\n",
    "    filtered_trees = filtered_trees[filtered_trees.geometry.is_valid]\n",
    "    filtered_transit = filtered_transit[filtered_transit.geometry.is_valid]\n",
    "\n",
    "    # Save checkpoints\n",
    "    selected_neighborhoods.to_file(os.path.join(CHECKPOINT_DIR, \"selected_neighborhoods_filtered.geojson\"), driver='GeoJSON')\n",
    "    filtered_buildings.to_file(os.path.join(CHECKPOINT_DIR, \"selected_buildings_filtered.geojson\"), driver='GeoJSON')\n",
    "    filtered_roads.to_file(os.path.join(CHECKPOINT_DIR, \"selected_roads_filtered.geojson\"), driver='GeoJSON')\n",
    "    filtered_trees.to_file(os.path.join(CHECKPOINT_DIR, \"selected_trees_filtered.geojson\"), driver='GeoJSON')\n",
    "    filtered_transit.to_file(os.path.join(CHECKPOINT_DIR, \"selected_transit_filtered.geojson\"), driver='GeoJSON')\n",
    "\n",
    "    print(f\"Data loaded and filtered for 和安里 and all neighborhoods within {covering_radius}m radius. Neighborhoods: {len(selected_neighborhoods)}, Buildings: {len(filtered_buildings)}, Roads: {len(filtered_roads)}, Trees: {len(filtered_trees)}, Transit Points: {len(filtered_transit)}\")\n",
    "    return selected_neighborhoods, filtered_buildings, filtered_roads, road_points, filtered_trees, filtered_transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build Graph Network with Checkpoints\n",
    "def build_graph(neighborhoods, buildings, roads, road_points, trees, transit):\n",
    "    print(\"Checkpoint 2: Building graph network for selected neighborhoods...\")\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add Neighborhood Nodes (include tree data, transit data, and NDVI)\n",
    "    print(\"Adding neighborhood nodes...\")\n",
    "    for idx, row in tqdm(neighborhoods.iterrows(), total=len(neighborhoods), desc=\"Adding neighborhoods\"):\n",
    "        node_id = f\"neighborhood_{row['LIE_NAME']}\"\n",
    "        G.add_node(node_id,\n",
    "                   type='neighborhood',\n",
    "                   lie_name=row['LIE_NAME'],\n",
    "                   sect_name=row['SECT_NAME'],\n",
    "                   population=row['2024population'],\n",
    "                   land_use_residential_percent=row['land_use_residential_percent'],\n",
    "                   land_use_commercial_percent=row['land_use_commercial_percent'],\n",
    "                   land_use_education_percent=row['land_use_education_percent'],\n",
    "                   ndvi_mean=row['ndvi_mean'],\n",
    "                   ndvi_median=row['ndvi_median'],\n",
    "                   tree_count=row['tree_count'],\n",
    "                   transit_count=row['transit_count'],\n",
    "                   geometry=row['geometry'])\n",
    "\n",
    "    # Add Building Nodes\n",
    "    print(\"Adding building nodes...\")\n",
    "    for idx, row in tqdm(buildings.iterrows(), total=len(buildings), desc=\"Adding buildings\"):\n",
    "        node_id = f\"building_{idx}\"\n",
    "        building_type = row['building'] if pd.notna(row['building']) else 'unknown'\n",
    "        area_m2 = row['area_m2'] if pd.notna(row['area_m2']) else 0.0\n",
    "        age = row['屋齡'] if pd.notna(row['屋齡']) else '<NA>'\n",
    "        height = row['建物高度'] if pd.notna(row['建物高度']) else '<NA>'\n",
    "        floors = row['地上層數'] if pd.notna(row['地上層數']) else '<NA>'\n",
    "        structure_type = row['構造種類'] if pd.notna(row['構造種類']) else 'Unknown'\n",
    "        usage_zone = row['使用分區'] if pd.notna(row['使用分區']) else 'Unknown'\n",
    "        G.add_node(node_id,\n",
    "                   type='building',\n",
    "                   building_type=building_type,\n",
    "                   area_m2=area_m2,\n",
    "                   age=age,\n",
    "                   height=height,\n",
    "                   floors=floors,\n",
    "                   structure_type=structure_type,\n",
    "                   usage_zone=usage_zone,\n",
    "                   geometry=row['geometry'])\n",
    "\n",
    "    # Add Road Nodes\n",
    "    print(\"Adding road nodes...\")\n",
    "    class_column = next((col for col in roads.columns if col.lower() in ['class', 'road_class', 'highway']), None)\n",
    "    if class_column is None:\n",
    "        print(f\"Warning: No column resembling 'class', 'road_class', or 'highway' found in roads data. Available columns: {roads.columns.tolist()}\")\n",
    "        class_column = 'unknown'\n",
    "    else:\n",
    "        print(f\"Using column '{class_column}' for road classification.\")\n",
    "\n",
    "    for node_id, geom in tqdm(road_points, total=len(road_points), desc=\"Adding road points\"):\n",
    "        road_idx = int(node_id.split('_')[2])\n",
    "        road_class = roads.loc[road_idx, class_column] if pd.notna(roads.loc[road_idx, class_column]) else 'unknown'\n",
    "        length_m = roads.loc[road_idx, 'length_m'] if pd.notna(roads.loc[road_idx, 'length_m']) else 0.0\n",
    "        G.add_node(node_id, type='road', road_class=road_class, length_m=length_m, geometry=geom)\n",
    "\n",
    "    # Add Tree Nodes\n",
    "    print(\"Adding tree nodes...\")\n",
    "    for idx, row in tqdm(trees.iterrows(), total=len(trees), desc=\"Adding trees\"):\n",
    "        node_id = f\"tree_{idx}\"\n",
    "        G.add_node(node_id, type='tree', geometry=row['geometry'])\n",
    "\n",
    "    # Add Transit Nodes\n",
    "    print(\"Adding transit nodes...\")\n",
    "    for idx, row in tqdm(transit.iterrows(), total=len(transit), desc=\"Adding transit points\"):\n",
    "        node_id = f\"transit_{idx}\"\n",
    "        G.add_node(node_id, type='transit', **{'class': row['class'], 'geometry': row['geometry']})\n",
    "\n",
    "    # Add Edges with optimized buffer distance\n",
    "    buffer_distance = 200  # Reduced from 500 to improve performance\n",
    "    print(\"Adding edges...\")\n",
    "    total_edges = (len([n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']) * \n",
    "                   len([n for n, d in G.nodes(data=True) if d['type'] == 'building'])) + \\\n",
    "                  (len([n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']) * \n",
    "                   len([n for n, d in G.nodes(data=True) if d['type'] == 'road'])) + \\\n",
    "                  (len([n for n, d in G.nodes(data=True) if d['type'] == 'building']) * \n",
    "                   len([n for n, d in G.nodes(data=True) if d['type'] == 'road'])) + \\\n",
    "                  (len([n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']) * \n",
    "                   len([n for n, d in G.nodes(data=True) if d['type'] == 'tree'])) + \\\n",
    "                  (len([n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']) * \n",
    "                   len([n for n, d in G.nodes(data=True) if d['type'] == 'transit'])) + \\\n",
    "                  max(0, len(road_points) * (len(road_points) - 1) // 2)\n",
    "    with tqdm(total=total_edges, desc=\"Adding edges\") as pbar:\n",
    "        # Neighborhood to Building edges\n",
    "        for neighborhood_node in [n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']:\n",
    "            neigh_geom = G.nodes[neighborhood_node]['geometry']\n",
    "            neigh_buffer = neigh_geom.buffer(buffer_distance)\n",
    "            for building_node in [n for n, d in G.nodes(data=True) if d['type'] == 'building']:\n",
    "                build_geom = G.nodes[building_node]['geometry']\n",
    "                if neigh_buffer.intersects(build_geom):\n",
    "                    distance = neigh_geom.distance(build_geom)\n",
    "                    G.add_edge(neighborhood_node, building_node, weight=distance, type='walk')\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Neighborhood to Road edges\n",
    "        for neighborhood_node in [n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']:\n",
    "            neigh_geom = G.nodes[neighborhood_node]['geometry']\n",
    "            neigh_buffer = neigh_geom.buffer(buffer_distance)\n",
    "            for road_node in [n for n, d in G.nodes(data=True) if d['type'] == 'road']:\n",
    "                road_geom = G.nodes[road_node]['geometry']\n",
    "                if isinstance(road_geom, Point) and neigh_buffer.intersects(road_geom):\n",
    "                    distance = neigh_geom.distance(road_geom)\n",
    "                    G.add_edge(neighborhood_node, road_node, weight=distance, type='walk')\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Building to Road edges\n",
    "        for building_node in [n for n, d in G.nodes(data=True) if d['type'] == 'building']:\n",
    "            build_geom = G.nodes[building_node]['geometry']\n",
    "            build_buffer = build_geom.buffer(50)  # Reduced from 100 to improve performance\n",
    "            for road_node in [n for n, d in G.nodes(data=True) if d['type'] == 'road']:\n",
    "                road_geom = G.nodes[road_node]['geometry']\n",
    "                if isinstance(road_geom, Point) and build_buffer.intersects(road_geom):\n",
    "                    distance = build_geom.distance(road_geom)\n",
    "                    G.add_edge(building_node, road_node, weight=distance, type='walk')\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Neighborhood to Tree edges\n",
    "        for neighborhood_node in [n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']:\n",
    "            neigh_geom = G.nodes[neighborhood_node]['geometry']\n",
    "            neigh_buffer = neigh_geom.buffer(buffer_distance)\n",
    "            for tree_node in [n for n, d in G.nodes(data=True) if d['type'] == 'tree']:\n",
    "                tree_geom = G.nodes[tree_node]['geometry']\n",
    "                if neigh_buffer.intersects(tree_geom):\n",
    "                    distance = neigh_geom.distance(tree_geom)\n",
    "                    G.add_edge(neighborhood_node, tree_node, weight=distance, type='natural')\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Neighborhood to Transit edges\n",
    "        for neighborhood_node in [n for n, d in G.nodes(data=True) if d['type'] == 'neighborhood']:\n",
    "            neigh_geom = G.nodes[neighborhood_node]['geometry']\n",
    "            neigh_buffer = neigh_geom.buffer(buffer_distance)\n",
    "            for transit_node in [n for n, d in G.nodes(data=True) if d['type'] == 'transit']:\n",
    "                transit_geom = G.nodes[transit_node]['geometry']\n",
    "                if neigh_buffer.intersects(transit_geom):\n",
    "                    distance = neigh_geom.distance(transit_geom)\n",
    "                    G.add_edge(neighborhood_node, transit_node, weight=distance, type='transit')\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Road to Road edges\n",
    "        if road_points:\n",
    "            road_class_weights = {\n",
    "                'footway': 0.5, 'pedestrian': 0.5, 'cycleway': 0.6, 'steps': 0.6, 'living_street': 0.6,\n",
    "                'path': 0.7, 'track': 0.7, 'residential': 0.8, 'service': 1.0, 'unclassified': 1.2,\n",
    "                'tertiary': 1.5, 'secondary': 2.0, 'primary': 2.5, 'highway': 3.5, 'motorway': 2.5,\n",
    "                'trunk': 2.5, 'unknown': 1.0\n",
    "            }\n",
    "            print(\"Adding road-to-road edges...\")\n",
    "            tolerance = 10\n",
    "            for i, (node1_id, geom1) in enumerate(road_points):\n",
    "                for j, (node2_id, geom2) in enumerate(road_points[i+1:], start=i+1):\n",
    "                    if geom1.distance(geom2) <= tolerance:\n",
    "                        road1_idx = int(node1_id.split('_')[2])\n",
    "                        road2_idx = int(node2_id.split('_')[2])\n",
    "                        class1 = roads.loc[road1_idx, class_column] if pd.notna(roads.loc[road1_idx, class_column]) else 'unknown'\n",
    "                        class2 = roads.loc[road2_idx, class_column] if pd.notna(roads.loc[road2_idx, class_column]) else 'unknown'\n",
    "                        weight1 = road_class_weights.get(class1, road_class_weights['unknown'])\n",
    "                        weight2 = road_class_weights.get(class2, road_class_weights['unknown'])\n",
    "                        distance = geom1.distance(geom2)\n",
    "                        weight = distance * (weight1 + weight2) / 2\n",
    "                        G.add_edge(node1_id, node2_id, weight=weight, type='road')\n",
    "                        pbar.update(1)\n",
    "\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"graph_with_edges_selected_neighborhoods.pkl\"), 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "\n",
    "    print(f\"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges for selected neighborhoods.\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate Walkability Scores (Integrate Tree Data, Transit Data, and NDVI)\n",
    "def calculate_walkability(G, neighborhoods):\n",
    "    print(\"Checkpoint 3: Calculating walkability scores for selected neighborhoods...\")\n",
    "    for node in tqdm(G.nodes(), total=G.number_of_nodes(), desc=\"Calculating walkability\"):\n",
    "        if G.nodes[node]['type'] == 'neighborhood':\n",
    "            # Handle NaN values in land use percentages and other metrics\n",
    "            residential = G.nodes[node]['land_use_residential_percent'] if pd.notna(G.nodes[node]['land_use_residential_percent']) else 0.0\n",
    "            commercial = G.nodes[node]['land_use_commercial_percent'] if pd.notna(G.nodes[node]['land_use_commercial_percent']) else 0.0\n",
    "            education = G.nodes[node]['land_use_education_percent'] if pd.notna(G.nodes[node]['land_use_education_percent']) else 0.0\n",
    "            ndvi = G.nodes[node]['ndvi_mean'] if pd.notna(G.nodes[node]['ndvi_mean']) else 0.0\n",
    "            tree_count = G.nodes[node]['tree_count'] if pd.notna(G.nodes[node]['tree_count']) else 0\n",
    "            transit_count = G.nodes[node]['transit_count'] if pd.notna(G.nodes[node]['transit_count']) else 0\n",
    "\n",
    "            # Original walkability score components\n",
    "            land_use_score = (residential * 0.4 + commercial * 0.3 + education * 0.2) / 100\n",
    "            ndvi_score = ndvi * 0.5\n",
    "\n",
    "            # Add tree and transit influence to walkability\n",
    "            # Normalize tree count (e.g., assume 100 trees max for scaling)\n",
    "            tree_score = min(1.0, tree_count / 100) * 0.2  # 20% weight for tree count\n",
    "            # Normalize transit count (e.g., assume 20 transit points max for scaling)\n",
    "            transit_score = min(1.0, transit_count / 20) * 0.2  # 20% weight for transit count\n",
    "\n",
    "            # Combine scores (weights sum to 1: land_use=0.4, ndvi=0.2, trees=0.2, transit=0.2)\n",
    "            walkability = min(1.0, land_use_score + (ndvi_score * 0.4) + tree_score + transit_score)\n",
    "            G.nodes[node]['walkability'] = walkability\n",
    "\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if data['type'] == 'neighborhood':\n",
    "            neighborhoods.loc[neighborhoods['LIE_NAME'] == data['lie_name'], 'walkability'] = data['walkability']\n",
    "\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"walkability_scores_selected_neighborhoods.pkl\"), 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "\n",
    "    print(\"Walkability scores calculated for selected neighborhoods.\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Interactive Kepler.gl Map (Modified)\n",
    "def create_interactive_map(G, neighborhoods, buildings, roads, trees, transit):\n",
    "    print(\"Generating interactive Kepler.gl map for selected neighborhoods...\")\n",
    "    try:\n",
    "        # Convert to WGS84 for Kepler.gl\n",
    "        neighborhoods_wgs84 = neighborhoods.to_crs('EPSG:4326')\n",
    "        buildings_wgs84 = buildings.to_crs('EPSG:4326')\n",
    "        roads_wgs84 = roads.to_crs('EPSG:4326')\n",
    "        trees_wgs84 = trees.to_crs('EPSG:4326')\n",
    "        transit_wgs84 = transit.to_crs('EPSG:4326')\n",
    "\n",
    "        # Prepare data for Kepler.gl\n",
    "        land_use_cols = [col for col in neighborhoods_wgs84.columns if col.startswith('land_use_') and col.endswith('_percent')]\n",
    "        display_cols = ['LIE_NAME', 'SECT_NAME', '2024population', 'ndvi_mean', 'tree_count', 'transit_count', 'walkability'] + land_use_cols\n",
    "        neighborhoods_data = neighborhoods_wgs84[display_cols + ['geometry']].copy()\n",
    "\n",
    "        # Update walkability and transit_count from the graph\n",
    "        for node in G.nodes(data=True):\n",
    "            if node[1]['type'] == 'neighborhood':\n",
    "                lie_name = node[1]['lie_name']\n",
    "                walkability = round(node[1].get('walkability', 0), 2)\n",
    "                transit_count = node[1].get('transit_count', 0)\n",
    "                lie_name_normalized = lie_name.strip()\n",
    "                neighborhoods_data.loc[neighborhoods_data['LIE_NAME'].str.strip() == lie_name_normalized, 'walkability'] = walkability\n",
    "                neighborhoods_data.loc[neighborhoods_data['LIE_NAME'].str.strip() == lie_name_normalized, 'transit_count'] = transit_count\n",
    "\n",
    "        # Round numeric columns to 2 decimal places\n",
    "        numeric_cols = ['2024population', 'ndvi_mean', 'tree_count', 'transit_count', 'walkability'] + land_use_cols\n",
    "        for col in numeric_cols:\n",
    "            neighborhoods_data[col] = pd.to_numeric(neighborhoods_data[col], errors='coerce').round(2)\n",
    "\n",
    "        # Convert to GeoJSON-like structure with dynamic filtering\n",
    "        geojson_data = {\n",
    "            'type': 'FeatureCollection',\n",
    "            'features': []\n",
    "        }\n",
    "        all_fields = set()  # To dynamically collect all non-zero/non-NaN fields across features\n",
    "        for _, row in neighborhoods_data.iterrows():\n",
    "            properties = row.drop('geometry').to_dict()\n",
    "            # Filter out zero and NaN values\n",
    "            filtered_properties = {k: v for k, v in properties.items() if pd.notna(v) and v != 0}\n",
    "            feature = {\n",
    "                'type': 'Feature',\n",
    "                'properties': filtered_properties,\n",
    "                'geometry': row['geometry'].__geo_interface__ if row['geometry'] is not None else None\n",
    "            }\n",
    "            geojson_data['features'].append(feature)\n",
    "            all_fields.update(filtered_properties.keys())\n",
    "\n",
    "        # Debug: Print GeoJSON properties for 和安里\n",
    "        print(\"GeoJSON properties for 和安里:\", [f for f in geojson_data['features'] if f['properties'].get('LIE_NAME') == '和安里'][0]['properties'])\n",
    "\n",
    "        # Dynamically determine fields to show based on filtered properties\n",
    "        fields_to_show = sorted(list(all_fields))  # Sort the fields alphabetically\n",
    "        print(\"Fields to show (sorted):\", fields_to_show)  # Debug: Print the sorted fields to verify\n",
    "\n",
    "        # Prepare other layers (unchanged)\n",
    "        buildings_data = buildings_wgs84[['building', 'area_m2', '屋齡', '建物高度', '地上層數', '構造種類', '使用分區', 'geometry']].copy()\n",
    "        buildings_data['建物高度'] = pd.to_numeric(buildings_data['建物高度'], errors='coerce').fillna(10).round(1)\n",
    "        buildings_data['地上層數'] = pd.to_numeric(buildings_data['地上層數'], errors='coerce').fillna(3).round(0)\n",
    "        buildings_data.columns = ['Building Type', 'Area (m²)', 'Building Age', 'Building Height (m)', 'Number of Floors', 'Structure Type', 'Zoning Use', 'geometry']\n",
    "        buildings_data = buildings_data[buildings_data['geometry'].notna()]\n",
    "\n",
    "        roads_data = roads_wgs84[['class', 'length_m', 'geometry']].copy()\n",
    "        roads_data['class'] = roads_data['class'].fillna('unknown')\n",
    "        roads_data['length_m'] = roads_data['length_m'].round(1)\n",
    "        roads_data = roads_data[roads_data['geometry'].notna()]\n",
    "\n",
    "        trees_data = trees_wgs84[['geometry']].copy()\n",
    "        trees_data['height_m'] = 10  # Default height for visualization\n",
    "        trees_data = trees_data[trees_data['geometry'].notna()]\n",
    "\n",
    "        transit_data = transit_wgs84[['class', 'geometry']].copy()\n",
    "        transit_data['size'] = 10  # Default size for visualization\n",
    "        transit_data = transit_data[transit_data['geometry'].notna()]\n",
    "\n",
    "        # Configure Kepler.gl with dynamic and sorted fieldsToShow\n",
    "        config = {\n",
    "            'version': 'v1',\n",
    "            'config': {\n",
    "                'visState': {\n",
    "                    'layers': [\n",
    "                        {\n",
    "                            'id': 'neighborhoods',\n",
    "                            'type': 'geojson',\n",
    "                            'config': {\n",
    "                                'dataId': 'Neighborhoods',\n",
    "                                'label': 'Neighborhoods',\n",
    "                                'isVisible': True,\n",
    "                                'visConfig': {\n",
    "                                    'opacity': 0.8,\n",
    "                                    'colorRange': {\n",
    "                                        'name': 'Global Warming',\n",
    "                                        'type': 'sequential',\n",
    "                                        'category': 'Uber',\n",
    "                                        'colors': ['#5A1846', '#900C3F', '#C70039', '#E3611C', '#F1920E', '#FFC300']\n",
    "                                    },\n",
    "                                    'filled': True\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        # ... (other layers remain unchanged)\n",
    "                    ],\n",
    "                    'interactionConfig': {\n",
    "                        'tooltip': {\n",
    "                            'fieldsToShow': {\n",
    "                                'Neighborhoods': fields_to_show,  # Use dynamically sorted fields\n",
    "                                'Buildings': ['Building Type', 'Area (m²)', 'Building Age', 'Building Height (m)', 'Number of Floors', 'Structure Type', 'Zoning Use'],\n",
    "                                'Roads': ['class', 'length_m'],\n",
    "                                'Trees': ['height_m'],\n",
    "                                'Transit': ['class', 'size']\n",
    "                            },\n",
    "                            'enabled': True\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                'mapState': {\n",
    "                    'latitude': 25.0224406,\n",
    "                    'longitude': 121.51855980000002,\n",
    "                    'zoom': 14,\n",
    "                    'pitch': 0,\n",
    "                    'bearing': 0\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Initialize Kepler.gl map with configuration\n",
    "        map_1 = KeplerGl(\n",
    "            height=600,\n",
    "            mapbox_api_access_token=MAPBOX_ACCESS_TOKEN,\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        # Add data to the map\n",
    "        map_1.add_data(data=geojson_data, name=\"Neighborhoods\")\n",
    "        map_1.add_data(data=buildings_data, name=\"Buildings\")\n",
    "        map_1.add_data(data=roads_data, name=\"Roads\")\n",
    "        map_1.add_data(data=trees_data, name=\"Trees\")\n",
    "        map_1.add_data(data=transit_data, name=\"Transit\")\n",
    "\n",
    "        # Save to HTML\n",
    "        output_path = os.path.join(r\"D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\", \"walkability_map_selected_neighborhoods.html\")\n",
    "        map_1.save_to_html(file_name=output_path)\n",
    "        print(f\"Interactive Kepler.gl map saved successfully at {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Kepler.gl map: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting walkability graph network analysis for 和安里 and all neighborhoods within the covering radius...\n",
      "Checkpoint 1: Loading data for 和安里 and all neighborhoods within the covering radius...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:  20%|██        | 1/5 [00:00<00:01,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in neighborhoods after loading: ['LIE_NAME', 'SECT_NAME', '2024population', 'land_use_city_open_area_count', 'land_use_city_open_area_area_m2', 'land_use_city_open_area_percent', 'land_use_commercial_count', 'land_use_commercial_area_m2', 'land_use_commercial_percent', 'land_use_infrastructure_count', 'land_use_infrastructure_area_m2', 'land_use_infrastructure_percent', 'land_use_government_count', 'land_use_government_area_m2', 'land_use_government_percent', 'land_use_public_transportation_count', 'land_use_public_transportation_area_m2', 'land_use_public_transportation_percent', 'land_use_education_count', 'land_use_education_area_m2', 'land_use_education_percent', 'land_use_medical_count', 'land_use_medical_area_m2', 'land_use_medical_percent', 'land_use_amenity_count', 'land_use_amenity_area_m2', 'land_use_amenity_percent', 'land_use_road_count', 'land_use_road_area_m2', 'land_use_road_percent', 'land_use_pedestrian_count', 'land_use_pedestrian_area_m2', 'land_use_pedestrian_percent', 'land_use_natural_count', 'land_use_natural_area_m2', 'land_use_natural_percent', 'land_use_special_zone_count', 'land_use_special_zone_area_m2', 'land_use_special_zone_percent', 'land_use_river_count', 'land_use_river_area_m2', 'land_use_river_percent', 'land_use_military_count', 'land_use_military_area_m2', 'land_use_military_percent', 'land_use_residential_count', 'land_use_residential_area_m2', 'land_use_residential_percent', 'land_use_industrial_count', 'land_use_industrial_area_m2', 'land_use_industrial_percent', 'land_use_agriculture_count', 'land_use_agriculture_area_m2', 'land_use_agriculture_percent', 'ndvi_mean', 'ndvi_median', 'geometry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building type distribution after cleaning:\n",
      "building\n",
      "apartments     23519\n",
      "residential    18958\n",
      "unknown        17957\n",
      "house           4305\n",
      "school          1569\n",
      "               ...  \n",
      "social             1\n",
      "civil              1\n",
      "entrance           1\n",
      "supermarket        1\n",
      "r                  1\n",
      "Name: count, Length: 80, dtype: int64\n",
      "Warren: Total number of neighborhoods in dataset: 456\n",
      "Total number of tree points loaded: 2289\n",
      "Total number of tree polylines loaded: 1106\n",
      "Total number of trees after converting polylines: 17786\n",
      "Total number of transit points loaded: 6845\n",
      "Found 16 neighborhoods within 1000m radius.\n",
      "Selected neighborhoods and distances from 和安里 (in meters):\n",
      "- 和安里: 0.0m\n",
      "- 仁慈里: 412.0m\n",
      "- 龍圖里: 459.4m\n",
      "- 義村里: 461.4m\n",
      "- 民炤里: 549.6m\n",
      "- 德安里: 674.6m\n",
      "- 住安里: 675.5m\n",
      "- 新龍里: 708.3m\n",
      "- 仁愛里: 715.3m\n",
      "- 誠安里: 843.3m\n",
      "- 民輝里: 850.9m\n",
      "- 昌隆里: 857.5m\n",
      "- 龍雲里: 872.8m\n",
      "- 龍陣里: 876.9m\n",
      "- 龍門里: 976.1m\n",
      "- 敦安里: 995.1m\n",
      "Integrating tree data with neighborhoods...\n",
      "Integrating transit data with neighborhoods...\n",
      "Tree and transit counts per neighborhood:\n",
      "- 和安里: 144 trees, 15 transit points\n",
      "- 仁慈里: 55 trees, 8 transit points\n",
      "- 龍圖里: 54 trees, 3 transit points\n",
      "- 義村里: 163 trees, 11 transit points\n",
      "- 民炤里: 122 trees, 13 transit points\n",
      "- 德安里: 128 trees, 6 transit points\n",
      "- 住安里: 34 trees, 3 transit points\n",
      "- 新龍里: 0 trees, 2 transit points\n",
      "- 仁愛里: 170 trees, 10 transit points\n",
      "- 誠安里: 21 trees, 8 transit points\n",
      "- 民輝里: 239 trees, 17 transit points\n",
      "- 昌隆里: 37 trees, 4 transit points\n",
      "- 龍雲里: 34 trees, 1 transit points\n",
      "- 龍陣里: 0 trees, 4 transit points\n",
      "- 龍門里: 455 trees, 20 transit points\n",
      "- 敦安里: 132 trees, 7 transit points\n",
      "Road length distribution (in meters):\n",
      "count     2063.000000\n",
      "mean       195.705574\n",
      "std       1160.733823\n",
      "min          0.800000\n",
      "25%         26.900000\n",
      "50%         63.300000\n",
      "75%        142.650000\n",
      "max      26879.200000\n",
      "Name: length_m, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting road endpoints: 100%|██████████| 2063/2063 [00:00<00:00, 21030.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and filtered for 和安里 and all neighborhoods within 1000m radius. Neighborhoods: 16, Buildings: 2848, Roads: 2063, Trees: 2085, Transit Points: 179\n",
      "Checkpoint 2: Building graph network for selected neighborhoods...\n",
      "Adding neighborhood nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding neighborhoods: 100%|██████████| 16/16 [00:00<00:00, 7999.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding building nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding buildings: 100%|██████████| 2848/2848 [00:00<00:00, 26872.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding road nodes...\n",
      "Using column 'class' for road classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding road points: 100%|██████████| 4126/4126 [00:00<00:00, 50313.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding tree nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding trees: 100%|██████████| 2085/2085 [00:00<00:00, 53629.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding transit nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding transit points: 100%|██████████| 179/179 [00:00<00:00, 43611.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding edges:   0%|          | 49748/20408531 [01:10<31:38, 10726.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding road-to-road edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding edges:   0%|          | 55255/20408531 [02:00<12:17:57, 459.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built with 9254 nodes and 55255 edges for selected neighborhoods.\n",
      "Checkpoint 3: Calculating walkability scores for selected neighborhoods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating walkability: 100%|██████████| 9254/9254 [00:00<00:00, 2312151.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walkability scores calculated for selected neighborhoods.\n",
      "Generating interactive Kepler.gl map for selected neighborhoods...\n",
      "GeoJSON properties for 和安里: {'LIE_NAME': '和安里', 'SECT_NAME': '大安區', '2024population': 6933, 'ndvi_mean': 0.28, 'tree_count': 144, 'transit_count': 15, 'walkability': 0.69, 'land_use_city_open_area_percent': 1.89, 'land_use_commercial_percent': 10.13, 'land_use_government_percent': 0.37, 'land_use_education_percent': 44.77, 'land_use_natural_percent': 2.24, 'land_use_special_zone_percent': 0.44, 'land_use_residential_percent': 40.17}\n",
      "Fields to show (sorted): ['2024population', 'LIE_NAME', 'SECT_NAME', 'land_use_amenity_percent', 'land_use_city_open_area_percent', 'land_use_commercial_percent', 'land_use_education_percent', 'land_use_government_percent', 'land_use_infrastructure_percent', 'land_use_medical_percent', 'land_use_military_percent', 'land_use_natural_percent', 'land_use_public_transportation_percent', 'land_use_residential_percent', 'land_use_road_percent', 'land_use_special_zone_percent', 'ndvi_mean', 'transit_count', 'tree_count', 'walkability']\n",
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n",
      "Map saved to D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\walkability_map_selected_neighborhoods.html!\n",
      "Interactive Kepler.gl map saved successfully at D:\\IAAC\\Thesis\\Python\\MLloading\\Geojson\\GNN_Read_data\\walkability_map_selected_neighborhoods.html\n",
      "Analysis completed successfully for 和安里 and all neighborhoods within the covering radius.\n"
     ]
    }
   ],
   "source": [
    "# 5. Main Execution\n",
    "def main():\n",
    "    print(\"Starting walkability graph network analysis for 和安里 and all neighborhoods within the covering radius...\")\n",
    "    try:\n",
    "        neighborhoods, buildings, roads, road_points, trees, transit = load_data()\n",
    "        G = build_graph(neighborhoods, buildings, roads, road_points, trees, transit)\n",
    "        G = calculate_walkability(G, neighborhoods)\n",
    "        create_interactive_map(G, neighborhoods, buildings, roads, trees, transit)\n",
    "        print(\"Analysis completed successfully for 和安里 and all neighborhoods within the covering radius.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
